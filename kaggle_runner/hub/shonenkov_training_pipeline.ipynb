{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shonenkov-training-pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fc4391950ec4d3485c09ecca6865f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_831e2c2466bc4706820928ef52e9d43b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c89370f1e14432d97d27e5b566bb2be",
              "IPY_MODEL_adccc5bc3c5649e08947bf303da9235e"
            ]
          }
        },
        "831e2c2466bc4706820928ef52e9d43b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c89370f1e14432d97d27e5b566bb2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_02d9b2a5f73140cea2a7200c026a0269",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 513,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 513,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab9a4062e20a4ac9b435a6125fef5cba"
          }
        },
        "adccc5bc3c5649e08947bf303da9235e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_400e12ae27e44d288f7c6c7dd1ddbb5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 513/513 [00:53&lt;00:00, 9.54B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a479796d76a04d748f676bc4919adb03"
          }
        },
        "02d9b2a5f73140cea2a7200c026a0269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab9a4062e20a4ac9b435a6125fef5cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "400e12ae27e44d288f7c6c7dd1ddbb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a479796d76a04d748f676bc4919adb03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91a008dd264c478abeede676c12aac6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd64e537195d4d83bb11532093923423",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7072f1c33925408cb4602f16248b7233",
              "IPY_MODEL_8c4206d2621f47dd96bd3e9c61a21ba1"
            ]
          }
        },
        "dd64e537195d4d83bb11532093923423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7072f1c33925408cb4602f16248b7233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6660c1bb684d45c0b9f3181f60bd69b0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 2244861551,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2244861551,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f33626631eff47edb3a6977ff3072568"
          }
        },
        "8c4206d2621f47dd96bd3e9c61a21ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_427e2d6eaff64f8ab4b0cbb87819a16b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.24G/2.24G [00:53&lt;00:00, 42.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f82755ad350542d0a31aa64d4c7502c7"
          }
        },
        "6660c1bb684d45c0b9f3181f60bd69b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f33626631eff47edb3a6977ff3072568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "427e2d6eaff64f8ab4b0cbb87819a16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f82755ad350542d0a31aa64d4c7502c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pennz/kaggle_runner/blob/master/kaggle_runner/hub/shonenkov_training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzoWM76m0Rfg",
        "colab_type": "text"
      },
      "source": [
        "### Dont forget turn on TPU & HIGH-RAM modes :) \n",
        "\n",
        "Author: [Alex Shonenkov](https://www.kaggle.com/shonenkov) //  shonenkov@phystech.edu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsZb7QICuRIe",
        "colab_type": "code",
        "outputId": "5ee75b41-191b-4648-8020-0a8fbe41c447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null\n",
        "!python pytorch-xla-env-setup.py --version 20200420 --apt-packages libomp5 libopenblas-dev\n",
        "!pip install transformers==2.5.1 > /dev/null\n",
        "!pip install pandarallel > /dev/null\n",
        "!pip install catalyst==20.4.2 > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4264  100  4264    0     0  47377      0 --:--:-- --:--:-- --:--:-- 47910\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200420 ...\n",
            "Uninstalling torch-1.5.0+cu101:\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "  Successfully uninstalled torch-1.5.0+cu101\n",
            "Uninstalling torchvision-0.6.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 86.8 MiB/ 86.8 MiB]                                                \n",
            "Operation completed over 1 objects/86.8 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\n",
            "| [1 files][117.2 MiB/117.2 MiB]                                                \n",
            "Operation completed over 1 objects/117.2 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.4 MiB/  2.4 MiB]                                                \n",
            "Operation completed over 1 objects/2.4 MiB.                                      \n",
            "Processing ./torch-nightly+20200420-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200420) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200420) (1.18.4)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+30e7055\n",
            "Processing ./torch_xla-nightly+20200420-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+ae5379c\n",
            "Processing ./torchvision-nightly+20200420-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200420) (1.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200420) (1.6.0a0+30e7055)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200420) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200420) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+7b60f4d\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (383 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6uGvKL3upio",
        "colab_type": "code",
        "outputId": "06d14a3a-0e0a-47c2-962e-cec20b94a62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "os.environ['XLA_USE_BF16'] = \"1\"\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "import sklearn\n",
        "\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
        "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
        "\n",
        "import gc\n",
        "import re\n",
        "\n",
        "# !pip install nltk > /dev/null\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from pandarallel import pandarallel\n",
        "\n",
        "pandarallel.initialize(nb_workers=4, progress_bar=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "INFO: Pandarallel will run on 4 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-VP4QbZu9EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "MAX_LENGTH = 224\n",
        "BACKBONE_PATH = 'xlm-roberta-large'\n",
        "# ROOT_PATH = f'..'\n",
        "ROOT_PATH = f'/content/drive/My Drive/jigsaw2020-kaggle-public-baseline' # for colab\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63ceMzcxu9GS",
        "colab_type": "code",
        "outputId": "7dfe689b-6b03-4d21-a0ae-825843ef4650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from nltk import sent_tokenize\n",
        "from random import shuffle\n",
        "import random\n",
        "import albumentations\n",
        "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
        "\n",
        "\n",
        "LANGS = {\n",
        "    'en': 'english',\n",
        "    'it': 'italian', \n",
        "    'fr': 'french', \n",
        "    'es': 'spanish',\n",
        "    'tr': 'turkish', \n",
        "    'ru': 'russian',\n",
        "    'pt': 'portuguese'\n",
        "}\n",
        "\n",
        "def get_sentences(text, lang='en'):\n",
        "    return sent_tokenize(text, LANGS.get(lang, 'english'))\n",
        "\n",
        "def exclude_duplicate_sentences(text, lang='en'):\n",
        "    sentences = []\n",
        "    for sentence in get_sentences(text, lang):\n",
        "        sentence = sentence.strip()\n",
        "        if sentence not in sentences:\n",
        "            sentences.append(sentence)\n",
        "    return ' '.join(sentences)\n",
        "\n",
        "def clean_text(text, lang='en'):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'[0-9\"]', '', text)\n",
        "    text = re.sub(r'#[\\S]+\\b', '', text)\n",
        "    text = re.sub(r'@[\\S]+\\b', '', text)\n",
        "    text = re.sub(r'https?\\S+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = exclude_duplicate_sentences(text, lang)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "class NLPTransform(BasicTransform):\n",
        "    \"\"\" Transform for nlp task.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def targets(self):\n",
        "        return {\"data\": self.apply}\n",
        "    \n",
        "    def update_params(self, params, **kwargs):\n",
        "        if hasattr(self, \"interpolation\"):\n",
        "            params[\"interpolation\"] = self.interpolation\n",
        "        if hasattr(self, \"fill_value\"):\n",
        "            params[\"fill_value\"] = self.fill_value\n",
        "        return params\n",
        "\n",
        "    def get_sentences(self, text, lang='en'):\n",
        "        return sent_tokenize(text, LANGS.get(lang, 'english'))\n",
        "\n",
        "class ShuffleSentencesTransform(NLPTransform):\n",
        "    \"\"\" Do shuffle by sentence \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        sentences = self.get_sentences(text, lang)\n",
        "        random.shuffle(sentences)\n",
        "        return ' '.join(sentences), lang\n",
        "\n",
        "class ExcludeDuplicateSentencesTransform(NLPTransform):\n",
        "    \"\"\" Exclude equal sentences \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeDuplicateSentencesTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        sentences = []\n",
        "        for sentence in self.get_sentences(text, lang):\n",
        "            sentence = sentence.strip()\n",
        "            if sentence not in sentences:\n",
        "                sentences.append(sentence)\n",
        "        return ' '.join(sentences), lang\n",
        "\n",
        "class ExcludeNumbersTransform(NLPTransform):\n",
        "    \"\"\" exclude any numbers \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeNumbersTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'[0-9]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang\n",
        "\n",
        "class ExcludeHashtagsTransform(NLPTransform):\n",
        "    \"\"\" Exclude any hashtags with # \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeHashtagsTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'#[\\S]+\\b', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang\n",
        "\n",
        "class ExcludeUsersMentionedTransform(NLPTransform):\n",
        "    \"\"\" Exclude @users \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeUsersMentionedTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'@[\\S]+\\b', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang\n",
        "\n",
        "class ExcludeUrlsTransform(NLPTransform):\n",
        "    \"\"\" Exclude urls \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeUrlsTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'https?\\S+', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFB3UeyAsYCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SynthesicOpenSubtitlesTransform(NLPTransform):\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(SynthesicOpenSubtitlesTransform, self).__init__(always_apply, p)\n",
        "        df = pd.read_csv(f'{ROOT_PATH}/input/open-subtitles-toxic-pseudo-labeling/open-subtitles-synthesic.csv', index_col='id')[['comment_text', 'toxic', 'lang']]\n",
        "        df = df[~df['comment_text'].isna()]\n",
        "        df['comment_text'] = df.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
        "        df = df.drop_duplicates(subset='comment_text')\n",
        "        df['toxic'] = df['toxic'].round().astype(np.int)\n",
        "\n",
        "        self.synthesic_toxic = df[df['toxic'] == 1].comment_text.values\n",
        "        self.synthesic_non_toxic = df[df['toxic'] == 0].comment_text.values\n",
        "\n",
        "        del df\n",
        "        gc.collect();\n",
        "\n",
        "    def generate_synthesic_sample(self, text, toxic):\n",
        "        texts = [text]\n",
        "        if toxic == 0:\n",
        "            for i in range(random.randint(1,5)):\n",
        "                texts.append(random.choice(self.synthesic_non_toxic))\n",
        "        else:\n",
        "            for i in range(random.randint(0,2)):\n",
        "                texts.append(random.choice(self.synthesic_non_toxic))\n",
        "            \n",
        "            for i in range(random.randint(1,3)):\n",
        "                texts.append(random.choice(self.synthesic_toxic))\n",
        "        random.shuffle(texts)\n",
        "        return ' '.join(texts)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, toxic = data\n",
        "        text = self.generate_synthesic_sample(text, toxic)\n",
        "        return text, toxic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5BdJ9HWvnLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "411e21c1-17bf-4341-df9f-02cf5d6a2045"
      },
      "source": [
        "def get_train_transforms():\n",
        "    return albumentations.Compose([\n",
        "        ExcludeUsersMentionedTransform(p=0.95),\n",
        "        ExcludeUrlsTransform(p=0.95),\n",
        "        ExcludeNumbersTransform(p=0.95),\n",
        "        ExcludeHashtagsTransform(p=0.95),\n",
        "        ExcludeDuplicateSentencesTransform(p=0.95),\n",
        "    ], p=1.0)\n",
        "\n",
        "def get_synthesic_transforms():\n",
        "    return SynthesicOpenSubtitlesTransform(p=0.5)\n",
        "\n",
        "\n",
        "train_transforms = get_train_transforms();\n",
        "synthesic_transforms = get_synthesic_transforms()\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(BACKBONE_PATH)\n",
        "shuffle_transforms = ShuffleSentencesTransform(always_apply=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-47630b1616bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrain_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msynthesic_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_synthesic_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBACKBONE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mshuffle_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSentencesTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-47630b1616bb>\u001b[0m in \u001b[0;36mget_synthesic_transforms\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_synthesic_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSynthesicOpenSubtitlesTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-af21f8cfca21>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, always_apply, p)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSynthesicOpenSubtitlesTransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{ROOT_PATH}/input/open-subtitles-toxic-pseudo-labeling/open-subtitles-synthesic.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toxic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/My Drive/jigsaw2020-kaggle-public-baseline/input/open-subtitles-toxic-pseudo-labeling/open-subtitles-synthesic.csv does not exist: '/content/drive/My Drive/jigsaw2020-kaggle-public-baseline/input/open-subtitles-toxic-pseudo-labeling/open-subtitles-synthesic.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFp80AuJu9Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot(size, target):\n",
        "    vec = torch.zeros(size, dtype=torch.float32)\n",
        "    vec[target] = 1.\n",
        "    return vec\n",
        "\n",
        "class DatasetRetriever(Dataset):\n",
        "\n",
        "    def __init__(self, labels_or_ids, comment_texts, langs, use_train_transforms=False, test=False):\n",
        "        self.test = test\n",
        "        self.labels_or_ids = labels_or_ids\n",
        "        self.comment_texts = comment_texts\n",
        "        self.langs = langs\n",
        "        self.use_train_transforms = use_train_transforms\n",
        "        \n",
        "    def get_tokens(self, text):\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text, \n",
        "            add_special_tokens=True, \n",
        "            max_length=MAX_LENGTH, \n",
        "            pad_to_max_length=True\n",
        "        )\n",
        "        return encoded['input_ids'], encoded['attention_mask']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.comment_texts.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comment_texts[idx]\n",
        "        lang = self.langs[idx]\n",
        "        if self.test is False:\n",
        "            label = self.labels_or_ids[idx]\n",
        "            target = onehot(2, label)\n",
        "\n",
        "        if self.use_train_transforms:\n",
        "            text, _ = train_transforms(data=(text, lang))['data']\n",
        "            tokens, attention_mask = self.get_tokens(str(text))\n",
        "            token_length = sum(attention_mask)\n",
        "            if token_length > 0.8*MAX_LENGTH:\n",
        "                text, _ = shuffle_transforms(data=(text, lang))['data']\n",
        "            elif token_length < 60:\n",
        "                text, _ = synthesic_transforms(data=(text, label))['data']\n",
        "            else:\n",
        "                tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n",
        "                return target, tokens, attention_mask\n",
        "\n",
        "        tokens, attention_mask = self.get_tokens(str(text))\n",
        "        tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n",
        "\n",
        "        if self.test is False:\n",
        "            return target, tokens, attention_mask\n",
        "        return self.labels_or_ids[idx], tokens, attention_mask\n",
        "\n",
        "    def get_labels(self):\n",
        "        return list(np.char.add(self.labels_or_ids.astype(str), self.langs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DVkkUVMu9Ka",
        "colab_type": "code",
        "outputId": "0298fff0-3c61-44ba-a3fe-891f9d7d8722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "df_train = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-public-baseline-train-data/train_data.csv')\n",
        "\n",
        "\n",
        "train_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_train['toxic'].values, \n",
        "    comment_texts=df_train['comment_text'].values, \n",
        "    langs=df_train['lang'].values,\n",
        "    use_train_transforms=True,\n",
        ")\n",
        "\n",
        "del df_train\n",
        "gc.collect();\n",
        "\n",
        "for targets, tokens, attention_masks in train_dataset:\n",
        "    break\n",
        "    \n",
        "print(targets)\n",
        "print(tokens.shape)\n",
        "print(attention_masks.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:2: DtypeWarning:\n",
            "\n",
            "Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 0.])\n",
            "torch.Size([224])\n",
            "torch.Size([224])\n",
            "CPU times: user 14.3 s, sys: 1.67 s, total: 15.9 s\n",
            "Wall time: 16.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlcGdUdSYewm",
        "colab_type": "code",
        "outputId": "da7b7b6d-1e16-49ad-b351-98799ecd81f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.unique(train_dataset.get_labels())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0en', '0es', '0fr', '0it', '0pt', '0ru', '0tr', '1en', '1es',\n",
              "       '1fr', '1it', '1pt', '1ru', '1tr'], dtype='<U3')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW4dEWaYu9NF",
        "colab_type": "code",
        "outputId": "76be10d9-4005-4e55-8a45-cfa3e35bb691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_val = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-multilingual-toxic-comment-classification/validation.csv', index_col='id')\n",
        "\n",
        "validation_tune_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_val['toxic'].values, \n",
        "    comment_texts=df_val['comment_text'].values, \n",
        "    langs=df_val['lang'].values,\n",
        "    use_train_transforms=True,\n",
        ")\n",
        "\n",
        "df_val['comment_text'] = df_val.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
        "\n",
        "validation_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_val['toxic'].values, \n",
        "    comment_texts=df_val['comment_text'].values, \n",
        "    langs=df_val['lang'].values,\n",
        "    use_train_transforms=False,\n",
        ")\n",
        "\n",
        "del df_val\n",
        "gc.collect();\n",
        "\n",
        "for targets, tokens, attention_masks in validation_dataset:\n",
        "    break\n",
        "\n",
        "print(targets)\n",
        "print(tokens.shape)\n",
        "print(attention_masks.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 0.])\n",
            "torch.Size([224])\n",
            "torch.Size([224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNdADp28v3av",
        "colab_type": "code",
        "outputId": "91f3e56a-d69f-4cea-cdec-46f6a8c9f7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_test = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-multilingual-toxic-comment-classification/test.csv', index_col='id')\n",
        "df_test['comment_text'] = df_test.parallel_apply(lambda x: clean_text(x['content'], x['lang']), axis=1)\n",
        "\n",
        "test_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_test.index.values, \n",
        "    comment_texts=df_test['comment_text'].values, \n",
        "    langs=df_test['lang'].values,\n",
        "    use_train_transforms=False,\n",
        "    test=True\n",
        ")\n",
        "\n",
        "del df_test\n",
        "gc.collect();\n",
        "\n",
        "for ids, tokens, attention_masks in test_dataset:\n",
        "    break\n",
        "\n",
        "print(ids)\n",
        "print(tokens.shape)\n",
        "print(attention_masks.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([224])\n",
            "torch.Size([224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2bN_NySwU6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RocAucMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.y_true = np.array([0,1])\n",
        "        self.y_pred = np.array([0.5,0.5])\n",
        "        self.score = 0\n",
        "\n",
        "    def update(self, y_true, y_pred):\n",
        "        y_true = y_true.cpu().numpy().argmax(axis=1)\n",
        "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
        "        self.y_true = np.hstack((self.y_true, y_true))\n",
        "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
        "        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred, labels=np.array([0, 1]))\n",
        "    \n",
        "    @property\n",
        "    def avg(self):\n",
        "        return self.score\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arcC5IeYxUbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LabelSmoothing(nn.Module):\n",
        "    def __init__(self, smoothing = 0.1):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        if self.training:\n",
        "            x = x.float()\n",
        "            target = target.float()\n",
        "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
        "\n",
        "            nll_loss = -logprobs * target\n",
        "            nll_loss = nll_loss.sum(-1)\n",
        "    \n",
        "            smooth_loss = -logprobs.mean(dim=-1)\n",
        "\n",
        "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return torch.nn.functional.cross_entropy(x, target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow13PTlFwbiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
        "\n",
        "class TPUFitter:\n",
        "    \n",
        "    def __init__(self, model, device, config):\n",
        "        if not os.path.exists('node_submissions'):\n",
        "            os.makedirs('node_submissions')\n",
        "\n",
        "        self.config = config\n",
        "        self.epoch = 0\n",
        "        self.log_path = 'log.txt'\n",
        "\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "\n",
        "        param_optimizer = list(self.model.named_parameters())\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=config.lr*xm.xrt_world_size())\n",
        "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
        "\n",
        "        self.criterion = config.criterion\n",
        "        xm.master_print(f'Fitter prepared. Device is {self.device}')\n",
        "\n",
        "    def fit(self, train_loader, validation_loader):\n",
        "        for e in range(self.config.n_epochs):\n",
        "            if self.config.verbose:\n",
        "                lr = self.optimizer.param_groups[0]['lr']\n",
        "                timestamp = datetime.utcnow().isoformat()\n",
        "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
        "\n",
        "            t = time.time()\n",
        "            para_loader = pl.ParallelLoader(train_loader, [self.device])\n",
        "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
        "            \n",
        "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            t = time.time()\n",
        "            para_loader = pl.ParallelLoader(validation_loader, [self.device])\n",
        "            losses, final_scores = self.validation(para_loader.per_device_loader(self.device))\n",
        "\n",
        "            self.log(f'[RESULT]: Validation. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            if self.config.validation_scheduler:\n",
        "                self.scheduler.step(metrics=final_scores.avg)\n",
        "\n",
        "            self.epoch += 1\n",
        "    \n",
        "    def run_tuning_and_inference(self, test_loader, validation_tune_loader):\n",
        "        for e in range(2):\n",
        "            self.optimizer.param_groups[0]['lr'] = self.config.lr*xm.xrt_world_size()\n",
        "            para_loader = pl.ParallelLoader(validation_tune_loader, [self.device])\n",
        "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
        "            para_loader = pl.ParallelLoader(test_loader, [self.device])\n",
        "            self.run_inference(para_loader.per_device_loader(self.device))\n",
        "\n",
        "    def validation(self, val_loader):\n",
        "        self.model.eval()\n",
        "        losses = AverageMeter()\n",
        "        final_scores = RocAucMeter()\n",
        "\n",
        "        t = time.time()\n",
        "        for step, (targets, inputs, attention_masks) in enumerate(val_loader):\n",
        "            if self.config.verbose:\n",
        "                if step % self.config.verbose_step == 0:\n",
        "                    xm.master_print(\n",
        "                        f'Valid Step {step}, loss: ' + \\\n",
        "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n",
        "                        f'time: {(time.time() - t):.5f}'\n",
        "                    )\n",
        "            with torch.no_grad():\n",
        "                inputs = inputs.to(self.device, dtype=torch.long) \n",
        "                attention_masks = attention_masks.to(self.device, dtype=torch.long) \n",
        "                targets = targets.to(self.device, dtype=torch.float) \n",
        "\n",
        "                outputs = self.model(inputs, attention_masks)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                \n",
        "                batch_size = inputs.size(0)\n",
        "\n",
        "                final_scores.update(targets, outputs)\n",
        "                losses.update(loss.detach().item(), batch_size)\n",
        "                \n",
        "        return losses, final_scores\n",
        "         \n",
        "    def train_one_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "\n",
        "        losses = AverageMeter()\n",
        "        final_scores = RocAucMeter()\n",
        "        t = time.time()\n",
        "        for step, (targets, inputs, attention_masks) in enumerate(train_loader):   \n",
        "            if self.config.verbose:\n",
        "                if step % self.config.verbose_step == 0:\n",
        "                    self.log(\n",
        "                        f'Train Step {step}, loss: ' + \\\n",
        "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n",
        "                        f'time: {(time.time() - t):.5f}'\n",
        "                    )\n",
        "\n",
        "            inputs = inputs.to(self.device, dtype=torch.long)\n",
        "            attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
        "            targets = targets.to(self.device, dtype=torch.float)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs, attention_masks)\n",
        "            loss = self.criterion(outputs, targets)\n",
        "\n",
        "            batch_size = inputs.size(0)\n",
        "            \n",
        "            final_scores.update(targets, outputs)\n",
        "            \n",
        "            losses.update(loss.detach().item(), batch_size)\n",
        "\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(self.optimizer)\n",
        "\n",
        "            if self.config.step_scheduler:\n",
        "                self.scheduler.step()\n",
        "        \n",
        "        self.model.eval()\n",
        "        self.save('last-checkpoint.bin')\n",
        "        return losses, final_scores\n",
        "\n",
        "    def run_inference(self, test_loader):\n",
        "        self.model.eval()\n",
        "        result = {'id': [], 'toxic': []}\n",
        "        t = time.time()\n",
        "        for step, (ids, inputs, attention_masks) in enumerate(test_loader):\n",
        "            if self.config.verbose:\n",
        "                if step % self.config.verbose_step == 0:\n",
        "                    xm.master_print(f'Prediction Step {step}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = inputs.to(self.device, dtype=torch.long) \n",
        "                attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
        "                outputs = self.model(inputs, attention_masks)\n",
        "                toxics = nn.functional.softmax(outputs, dim=1).data.cpu().numpy()[:,1]\n",
        "\n",
        "            result['id'].extend(ids.cpu().numpy())\n",
        "            result['toxic'].extend(toxics)\n",
        "\n",
        "        result = pd.DataFrame(result)\n",
        "        node_count = len(glob('node_submissions/*.csv'))\n",
        "        result.to_csv(f'node_submissions/submission_{node_count}_{datetime.utcnow().microsecond}_{random.random()}.csv', index=False)\n",
        "\n",
        "    def save(self, path):        \n",
        "        xm.save(self.model.state_dict(), path)\n",
        "\n",
        "    def log(self, message):\n",
        "        if self.config.verbose:\n",
        "            xm.master_print(message)\n",
        "        with open(self.log_path, 'a+') as logger:\n",
        "            xm.master_print(f'{message}', logger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO9ovGhdwb7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import XLMRobertaModel\n",
        "\n",
        "class ToxicSimpleNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ToxicSimpleNNModel, self).__init__()\n",
        "        self.backbone = XLMRobertaModel.from_pretrained(BACKBONE_PATH)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.linear = nn.Linear(\n",
        "            in_features=self.backbone.pooler.dense.out_features*2,\n",
        "            out_features=2,\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        bs, seq_length = input_ids.shape\n",
        "        seq_x, _ = self.backbone(input_ids=input_ids, attention_mask=attention_masks)\n",
        "        apool = torch.mean(seq_x, 1)\n",
        "        mpool, _ = torch.max(seq_x, 1)\n",
        "        x = torch.cat((apool, mpool), 1)\n",
        "        x = self.dropout(x)\n",
        "        return self.linear(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZmTJ4XQwb9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainGlobalConfig:\n",
        "    \"\"\" Global Config for this notebook \"\"\"\n",
        "    num_workers = 0  # количество воркеров для loaders\n",
        "    batch_size = 16  # bs\n",
        "    n_epochs = 3  # количество эпох для обучения\n",
        "    lr = 0.5 * 1e-5 # стартовый learning rate (внутри логика работы с мульти TPU домножает на кол-во процессов)\n",
        "    fold_number = 0  # номер фолда для обучения\n",
        "\n",
        "    # -------------------\n",
        "    verbose = True  # выводить принты\n",
        "    verbose_step = 50  # количество шагов для вывода принта\n",
        "    # -------------------\n",
        "\n",
        "    # --------------------\n",
        "    step_scheduler = False  # выполнять scheduler.step после вызова optimizer.step\n",
        "    validation_scheduler = True  # выполнять scheduler.step после валидации loss (например для плато)\n",
        "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "    scheduler_params = dict(\n",
        "        mode='max',\n",
        "        factor=0.7,\n",
        "        patience=0,\n",
        "        verbose=False, \n",
        "        threshold=0.0001,\n",
        "        threshold_mode='abs',\n",
        "        cooldown=0, \n",
        "        min_lr=1e-8,\n",
        "        eps=1e-08\n",
        "    )\n",
        "    # --------------------\n",
        "\n",
        "    # -------------------\n",
        "    criterion = LabelSmoothing()\n",
        "    # -------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_79qoceFwcAF",
        "colab_type": "code",
        "outputId": "afaf8542-c383-475c-d628-2503e556138d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "9fc4391950ec4d3485c09ecca6865f31",
            "831e2c2466bc4706820928ef52e9d43b",
            "0c89370f1e14432d97d27e5b566bb2be",
            "adccc5bc3c5649e08947bf303da9235e",
            "02d9b2a5f73140cea2a7200c026a0269",
            "ab9a4062e20a4ac9b435a6125fef5cba",
            "400e12ae27e44d288f7c6c7dd1ddbb5a",
            "a479796d76a04d748f676bc4919adb03",
            "91a008dd264c478abeede676c12aac6c",
            "dd64e537195d4d83bb11532093923423",
            "7072f1c33925408cb4602f16248b7233",
            "8c4206d2621f47dd96bd3e9c61a21ba1",
            "6660c1bb684d45c0b9f3181f60bd69b0",
            "f33626631eff47edb3a6977ff3072568",
            "427e2d6eaff64f8ab4b0cbb87819a16b",
            "f82755ad350542d0a31aa64d4c7502c7"
          ]
        }
      },
      "source": [
        "net = ToxicSimpleNNModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fc4391950ec4d3485c09ecca6865f31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=513, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91a008dd264c478abeede676c12aac6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=2244861551, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INecI_CbxXA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _mp_fn(rank, flags):\n",
        "    device = xm.xla_device()\n",
        "    net.to(device)\n",
        "\n",
        "    train_sampler = DistributedSamplerWrapper(\n",
        "        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=True,\n",
        "        num_workers=TrainGlobalConfig.num_workers,\n",
        "    )\n",
        "    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        validation_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    validation_loader = torch.utils.data.DataLoader(\n",
        "        validation_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        validation_tune_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    validation_tune_loader = torch.utils.data.DataLoader(\n",
        "        validation_tune_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_tune_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        test_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=test_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "\n",
        "    if rank == 0:\n",
        "        time.sleep(1)\n",
        "    \n",
        "    fitter = TPUFitter(model=net, device=device, config=TrainGlobalConfig)\n",
        "    fitter.fit(train_loader, validation_loader)\n",
        "    fitter.run_tuning_and_inference(test_loader, validation_tune_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKuUULH7l5W1",
        "colab_type": "code",
        "outputId": "cf01d30c-8ff8-4369-85cb-32cf610993ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "FLAGS={}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitter prepared. Device is xla:1\n",
            "\n",
            "2020-05-04T16:52:20.438990\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.82617\n",
            "Train Step 50, loss: 0.51566, final_score: 0.85479, time: 200.35051\n",
            "Train Step 100, loss: 0.43166, final_score: 0.92426, time: 251.99104\n",
            "Train Step 150, loss: 0.39472, final_score: 0.94679, time: 303.32809\n",
            "Train Step 200, loss: 0.38015, final_score: 0.95423, time: 354.55723\n",
            "Train Step 250, loss: 0.36591, final_score: 0.96103, time: 405.76366\n",
            "Train Step 300, loss: 0.36124, final_score: 0.96301, time: 457.29157\n",
            "Train Step 350, loss: 0.35468, final_score: 0.96579, time: 508.98310\n",
            "Train Step 400, loss: 0.34817, final_score: 0.96824, time: 560.27298\n",
            "Train Step 450, loss: 0.34598, final_score: 0.96890, time: 611.92743\n",
            "Train Step 500, loss: 0.34399, final_score: 0.96969, time: 663.06764\n",
            "Train Step 550, loss: 0.34247, final_score: 0.97014, time: 714.46248\n",
            "Train Step 600, loss: 0.34056, final_score: 0.97068, time: 766.03350\n",
            "Train Step 650, loss: 0.33792, final_score: 0.97173, time: 817.71023\n",
            "Train Step 700, loss: 0.33521, final_score: 0.97269, time: 869.37578\n",
            "Train Step 750, loss: 0.33432, final_score: 0.97289, time: 920.80785\n",
            "Train Step 800, loss: 0.33203, final_score: 0.97366, time: 972.32708\n",
            "Train Step 850, loss: 0.33050, final_score: 0.97417, time: 1023.88730\n",
            "Train Step 900, loss: 0.33040, final_score: 0.97421, time: 1075.52495\n",
            "Train Step 950, loss: 0.33002, final_score: 0.97440, time: 1127.22216\n",
            "Train Step 1000, loss: 0.32942, final_score: 0.97460, time: 1178.87880\n",
            "Train Step 1050, loss: 0.32741, final_score: 0.97527, time: 1230.41131\n",
            "Train Step 1100, loss: 0.32675, final_score: 0.97548, time: 1281.96718\n",
            "Train Step 1150, loss: 0.32512, final_score: 0.97610, time: 1333.36557\n",
            "Train Step 1200, loss: 0.32437, final_score: 0.97633, time: 1384.80062\n",
            "Train Step 1250, loss: 0.32281, final_score: 0.97682, time: 1436.54636\n",
            "Train Step 1300, loss: 0.32122, final_score: 0.97737, time: 1488.07252\n",
            "Train Step 1350, loss: 0.32010, final_score: 0.97779, time: 1539.98610\n",
            "Train Step 1400, loss: 0.31966, final_score: 0.97790, time: 1591.74166\n",
            "Train Step 1450, loss: 0.31926, final_score: 0.97807, time: 1643.68167\n",
            "Train Step 1500, loss: 0.31856, final_score: 0.97826, time: 1695.54179\n",
            "Train Step 1550, loss: 0.31708, final_score: 0.97875, time: 1747.24074\n",
            "Train Step 1600, loss: 0.31631, final_score: 0.97901, time: 1798.85795\n",
            "Train Step 1650, loss: 0.31635, final_score: 0.97894, time: 1850.48001\n",
            "Train Step 1700, loss: 0.31544, final_score: 0.97920, time: 1902.43657\n",
            "Train Step 1750, loss: 0.31468, final_score: 0.97940, time: 1954.21068\n",
            "Train Step 1800, loss: 0.31439, final_score: 0.97950, time: 2006.29937\n",
            "Train Step 1850, loss: 0.31385, final_score: 0.97973, time: 2058.01552\n",
            "Train Step 1900, loss: 0.31338, final_score: 0.97993, time: 2109.84440\n",
            "Train Step 1950, loss: 0.31279, final_score: 0.98009, time: 2161.52416\n",
            "Train Step 2000, loss: 0.31245, final_score: 0.98022, time: 2213.10101\n",
            "Train Step 2050, loss: 0.31204, final_score: 0.98036, time: 2264.95371\n",
            "Train Step 2100, loss: 0.31163, final_score: 0.98049, time: 2316.80271\n",
            "Train Step 2150, loss: 0.31118, final_score: 0.98058, time: 2368.55198\n",
            "Train Step 2200, loss: 0.31089, final_score: 0.98068, time: 2420.48665\n",
            "Train Step 2250, loss: 0.30999, final_score: 0.98096, time: 2472.39876\n",
            "Train Step 2300, loss: 0.30974, final_score: 0.98102, time: 2524.05419\n",
            "[RESULT]: Train. Epoch: 0, loss: 0.30947, final_score: 0.98111, time: 2561.62316\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04492\n",
            "Valid Step 50, loss: 0.45006, final_score: 0.95625, time: 59.37578\n",
            "[RESULT]: Validation. Epoch: 0, loss: 0.45466, final_score: 0.95247, time: 99.24068\n",
            "\n",
            "2020-05-04T17:36:41.308890\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.87386\n",
            "Train Step 50, loss: 0.31293, final_score: 0.98053, time: 52.19552\n",
            "Train Step 100, loss: 0.30277, final_score: 0.98346, time: 103.73965\n",
            "Train Step 150, loss: 0.29949, final_score: 0.98393, time: 155.16630\n",
            "Train Step 200, loss: 0.29830, final_score: 0.98442, time: 206.59688\n",
            "Train Step 250, loss: 0.29589, final_score: 0.98496, time: 258.08602\n",
            "Train Step 300, loss: 0.29044, final_score: 0.98656, time: 309.53231\n",
            "Train Step 350, loss: 0.29310, final_score: 0.98585, time: 361.21536\n",
            "Train Step 400, loss: 0.29141, final_score: 0.98633, time: 412.85508\n",
            "Train Step 450, loss: 0.28982, final_score: 0.98687, time: 464.57073\n",
            "Train Step 500, loss: 0.29105, final_score: 0.98650, time: 516.45296\n",
            "Train Step 550, loss: 0.28987, final_score: 0.98680, time: 568.33928\n",
            "Train Step 600, loss: 0.29074, final_score: 0.98634, time: 619.79560\n",
            "Train Step 650, loss: 0.29030, final_score: 0.98631, time: 671.42823\n",
            "Train Step 700, loss: 0.29158, final_score: 0.98606, time: 723.26909\n",
            "Train Step 750, loss: 0.29135, final_score: 0.98614, time: 774.75574\n",
            "Train Step 800, loss: 0.29070, final_score: 0.98641, time: 826.38022\n",
            "Train Step 850, loss: 0.29039, final_score: 0.98644, time: 878.02439\n",
            "Train Step 900, loss: 0.29034, final_score: 0.98650, time: 929.89079\n",
            "Train Step 950, loss: 0.29049, final_score: 0.98641, time: 981.82135\n",
            "Train Step 1000, loss: 0.29108, final_score: 0.98627, time: 1033.89977\n",
            "Train Step 1050, loss: 0.29176, final_score: 0.98614, time: 1085.75737\n",
            "Train Step 1100, loss: 0.29216, final_score: 0.98599, time: 1137.21495\n",
            "Train Step 1150, loss: 0.29243, final_score: 0.98594, time: 1188.77938\n",
            "Train Step 1200, loss: 0.29158, final_score: 0.98611, time: 1240.78199\n",
            "Train Step 1250, loss: 0.29183, final_score: 0.98596, time: 1292.75725\n",
            "Train Step 1300, loss: 0.29204, final_score: 0.98589, time: 1344.46774\n",
            "Train Step 1350, loss: 0.29193, final_score: 0.98592, time: 1396.31739\n",
            "Train Step 1400, loss: 0.29192, final_score: 0.98594, time: 1448.30803\n",
            "Train Step 1450, loss: 0.29222, final_score: 0.98591, time: 1500.12178\n",
            "Train Step 1500, loss: 0.29243, final_score: 0.98589, time: 1552.02075\n",
            "Train Step 1550, loss: 0.29220, final_score: 0.98594, time: 1604.06369\n",
            "Train Step 1600, loss: 0.29213, final_score: 0.98599, time: 1656.05157\n",
            "Train Step 1650, loss: 0.29231, final_score: 0.98597, time: 1708.04057\n",
            "Train Step 1700, loss: 0.29255, final_score: 0.98597, time: 1759.94502\n",
            "Train Step 1750, loss: 0.29195, final_score: 0.98613, time: 1811.86787\n",
            "Train Step 1800, loss: 0.29159, final_score: 0.98623, time: 1863.84753\n",
            "Train Step 1850, loss: 0.29166, final_score: 0.98617, time: 1915.93650\n",
            "Train Step 1900, loss: 0.29148, final_score: 0.98623, time: 1967.76293\n",
            "Train Step 1950, loss: 0.29090, final_score: 0.98637, time: 2019.82749\n",
            "Train Step 2000, loss: 0.29079, final_score: 0.98642, time: 2071.83670\n",
            "Train Step 2050, loss: 0.29082, final_score: 0.98639, time: 2123.64122\n",
            "Train Step 2100, loss: 0.29004, final_score: 0.98658, time: 2175.61234\n",
            "Train Step 2150, loss: 0.28984, final_score: 0.98665, time: 2227.58902\n",
            "Train Step 2200, loss: 0.28949, final_score: 0.98676, time: 2279.65391\n",
            "Train Step 2250, loss: 0.29013, final_score: 0.98659, time: 2331.64764\n",
            "Train Step 2300, loss: 0.29050, final_score: 0.98651, time: 2384.06174\n",
            "[RESULT]: Train. Epoch: 1, loss: 0.29058, final_score: 0.98648, time: 2427.53442\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04858\n",
            "Valid Step 50, loss: 0.44330, final_score: 0.95911, time: 22.61496\n",
            "[RESULT]: Validation. Epoch: 1, loss: 0.44523, final_score: 0.95650, time: 28.35599\n",
            "\n",
            "2020-05-04T18:17:37.224802\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.75165\n",
            "Train Step 50, loss: 0.26416, final_score: 0.99262, time: 51.92467\n",
            "Train Step 100, loss: 0.27299, final_score: 0.99088, time: 103.50740\n",
            "Train Step 150, loss: 0.27628, final_score: 0.99030, time: 155.05243\n",
            "Train Step 200, loss: 0.27750, final_score: 0.98981, time: 206.70986\n",
            "Train Step 250, loss: 0.27816, final_score: 0.98983, time: 258.27796\n",
            "Train Step 300, loss: 0.27922, final_score: 0.98931, time: 309.76611\n",
            "Train Step 350, loss: 0.28097, final_score: 0.98895, time: 361.04921\n",
            "Train Step 400, loss: 0.28135, final_score: 0.98893, time: 412.44446\n",
            "Train Step 450, loss: 0.28222, final_score: 0.98882, time: 463.88209\n",
            "Train Step 500, loss: 0.28114, final_score: 0.98904, time: 515.40198\n",
            "Train Step 550, loss: 0.28224, final_score: 0.98850, time: 567.01739\n",
            "Train Step 600, loss: 0.28275, final_score: 0.98855, time: 618.87824\n",
            "Train Step 650, loss: 0.28227, final_score: 0.98871, time: 670.59830\n",
            "Train Step 700, loss: 0.28476, final_score: 0.98787, time: 722.28040\n",
            "Train Step 750, loss: 0.28578, final_score: 0.98768, time: 774.04823\n",
            "Train Step 800, loss: 0.28646, final_score: 0.98756, time: 826.13989\n",
            "Train Step 850, loss: 0.28685, final_score: 0.98743, time: 877.75621\n",
            "Train Step 900, loss: 0.28638, final_score: 0.98751, time: 929.71196\n",
            "Train Step 950, loss: 0.28580, final_score: 0.98758, time: 981.66511\n",
            "Train Step 1000, loss: 0.28433, final_score: 0.98794, time: 1033.48173\n",
            "Train Step 1050, loss: 0.28406, final_score: 0.98799, time: 1085.34827\n",
            "Train Step 1100, loss: 0.28385, final_score: 0.98813, time: 1137.07452\n",
            "Train Step 1150, loss: 0.28439, final_score: 0.98806, time: 1189.04923\n",
            "Train Step 1200, loss: 0.28457, final_score: 0.98791, time: 1240.59837\n",
            "Train Step 1250, loss: 0.28488, final_score: 0.98782, time: 1292.51401\n",
            "Train Step 1300, loss: 0.28465, final_score: 0.98789, time: 1344.23372\n",
            "Train Step 1350, loss: 0.28490, final_score: 0.98785, time: 1396.03908\n",
            "Train Step 1400, loss: 0.28448, final_score: 0.98801, time: 1447.90557\n",
            "Train Step 1450, loss: 0.28451, final_score: 0.98805, time: 1500.18476\n",
            "Train Step 1500, loss: 0.28422, final_score: 0.98808, time: 1552.09611\n",
            "Train Step 1550, loss: 0.28446, final_score: 0.98801, time: 1603.79828\n",
            "Train Step 1600, loss: 0.28453, final_score: 0.98801, time: 1655.65210\n",
            "Train Step 1650, loss: 0.28415, final_score: 0.98807, time: 1707.60745\n",
            "Train Step 1700, loss: 0.28417, final_score: 0.98801, time: 1759.53869\n",
            "Train Step 1750, loss: 0.28454, final_score: 0.98791, time: 1811.40234\n",
            "Train Step 1800, loss: 0.28475, final_score: 0.98784, time: 1863.32700\n",
            "Train Step 1850, loss: 0.28507, final_score: 0.98773, time: 1914.97625\n",
            "Train Step 1900, loss: 0.28476, final_score: 0.98779, time: 1967.12709\n",
            "Train Step 1950, loss: 0.28457, final_score: 0.98786, time: 2019.14979\n",
            "Train Step 2000, loss: 0.28428, final_score: 0.98788, time: 2071.42615\n",
            "Train Step 2050, loss: 0.28385, final_score: 0.98798, time: 2123.31717\n",
            "Train Step 2100, loss: 0.28368, final_score: 0.98801, time: 2175.50050\n",
            "Train Step 2150, loss: 0.28369, final_score: 0.98800, time: 2227.68828\n",
            "Train Step 2200, loss: 0.28373, final_score: 0.98795, time: 2279.52692\n",
            "Train Step 2250, loss: 0.28406, final_score: 0.98785, time: 2331.70731\n",
            "Train Step 2300, loss: 0.28432, final_score: 0.98780, time: 2384.01696\n",
            "[RESULT]: Train. Epoch: 2, loss: 0.28421, final_score: 0.98786, time: 2426.40250\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04751\n",
            "Valid Step 50, loss: 0.52799, final_score: 0.95200, time: 22.62193\n",
            "[RESULT]: Validation. Epoch: 2, loss: 0.52592, final_score: 0.95075, time: 28.34848\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.09278\n",
            "Train Step 50, loss: 0.33469, final_score: 0.93645, time: 115.72396\n",
            "Prediction Step 0, time: 0.06223\n",
            "Prediction Step 50, time: 27.51112\n",
            "Prediction Step 100, time: 42.60491\n",
            "Prediction Step 150, time: 57.71438\n",
            "Prediction Step 200, time: 72.83505\n",
            "Prediction Step 250, time: 87.92908\n",
            "Prediction Step 300, time: 102.99311\n",
            "Prediction Step 350, time: 118.07935\n",
            "Prediction Step 400, time: 133.14358\n",
            "Prediction Step 450, time: 148.25623\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.08656\n",
            "Train Step 50, loss: 0.29525, final_score: 0.96969, time: 51.76507\n",
            "Prediction Step 0, time: 0.05810\n",
            "Prediction Step 50, time: 15.21452\n",
            "Prediction Step 100, time: 30.37609\n",
            "Prediction Step 150, time: 45.53589\n",
            "Prediction Step 200, time: 60.70485\n",
            "Prediction Step 250, time: 75.91374\n",
            "Prediction Step 300, time: 91.12003\n",
            "Prediction Step 350, time: 106.22561\n",
            "Prediction Step 400, time: 121.33047\n",
            "Prediction Step 450, time: 136.43433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j9JlGBRl5bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu0VhhZAFuYs",
        "colab_type": "code",
        "outputId": "579aed6c-6b41-465e-abe5-a606eac190f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "submission = pd.concat([pd.read_csv(path) for path in glob('node_submissions/*.csv')]).groupby('id').mean()\n",
        "submission['toxic'].hist(bins=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f64924c3be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRr-yzJ_yVTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv(f'{ROOT_PATH}/submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARz9TllfyVVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp log.txt '/content/drive/My Drive/jigsaw2020-kaggle-public-baseline/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1oxax9JyVXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}