{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 show kaggle_runner || ( git clone https://github.com/pennz/kaggle_runner; \\\n",
    "mv kaggle_runner k && \\\n",
    "mv k/* . && mv k/.* .; \\\n",
    "pip3 install -e .; \\\n",
    "git submodule update --init; \\\n",
    "export PATH=$PWD/bin:$PATH; \\\n",
    "entry.sh &)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "make transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import kaggle_runner\n",
    "reload(kaggle_runner)\n",
    "from kaggle_runner import may_debug, logger\n",
    "from kaggle_runner.modules.ToxicSimpleNNModel import ToxicSimpleNNModel\n",
    "from kaggle_runner.kernels.Shonenkov import Shonenkov\n",
    "from kaggle_runner.callbacks import CheckGrad,_check_grad\n",
    "from kaggle_runner.metrics.meters import AverageMeter, RocAucMeter\n",
    "from kaggle_runner.losses import LabelSmoothing\n",
    "from kaggle_runner.datasets.transfomers import *\n",
    "from kaggle_runner import defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['XLA_USE_BF16'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.core import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.misc import StopAfterNBatches\n",
    "from fastai.callbacks import *\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "from fastai.text.transform import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install nltk > /dev/null\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=4, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = f'/kaggle' # for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_toxic_comments(df):\n",
    "        df = df[~df['comment_text'].isna()]\n",
    "        df = df.drop_duplicates(subset='comment_text')\n",
    "        df['toxic'] = df['toxic'].round().astype(np.int)\n",
    "\n",
    "        return df[df['toxic'] == 1].comment_text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ -f train.pkl ] || cp /kaggle/input/clean-pickle-for-jigsaw-toxicity/*pkl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    \"\"\" Global Config for this notebook \"\"\"\n",
    "    num_workers = 0  # количество воркеров для loaders\n",
    "    batch_size = 16  # bs , 8 for GPU, 16 for TPU\n",
    "    n_epochs = 2  # количество эпох для обучения\n",
    "    lr = 0.3 * 1e-5 # стартовый learning rate (внутри логика работы с мульти TPU домножает на кол-во процессов)\n",
    "    fold_number = 0  # номер фолда для обучения\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True  # выводить принты\n",
    "    verbose_step = 25  # количество шагов для вывода принта\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  # выполнять scheduler.step после вызова optimizer.step\n",
    "    validation_scheduler = True  # выполнять scheduler.step после валидации loss (например для плато)\n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='max',\n",
    "        factor=0.7,\n",
    "        patience=0,\n",
    "        verbose=False,\n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0,\n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n",
    "    # --------------------\n",
    "\n",
    "    # -------------------\n",
    "    criterion = LabelSmoothing()\n",
    "    # -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Shonenkov(torch.device(\"cpu\"), TrainGlobalConfig, metrics=None, loss_func=LabelSmoothing(), opt_func=None)\n",
    "k.run(dump_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from kaggle_runner.kernels.fastai_kernel import FastAIKernel\n",
    "from kaggle_runner.runners.trainer import GPUTrainer\n",
    "def _to_gpu(learn:Learner, k: FastAIKernel) -> Learner:\n",
    "    learn.callback_fns.append(partial(GPUTrainer, k=k))\n",
    "\n",
    "    return learn\n",
    "\n",
    "Learner.to_gpu = _to_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import pysnooper\n",
    "from functools import partial\n",
    "\n",
    "from hub.custom_fastai_callbacks.callbacks import GradientAccumulator\n",
    "def debug_train(use_dist_cb=True):\n",
    "    logger.debug(f'debug train with{\" \" if use_dist_cb else \"OUT\"} to_tpu_distributed')\n",
    "    from kaggle_runner import defaults\n",
    "    _DEBUG = defaults.DEBUG\n",
    "    #defaults.DEBUG = True\n",
    "\n",
    "    param_optimizer = list(k.model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'lr': 0., 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'lr': 0., 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    def AdamW_with_given_p(p_to_ignore, *args, **kargs):\n",
    "        kargs['lr']=TrainGlobalConfig.lr*8 #xm.xrt_world_size()\n",
    "\n",
    "        return AdamW(optimizer_grouped_parameters, *args, **kargs)\n",
    "\n",
    "    learn = k.create_learner(k, opt_func=AdamW_with_given_p,\n",
    "                             loss_func=LabelSmoothing(),\n",
    "                             wd=0.01,\n",
    "                             callback_fns=[partial(GradientClipping, clip=0.5),\n",
    "                                           partial(CSVLogger, append=True),\n",
    "                                           partial(GradientAccumulator, num_iterations=4),\n",
    "                                           partial(CheckGrad, skip_loss_step=False, batch_size=k.config.batch_size)]\n",
    "                             )\n",
    "    k.learner = learn\n",
    "\n",
    "    if use_dist_cb:\n",
    "        learn = learn.to_tpu_distributed()\n",
    "    else:\n",
    "        learn = learn.to_gpu(k)\n",
    "\n",
    "    #learn.callback_fns.append(CheckGrad)\n",
    "    #print('hello')\n",
    "    #learn.lr_find(start_lr=1e-7, end_lr=1e-2, num_it=200)\n",
    "    #learn.recorder.plot()\n",
    "    learn.fit_one_cycle(2, max_lr=3e-5)\n",
    "    #learn.fit(1, lr=4e-5) # original 0.5*e-5*8=4*e-5\n",
    "    defaults.DEBUG = _DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#debug_train(use_dist_cb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# XLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make xla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla\n",
    "import torch_xla.distributed.data_parallel as dp\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.core import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.vision import *\n",
    "from fastai.basic_train import *\n",
    "from kaggle_runner.runners.tpu_trainer import TPUDistributed, TPUFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
    "def len_parallelloader(self):\n",
    "    return len(self._loader._loader)\n",
    "pl.PerDeviceLoader.__len__ = len_parallelloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _to_tpu_distributed(learn:Learner) -> Learner:\n",
    "    learn.callback_fns.append(TPUDistributed)\n",
    "\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "Learner.to_tpu_distributed = _to_tpu_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_fn(device=torch.device(\"cpu\")):\n",
    "    #device = xm.xla_device(devkind='TPU')\n",
    "    #device=torch.device(\"xla\")\n",
    "    logger.debug(\"Device used: %s\", device)\n",
    "\n",
    "    #k.run(dump_flag=True) # it seems it cannot save right\n",
    "    #k.run(dump_flag=False)\n",
    "    #k.peek_data()\n",
    "\n",
    "    self = k\n",
    "    assert self.validation_dataset is not None\n",
    "    #assert self.learner is not None\n",
    "\n",
    "    net = k.model\n",
    "    assert net is not None\n",
    "    net.to(device)\n",
    "\n",
    "    param_optimizer = list(self.model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    #optimizer = AdamW(optimizer_grouped_parameters, lr=TrainGlobalConfig.lr*xm.xrt_world_size())\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=TrainGlobalConfig.lr*8)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        self.train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        shuffle=False, # sampler is set, so shuffle here should be False\n",
    "        sampler=BalanceClassSampler(labels=k.train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    may_debug()\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        self.validation_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "    #    sampler=validation_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        self.test_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "    #    sampler=test_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    validation_tune_loader = torch.utils.data.DataLoader(\n",
    "        self.validation_tune_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        #sampler=validation_tune_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "\n",
    "    def validation(model, device, config, val_loader, criterion):\n",
    "        model.eval()\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(val_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            if config.verbose:\n",
    "                if step % config.verbose_step == 0:\n",
    "                    logger.info(\n",
    "                        f'Valid Step {step}, loss: ' + \\\n",
    "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device, dtype=torch.long)\n",
    "                attention_masks = attention_masks.to(device, dtype=torch.long)\n",
    "                targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "                outputs = model(inputs, attention_masks)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                batch_size = inputs.size(0)\n",
    "\n",
    "                final_scores.update(targets, outputs)\n",
    "                losses.update(loss.detach().item(), batch_size)\n",
    "\n",
    "    def run_inference(model, device, config, test_loader):\n",
    "        model.eval()\n",
    "        result = {'id': [], 'toxic': []}\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(test_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            if config.verbose:\n",
    "                if step % config.verbose_step == 0:\n",
    "                    logger.info(f'Prediction Step {step}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device, dtype=torch.long)\n",
    "                attention_masks = attention_masks.to(device, dtype=torch.long)\n",
    "                outputs = model(inputs, attention_masks)\n",
    "                toxics = nn.functional.softmax(outputs, dim=1).data.cpu().numpy()[:,1]\n",
    "\n",
    "            result['id'].extend(ids.cpu().numpy())\n",
    "            result['toxic'].extend(toxics)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def train_one_epoch(model, device, config, train_loader, criterion, optimizer):\n",
    "        model.train()\n",
    "\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(train_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            if config.verbose:\n",
    "                if step % config.verbose_step == 0:\n",
    "                    logger.debug(\n",
    "                        f'Train Step {step}, bs: {batch_size}, loss: ' + \\\n",
    "                        f\"{losses.avg:.5f}, lr: {optimizer.param_groups[0]['lr']} final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, \" + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.long)\n",
    "            attention_masks = attention_masks.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs, attention_masks)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "\n",
    "            final_scores.update(targets, outputs)\n",
    "\n",
    "            losses.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            loss.backward()\n",
    "            _check_grad(optimizer)\n",
    "            #optimizer.step()\n",
    "            xm.optimizer_step(optimizer, barrier=True)\n",
    "\n",
    "        model.eval()\n",
    "        #self.save('last-checkpoint.bin')\n",
    "\n",
    "        return losses, final_scores\n",
    "\n",
    "    def run_tuning_and_inference(net, device, TrainGlobalConfig, validation_loader, train_loader):\n",
    "        for e in range(1):\n",
    "            self.optimizer.param_groups[0]['lr'] = self.config.lr*8\n",
    "\n",
    "            losses, final_scores = train_one_epoch(net, device, TrainGlobalConfig, train_loader, TrainGlobalConfig.criterion, )\n",
    "            self.log(f'[RESULT]: Tune_Train. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            t = time.time()\n",
    "            para_loader = pl.ParallelLoader(validation_loader, [self.device])\n",
    "            losses, final_scores = self.validation(para_loader.per_device_loader(self.device))\n",
    "            self.log(f'[RESULT]: Tune_Validation. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            run_inference(net, device, TrainGlobalConfig, validation_loader)\n",
    "\n",
    "    train_one_epoch(net, device, TrainGlobalConfig, train_loader, TrainGlobalConfig.criterion, optimizer)\n",
    "    losses, final_scores = validation(net, device, TrainGlobalConfig, validation_loader, TrainGlobalConfig.criterion)\n",
    "    logger.info(f\"Val results: losses={losses}, final_scores={final_scores}\")\n",
    "\n",
    "    results = run_inference(net, device, TrainGlobalConfig, validation_loader)\n",
    "    logger.info(f\"Test done, result len %d\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pysnooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pysnooper.snoop()\n",
    "def train_loop(index, *args):\n",
    "    logger.debug(\"rank: %d entered train_loop\", index)\n",
    "\n",
    "    param_optimizer = list(k.model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'lr': 4e-5, 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'lr': 4e-5, 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    def AdamW_with_given_p(p_to_ignore, *args, **kargs):\n",
    "        kargs['lr']=TrainGlobalConfig.lr*xm.xrt_world_size()\n",
    "\n",
    "        return AdamW(optimizer_grouped_parameters, *args, **kargs)\n",
    "\n",
    "    if index == 0:\n",
    "        time.sleep(1)\n",
    "    learn = k.create_learner(k, opt_func=AdamW_with_given_p,\n",
    "                             loss_func=LabelSmoothing(),\n",
    "                             wd=0.01,\n",
    "                             callback_fns=[partial(GradientClipping, clip=0.5),\n",
    "                                           ShowGraph,\n",
    "                                           partial(CSVLogger, append=True),\n",
    "                                           partial(CheckGrad, skip_loss_step=False)]\n",
    "                             ).to_tpu_distributed()\n",
    "    learn.lr_find(start_lr=1e-7, end_lr=1e-5, num_it=200)\n",
    "    learn.recorder.plot()\n",
    "    #learn.fit_one_cycle(3, max_lr=5e-6, wd=0.001)\n",
    "    learn.fit(1, lr=5e-6, wd=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS={}\n",
    "#xmp.spawn(train_loop, args=(FLAGS,),  nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_abc():\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pysnooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pysnooper.snoop()\n",
    "def _mp_fn(rank, flags, k=k):\n",
    "    device = xm.xla_device(devkind='TPU')\n",
    "    logger.debug(\"%s used for xla_device\" % device)\n",
    "    net = k.model\n",
    "    net.to(device)\n",
    "    logger.debug(\"%s used for xla_device, to device done\" % device)\n",
    "\n",
    "    train_sampler = DistributedSamplerWrapper(\n",
    "        sampler=BalanceClassSampler(labels=k.train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        k.train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        k.validation_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        k.validation_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=validation_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        k.validation_tune_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True\n",
    "    )\n",
    "    validation_tune_loader = torch.utils.data.DataLoader(\n",
    "        k.validation_tune_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=validation_tune_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        k.test_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        k.test_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=test_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "\n",
    "    logger.debug(\"rank: %d. Will create TPU Fitter\", rank)\n",
    "\n",
    "    if rank == 0:\n",
    "        time.sleep(1)\n",
    "\n",
    "    fitter = TPUFitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    fitter.fit(train_loader, validation_loader)\n",
    "    fitter.run_tuning_and_inference(test_loader, validation_tune_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    FLAGS={}\n",
    "    xmp.spawn(_mp_fn, args=(FLAGS,),  nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "output_model_file='XLMRobertaModel_tpu_trained.bin'\n",
    "torch.save(k.model.state_dict(), f\"{today}_{output_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.read_csv(path) for path in glob('node_submissions/*.csv')]).groupby('id').mean()\n",
    "submission['toxic'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f'{ROOT_PATH}/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp log.txt '/content/drive/My Drive/jigsaw2020-kaggle-public-baseline/'\n",
    "!make push_dataset"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "id,colab_type,colab,language,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
