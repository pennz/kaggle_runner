{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWF5pHpO3bEX"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "f7_Bllh93bEt",
    "lines_to_next_cell": 2,
    "outputId": "d21d7121-3dfa-423a-8323-3e0a08da3406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kaggle-runner\n",
      "Version: 0.1.6\n",
      "Summary: Run kaggle kernels, for fast model prototyping.\n",
      "Home-page: http://github.com/pennz/kaggle_runner\n",
      "Author: pennz\n",
      "Author-email: pengyuzhou.work@gmail.com\n",
      "License: MIT\n",
      "Location: /content/kaggle_runner\n",
      "Requires: slug, parse, python-logging-rabbitmq, kaggle\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 show kaggle_runner || ( git clone https://github.com/pennz/kaggle_runner; \\\n",
    "mv kaggle_runner k && \\\n",
    "pip3 install -e k;\\\n",
    "export PATH=$PWD/k/bin:$PATH; \\\n",
    "entry.sh &)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mg3zuCSx3bE9",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!python3 -c 'import torch_xla' || (curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null; \\\n",
    "                                   python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev; \\\n",
    "                                   python3 -m pip install transformers==2.5.1 > /dev/null; \\\n",
    "                                   python3 -m pip install pandarallel > /dev/null; \\\n",
    "                                   python3 -m pip install catalyst==20.4.2 > /dev/null;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9Wgilnm3bFE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['XLA_USE_BF16'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecCODkEU3bFK",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBw5JHOK3bFR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8HpmDLV3bFX"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63n9I5s03bFc"
   },
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "from fastai.text.transform import Vocab\n",
    "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_bxIOBr3bFf"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "PQAFCOlu3bFl",
    "outputId": "fed638fe-aaf5-432c-9bd8-12605cbd8052"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !python3 -m pip install nltk > /dev/null\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tz4yfcsg3bFq"
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "krJjgsvu3bFw"
   },
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-dI4yCqa3bF1",
    "outputId": "f5285cdc-22ca-4a41-a09c-b8c6fb1979e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(nb_workers=4, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "Ja1ioFcG3bF7",
    "lines_to_next_cell": 2,
    "outputId": "d0831d82-0bc9-4027-e02e-0ec6fba4f717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('__call__', <function LevelMapper.__call__ at 0x7f466f9aa0d0>), ('__init__', <function LevelMapper.__init__ at 0x7f466f9ebd90>)]\n",
      "[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x7f466f958bf8>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x7f466f958b70>)]\n",
      "[('__init__', <function BoxCoder.__init__ at 0x7f466f8f70d0>), ('decode', <function BoxCoder.decode at 0x7f466f8f7268>), ('decode_single', <function BoxCoder.decode_single at 0x7f466f8f72f0>), ('encode', <function BoxCoder.encode at 0x7f466f8f7158>), ('encode_single', <function BoxCoder.encode_single at 0x7f466f8f71e0>)]\n",
      "[('__call__', <function Matcher.__call__ at 0x7f466f8e7e18>), ('__init__', <function Matcher.__init__ at 0x7f466f8e7f28>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x7f466f8e7ea0>)]\n",
      "[('__init__', <function ImageList.__init__ at 0x7f466f8f7598>), ('to', <function ImageList.to at 0x7f466f8f7510>)]\n",
      "[('__init__', <function Timebase.__init__ at 0x7f466f818510>)]\n",
      "[('__init__', <function VideoMetaData.__init__ at 0x7f466f8187b8>)]\n"
     ]
    }
   ],
   "source": [
    "from fastai.basic_data import DataBunch\n",
    "from kaggle_runner.kernels.fastai_kernel import FastAIKernel\n",
    "from kaggle_runner import may_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErWqUgQH3bGA"
   },
   "outputs": [],
   "source": [
    "SEED = 142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rl2PW6iO3bGF"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 224\n",
    "BACKBONE_PATH = 'xlm-roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94IiMvCD3bGJ"
   },
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained(BACKBONE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ya6Mxv0G3bGO"
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = f'/kaggle' # for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sA1Da3DB3bGQ"
   },
   "outputs": [],
   "source": [
    "from kaggle_runner.utils.kernel_utils import get_obj_or_dump\n",
    "def get_pickled_data(file_path):\n",
    "    obj = get_obj_or_dump(file_path)\n",
    "\n",
    "    if obj is None:\n",
    "        #may_debug(True)\n",
    "\n",
    "        return get_obj_or_dump(f\"{ROOT_PATH}/input/clean-pickle-for-jigsaw-toxicity/{file_path}\")\n",
    "\n",
    "    return obj\n",
    "vocab = get_pickled_data(\"vocab.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tPoNUuvx3bGU",
    "lines_to_next_cell": 2
   },
   "source": [
    "if vocab is None: # vocab file read~~\n",
    "   vocab = [tokenizer.convert_ids_to_tokens(i) for i in range(tokenizer.vocab_size)]\n",
    "   get_obj_or_dump(\"vocab.pkl\", default=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jAeLvflH3bGV",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "Nej3KhiY3bGZ",
    "lines_to_next_cell": 2,
    "outputId": "771fe8cf-7736-4f26-fa57-607db4bff17a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "from random import shuffle\n",
    "import random\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLdFogcG3bGe",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "LANGS = {\n",
    "    'en': 'english',\n",
    "    'it': 'italian',\n",
    "    'fr': 'french',\n",
    "    'es': 'spanish',\n",
    "    'tr': 'turkish',\n",
    "    'ru': 'russian',\n",
    "    'pt': 'portuguese'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lcd0sZJ3bGj",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_sentences(text, lang='en'):\n",
    "    return sent_tokenize(text, LANGS.get(lang, 'english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMHg6Xvz3bGn",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def exclude_duplicate_sentences(text, lang='en'):\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in get_sentences(text, lang):\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        if sentence not in sentences:\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EizVrxLZ3bGr"
   },
   "outputs": [],
   "source": [
    "def clean_text(text, lang='en'):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[0-9\"]', '', text)\n",
    "    text = re.sub(r'#[\\S]+\\b', '', text)\n",
    "    text = re.sub(r'@[\\S]+\\b', '', text)\n",
    "    text = re.sub(r'https?\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = exclude_duplicate_sentences(text, lang)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffbjaiBH3bGu",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class NLPTransform(BasicTransform):\n",
    "    \"\"\" Transform for nlp task.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "\n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "\n",
    "        return params\n",
    "\n",
    "    def get_sentences(self, text, lang='en'):\n",
    "        return sent_tokenize(text, LANGS.get(lang, 'english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yi6VEAZB3bGy",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ShuffleSentencesTransform(NLPTransform):\n",
    "    \"\"\" Do shuffle by sentence \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = self.get_sentences(text, lang)\n",
    "        random.shuffle(sentences)\n",
    "\n",
    "        return ' '.join(sentences), lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3b2yIDOv3bG1",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ExcludeDuplicateSentencesTransform(NLPTransform):\n",
    "    \"\"\" Exclude equal sentences \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeDuplicateSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = []\n",
    "\n",
    "        for sentence in self.get_sentences(text, lang):\n",
    "            sentence = sentence.strip()\n",
    "\n",
    "            if sentence not in sentences:\n",
    "                sentences.append(sentence)\n",
    "\n",
    "        return ' '.join(sentences), lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyDSPoUF3bG4",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ExcludeNumbersTransform(NLPTransform):\n",
    "    \"\"\" exclude any numbers \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeNumbersTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'[0-9]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAbXjyV63bG8",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ExcludeHashtagsTransform(NLPTransform):\n",
    "    \"\"\" Exclude any hashtags with # \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeHashtagsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'#[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQHHd_wo3bG_",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ExcludeUsersMentionedTransform(NLPTransform):\n",
    "    \"\"\" Exclude @users \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUsersMentionedTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'@[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sv-ecgw3bHC",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ExcludeUrlsTransform(NLPTransform):\n",
    "    \"\"\" Exclude urls \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUrlsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'https?\\S+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YSO5OEp3bHF"
   },
   "outputs": [],
   "source": [
    "def get_open_subtitles():\n",
    "    df_ot = get_pickled_data(\"ot.pkl\")\n",
    "\n",
    "    if df_ot is None:\n",
    "        df_ot = pd.read_csv(f'{ROOT_PATH}/input/open-subtitles-toxic-pseudo-labeling/open-subtitles-synthesic.csv', index_col='id')[['comment_text', 'toxic', 'lang']]\n",
    "        df_ot = df_ot[~df_ot['comment_text'].isna()]\n",
    "        df_ot['comment_text'] = df_ot.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
    "        df_ot = df_ot.drop_duplicates(subset='comment_text')\n",
    "        df_ot['toxic'] = df_ot['toxic'].round().astype(np.int)\n",
    "        get_obj_or_dump(\"ot.pkl\", default=df_ot)\n",
    "\n",
    "    return df_ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Oyryrcx3bHI",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SynthesicOpenSubtitlesTransform(NLPTransform):\n",
    "    def __init__(self, always_apply=False, supliment_toxic=None, p=0.5, mix=False):\n",
    "        super(SynthesicOpenSubtitlesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "        df = get_open_subtitles()\n",
    "        self.synthesic_toxic = df[df['toxic'] == 1].comment_text.values\n",
    "        self.synthesic_non_toxic = df[df['toxic'] == 0].comment_text.values\n",
    "\n",
    "        if supliment_toxic is not None:\n",
    "            self.synthesic_toxic = np.concatenate((self.synthesic_toxic, supliment_toxic))\n",
    "        self.mix = mix\n",
    "\n",
    "        del df\n",
    "        gc.collect();\n",
    "\n",
    "\n",
    "    def _mix_both(self, texts):\n",
    "        for i in range(random.randint(0,2)):\n",
    "            texts.append(random.choice(self.synthesic_non_toxic))\n",
    "\n",
    "        for i in range(random.randint(1,3)):\n",
    "            texts.append(random.choice(self.synthesic_toxic))\n",
    "\n",
    "    def generate_synthesic_sample(self, text, toxic):\n",
    "        texts = [text]\n",
    "\n",
    "        if toxic == 0:\n",
    "            if self.mix:\n",
    "                self._mix_both(texts)\n",
    "                toxic = 1\n",
    "            else:\n",
    "                for i in range(random.randint(1,5)):\n",
    "                    texts.append(random.choice(self.synthesic_non_toxic))\n",
    "        else:\n",
    "            self._mix_both(texts)\n",
    "        random.shuffle(texts)\n",
    "\n",
    "        return ' '.join(texts), toxic\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, toxic = data\n",
    "        text, toxic = self.generate_synthesic_sample(text, toxic)\n",
    "\n",
    "        return text, toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IY_VsMfk3bHL",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose([\n",
    "        ExcludeUsersMentionedTransform(p=0.95),\n",
    "        ExcludeUrlsTransform(p=0.95),\n",
    "        ExcludeNumbersTransform(p=0.95),\n",
    "        ExcludeHashtagsTransform(p=0.95),\n",
    "        ExcludeDuplicateSentencesTransform(p=0.95),\n",
    "    ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4bTYrA1l3bHR",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_synthesic_transforms(supliment_toxic, p=0.5, mix=False):\n",
    "    return SynthesicOpenSubtitlesTransform(p=p, supliment_toxic=supliment_toxic, mix=mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjmhIsAK3bHU",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_toxic_comments(df):\n",
    "        df = df[~df['comment_text'].isna()]\n",
    "        df = df.drop_duplicates(subset='comment_text')\n",
    "        df['toxic'] = df['toxic'].round().astype(np.int)\n",
    "\n",
    "        return df[df['toxic'] == 1].comment_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nib4YbrO3bHX",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def onehot(size, target, aux=None):\n",
    "    if aux is not None:\n",
    "        vec = np.zeros(size+len(aux), dtype=np.float32)\n",
    "        vec[target] = 1.\n",
    "        vec[2:] = aux\n",
    "        vec = torch.tensor(vec, dtype=torch.float32)\n",
    "    else:\n",
    "        vec = torch.zeros(size, dtype=torch.float32)\n",
    "        vec[target] = 1.\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsNlLK4G3bHZ"
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, labels_or_ids, comment_texts, langs,\n",
    "                 severe_toxic=None, obscene=None, threat=None, insult=None, identity_hate=None,\n",
    "                 use_train_transforms=False, test=False, use_aux=True, transformers=None):\n",
    "        self.test = test\n",
    "        self.labels_or_ids = labels_or_ids\n",
    "        self.comment_texts = comment_texts\n",
    "        self.langs = langs\n",
    "        self.severe_toxic = severe_toxic\n",
    "        self.obscene = obscene\n",
    "        self.threat = threat\n",
    "        self.insult = insult\n",
    "        self.identity_hate = identity_hate\n",
    "        self.use_train_transforms = use_train_transforms\n",
    "        self.aux = None\n",
    "        assert transformers is not None\n",
    "        self.transformers = transformers\n",
    "        self.vocab = vocab\n",
    "\n",
    "        if use_aux:\n",
    "            self.aux = [self.severe_toxic, self.obscene, self.threat, self.insult, self.identity_hate]\n",
    "\n",
    "    def get_tokens(self, text):\n",
    "        encoded = self.transformers['tokenizer'].encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "\n",
    "        return encoded['input_ids'], encoded['attention_mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.comment_texts.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.comment_texts[idx]\n",
    "        lang = self.langs[idx]\n",
    "\n",
    "        if self.severe_toxic is None:\n",
    "            aux = [0., 0., 0., 0., 0.]\n",
    "        else:\n",
    "            aux = [self.severe_toxic[idx], self.obscene[idx], self.threat[idx], self.insult[idx], self.identity_hate[idx]]\n",
    "\n",
    "\n",
    "        label = self.labels_or_ids[idx]\n",
    "\n",
    "        if self.use_train_transforms and (not self.test):\n",
    "            text, _ = self.transformers['train_transforms'](data=(text, lang))['data']\n",
    "            tokens, attention_mask = self.get_tokens(str(text))\n",
    "            token_length = sum(attention_mask)\n",
    "\n",
    "            if token_length > 0.8*MAX_LENGTH:\n",
    "                text, _ = self.transformers['shuffle_transforms'](data=(text, lang))['data']\n",
    "            elif token_length < 60:\n",
    "                text, label = self.transformers['synthesic_transforms_often'](data=(text, label))['data']\n",
    "            else: # will not need to use transforms\n",
    "                #text, label = synthesic_transforms_low(data=(text, label))['data']\n",
    "                pass\n",
    "\n",
    "        # TODO add language detection and shuffle\n",
    "        # https://pypi.org/project/langdetect/\n",
    "        # if self.use_train_transforms and self.test:\n",
    "        #    text, _ = train_transforms(data=(text, lang))['data']\n",
    "        #    tokens, attention_mask = self.get_tokens(str(text))\n",
    "        #    token_length = sum(attention_mask)\n",
    "\n",
    "        #    if token_length > 0.8*MAX_LENGTH:\n",
    "        #        text, _ = shuffle_transforms(data=(text, lang))['data']\n",
    "        # to tensors\n",
    "        tokens, attention_mask = self.get_tokens(str(text))\n",
    "        tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n",
    "\n",
    "        if self.test:  # for test, return id TODO TTA\n",
    "            return [tokens, attention_mask], self.labels_or_ids[idx]\n",
    "\n",
    "        # label might be changed\n",
    "        target = onehot(2, label, aux=aux)\n",
    "\n",
    "        return [tokens, attention_mask], target\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(np.char.add(self.labels_or_ids.astype(str), self.langs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swiDMY2l3bHb"
   },
   "outputs": [],
   "source": [
    "from kaggle_runner.kernels.fastai_kernel import FastAIKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrGZycwx3bHd"
   },
   "outputs": [],
   "source": [
    "class Shonenkov(FastAIKernel):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Shonenkov, self).__init__(**kargs)\n",
    "        self.data = None\n",
    "        self.transformers = None\n",
    "        self.setup_transformers()\n",
    "\n",
    "    def build_and_set_model(self):\n",
    "        self.model = ToxicSimpleNNModel()\n",
    "\n",
    "    def set_random_seed(self):\n",
    "        seed_everything(SEED)\n",
    "\n",
    "    def setup_transformers(self):\n",
    "        if self.transformers is None:\n",
    "            supliment_toxic = None # avoid overfit\n",
    "            train_transforms = get_train_transforms();\n",
    "            synthesic_transforms_often = get_synthesic_transforms(supliment_toxic, p=0.5)\n",
    "            synthesic_transforms_low = None\n",
    "            #tokenizer = tokenizer\n",
    "            shuffle_transforms = ShuffleSentencesTransform(always_apply=True)\n",
    "\n",
    "            self.transformers = {'train_transforms': train_transforms,\n",
    "                                 'synthesic_transforms_often': synthesic_transforms_often,\n",
    "                                 'synthesic_transforms_low': synthesic_transforms_low,\n",
    "                                 'tokenizer': tokenizer, 'shuffle_transforms':\n",
    "                                 shuffle_transforms}\n",
    "\n",
    "    def prepare_train_dev_data(self):\n",
    "        df_train = get_pickled_data(\"train.pkl\")\n",
    "\n",
    "        if df_train is None:\n",
    "            df_train = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-toxicity-train-data-with-aux/train_data.csv')\n",
    "            df_train['comment_text'] = df_train.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
    "            get_obj_or_dump(\"train.pkl\", default=df_train)\n",
    "\n",
    "        #supliment_toxic = get_toxic_comments(df_train)\n",
    "        self.train_dataset = DatasetRetriever(\n",
    "            labels_or_ids=df_train['toxic'].values,\n",
    "            comment_texts=df_train['comment_text'].values,\n",
    "            langs=df_train['lang'].values,\n",
    "            severe_toxic=df_train['severe_toxic'].values,\n",
    "            obscene=df_train['obscene'].values,\n",
    "            threat=df_train['threat'].values,\n",
    "            insult=df_train['insult'].values,\n",
    "            identity_hate=df_train['identity_hate'].values,\n",
    "            use_train_transforms=True,\n",
    "            transformers=self.transformers\n",
    "        )\n",
    "        df_val = get_pickled_data(\"val.pkl\")\n",
    "\n",
    "        if df_val is None:\n",
    "            df_val = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-multilingual-toxic-comment-classification/validation.csv', index_col='id')\n",
    "            df_val['comment_text'] = df_val.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
    "            get_obj_or_dump(\"val.pkl\", default=df_val)\n",
    "\n",
    "        self.validation_tune_dataset = DatasetRetriever(\n",
    "            labels_or_ids=df_val['toxic'].values,\n",
    "            comment_texts=df_val['comment_text'].values,\n",
    "            langs=df_val['lang'].values,\n",
    "            use_train_transforms=True,\n",
    "            transformers=self.transformers\n",
    "        )\n",
    "        self.validation_dataset = DatasetRetriever(\n",
    "            labels_or_ids=df_val['toxic'].values,\n",
    "            comment_texts=df_val['comment_text'].values,\n",
    "            langs=df_val['lang'].values,\n",
    "            use_train_transforms=False,\n",
    "            transformers=self.transformers\n",
    "        )\n",
    "\n",
    "        del df_val\n",
    "#del df_val_unclean\n",
    "        gc.collect();\n",
    "\n",
    "        del df_train\n",
    "        gc.collect();\n",
    "\n",
    "    def prepare_test_data(self):\n",
    "        df_test = get_pickled_data(\"test.pkl\")\n",
    "\n",
    "        if df_test is None:\n",
    "            df_test = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-multilingual-toxic-comment-classification/test.csv', index_col='id')\n",
    "            df_test['comment_text'] = df_test.parallel_apply(lambda x: clean_text(x['content'], x['lang']), axis=1)\n",
    "            get_obj_or_dump(\"test.pkl\", default=df_test)\n",
    "\n",
    "        self.test_dataset = DatasetRetriever(\n",
    "            labels_or_ids=df_test.index.values, ## here different!!!\n",
    "            comment_texts=df_test['comment_text'].values,\n",
    "            langs=df_test['lang'].values,\n",
    "            use_train_transforms=False,\n",
    "            test=True,\n",
    "            transformers=self.transformers\n",
    "        )\n",
    "\n",
    "        del df_test\n",
    "        gc.collect();\n",
    "    def after_prepare_data_hook(self):\n",
    "        \"\"\"Put to databunch here\"\"\"\n",
    "        self.data = DataBunch.create(self.train_dataset,\n",
    "                                     self.validation_dataset,\n",
    "                                     bs=TrainGlobalConfig.batch_size,\n",
    "                                     num_workers=TrainGlobalConfig.num_workers)\n",
    "\n",
    "    def peek_data(self):\n",
    "        if self.data is not None:\n",
    "            may_debug()\n",
    "            o = self.data.one_batch()\n",
    "            print(o)\n",
    "\n",
    "            return o\n",
    "        else:\n",
    "            if self.logger is not None:\n",
    "                self.logger.error(\"peek_data failed, DataBunch is None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0U0v_7EA3bHg",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from kaggle_runner.metrics.metrics import matthews_correlation\n",
    "class RocAucMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = np.array([])\n",
    "        self.y_true_float = np.array([], dtype=np.float)\n",
    "        self.y_pred = np.array([])\n",
    "        self.score = 0\n",
    "        self.mc_score = 0\n",
    "        self.aux_part = 0\n",
    "\n",
    "    def update(self, y_true, y_pred, aux_part=0):\n",
    "        #y_true_ = y_true\n",
    "        y_true = y_true[:,:2].cpu().numpy().argmax(axis=1)\n",
    "        y_true_float = y_true.astype(np.float)\n",
    "        y_pred = nn.functional.softmax(y_pred[:,:2], dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_true_float = np.hstack((self.y_true_float, y_true_float))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        try:\n",
    "            self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred, labels=np.array([0, 1]))\n",
    "        except Exception:\n",
    "            self.score = 0\n",
    "        self.mc_score = matthews_correlation(self.y_true_float, self.y_pred)\n",
    "        self.aux_part = aux_part\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score\n",
    "    @property\n",
    "    def mc_avg(self):\n",
    "        return self.mc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj4NmKFm3bHj"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meOpcCrs3bHl",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcatLT2U3bHn",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ToxicSimpleNNModel(nn.Module):\n",
    "    def __init__(self, use_aux=True):\n",
    "        super(ToxicSimpleNNModel, self).__init__()\n",
    "        self.backbone = XLMRobertaModel.from_pretrained(BACKBONE_PATH)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        aux_len = 0\n",
    "\n",
    "        if use_aux:\n",
    "            aux_len = 5\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=self.backbone.pooler.dense.out_features*2,\n",
    "            out_features=2+aux_len,\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        bs, seq_length = input_ids.shape\n",
    "        seq_x, _ = self.backbone(input_ids=input_ids, attention_mask=attention_masks)\n",
    "        apool = torch.mean(seq_x, 1)\n",
    "        mpool, _ = torch.max(seq_x, 1)\n",
    "        x = torch.cat((apool, mpool), 1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2NkI1sW3bHs"
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imzd88o33bIB"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGfbDB5z3bID"
   },
   "outputs": [],
   "source": [
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnDl9J_d3bIF",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbxKT4Td3bII",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TPUFitter:\n",
    "\n",
    "    def __init__(self, model, device, config):\n",
    "        if not os.path.exists('node_submissions'):\n",
    "            os.makedirs('node_submissions')\n",
    "\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "        self.log_path = 'log.txt'\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=config.lr*xm.xrt_world_size())\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "\n",
    "        self.criterion = config.criterion\n",
    "        xm.master_print(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            para_loader = pl.ParallelLoader(train_loader, [self.device])\n",
    "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
    "\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            t = time.time()\n",
    "            para_loader = pl.ParallelLoader(validation_loader, [self.device])\n",
    "            losses, final_scores = self.validation(para_loader.per_device_loader(self.device))\n",
    "\n",
    "            self.log(f'[RESULT]: Validation. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=final_scores.mc_avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def run_tuning_and_inference(self, test_loader, validation_tune_loader):\n",
    "        for e in range(2):\n",
    "            self.optimizer.param_groups[0]['lr'] = self.config.lr*xm.xrt_world_size()\n",
    "            para_loader = pl.ParallelLoader(validation_tune_loader, [self.device])\n",
    "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
    "            para_loader = pl.ParallelLoader(test_loader, [self.device])\n",
    "            self.run_inference(para_loader.per_device_loader(self.device))\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(val_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    xm.master_print(\n",
    "                        f'Valid Step {step}, loss: ' + \\\n",
    "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(self.device, dtype=torch.long)\n",
    "                attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
    "                targets = targets.to(self.device, dtype=torch.float)\n",
    "\n",
    "                outputs = self.model(inputs, attention_masks)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                batch_size = inputs.size(0)\n",
    "\n",
    "                final_scores.update(targets, outputs)\n",
    "                losses.update(loss.detach().item(), batch_size)\n",
    "\n",
    "        return losses, final_scores\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(train_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    logger.info(\n",
    "                        f'Train Step {step}, bs: {batch_size}, loss: ' + \\\n",
    "                        f\"{losses.avg:.5f}, lr: {self.optimizer.param_groups[0]['lr']} final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, \" + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "\n",
    "            inputs = inputs.to(self.device, dtype=torch.long)\n",
    "            attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
    "            targets = targets.to(self.device, dtype=torch.float)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(inputs, attention_masks)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "\n",
    "\n",
    "            final_scores.update(targets, outputs)\n",
    "\n",
    "            losses.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            loss.backward()\n",
    "            _check_grad(self.optimizer)\n",
    "            logger.info(\"step: %d, loss: %f\", step, loss)\n",
    "\n",
    "            xm.optimizer_step(self.optimizer)\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "        self.model.eval()\n",
    "        self.save('last-checkpoint.bin')\n",
    "\n",
    "        return losses, final_scores\n",
    "\n",
    "    def run_inference(self, test_loader):\n",
    "        self.model.eval()\n",
    "        result = {'id': [], 'toxic': []}\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, ids) in enumerate(test_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    xm.master_print(f'Prediction Step {step}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(self.device, dtype=torch.long)\n",
    "                attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
    "                outputs = self.model(inputs, attention_masks)\n",
    "                toxics = nn.functional.softmax(outputs, dim=1).data.cpu().numpy()[:,1]\n",
    "\n",
    "            result['id'].extend(ids.cpu().numpy())\n",
    "            result['toxic'].extend(toxics)\n",
    "\n",
    "        result = pd.DataFrame(result)\n",
    "        node_count = len(glob('node_submissions/*.csv'))\n",
    "        result.to_csv(f'node_submissions/submission_{node_count}_{datetime.utcnow().microsecond}_{random.random()}.csv', index=False)\n",
    "\n",
    "    def save(self, path):\n",
    "        xm.save(self.model.state_dict(), path)\n",
    "\n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            xm.master_print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            xm.master_print(f'{message}', logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRdMTDq13bIN",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"https://github.com/pytorch/pytorch/issues/7455#issuecomment-513062631\"\"\"\n",
    "\n",
    "    def __init__(self, smoothing = 0.1, dim=-1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.cls = 2\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        if self.training:\n",
    "            pred = x[:,:2].log_softmax(dim=self.dim)\n",
    "            aux=x[:, 2:]\n",
    "\n",
    "            toxic_target = target[:,:2]\n",
    "            aux_target = target[:, 2:]\n",
    "            with torch.no_grad():\n",
    "                # smooth_toxic = pred.data.clone()\n",
    "                smooth_toxic = self.smoothing + (1-self.smoothing*2)*toxic_target\n",
    "                # smooth_toxic.scatter_(1, toxic_target.data.unsqueeze(1), self.confidence) # only for 0 1 label, put confidence to related place\n",
    "                # for 0-1, 0 -> 0.1, 1->0.9.(if 1), if zero. 0->0.9, 1->0.1\n",
    "                smooth_aux = self.smoothing + (1-self.smoothing*2)*aux_target  # only for binary cross entropy, so for lable, it is (1-smooth)*\n",
    "\n",
    "            aux_loss = torch.nn.functional.binary_cross_entropy_with_logits(aux, smooth_aux)\n",
    "\n",
    "            return torch.mean(torch.sum(-smooth_toxic * pred, dim=self.dim)) + aux_loss/3\n",
    "        else:\n",
    "            return torch.nn.functional.cross_entropy(x[:,:2], target[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KQPK1tG3bIO",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    \"\"\" Global Config for this notebook \"\"\"\n",
    "    num_workers = 0  #    loaders\n",
    "    batch_size = 16  # bs\n",
    "    n_epochs = 2  #    \n",
    "    lr = 0.5 * 1e-5 #  learning rate (     TPU   - )\n",
    "    fold_number = 0  #    \n",
    "\n",
    "    # -------------------\n",
    "    verbose = True  #  \n",
    "    verbose_step = 1  #     \n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  #  scheduler.step   optimizer.step\n",
    "    validation_scheduler = True  #  scheduler.step   loss (  )\n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='max',\n",
    "        factor=0.7,\n",
    "        patience=0,\n",
    "        verbose=False,\n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0,\n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n",
    "    # --------------------\n",
    "\n",
    "    # -------------------\n",
    "    criterion = LabelSmoothing()\n",
    "    # -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jRWjZRd3bIQ"
   },
   "outputs": [],
   "source": [
    "def test_init():\n",
    "    l = Shonenkov(loss_func=None, metrics=None)\n",
    "    assert l is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQ86CF413bIS",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/input/clean-pickle-for-jigsaw-toxicity/*pkl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROFBN4h33bIV"
   },
   "outputs": [],
   "source": [
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7bNG49v3bIZ"
   },
   "outputs": [],
   "source": [
    "from kaggle_runner import may_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "fYMCn2Gt3bIb",
    "outputId": "221aec22-4e09-4f8a-e04f-641d2f36a1db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG]2020-06-18 14:44:17,258:utils:load ot.pkl\n",
      "[DEBUG]2020-06-18 14:44:18,744:utils:None -> KernelRunningState.SAVE_SUBMISSION_DONE\n",
      "[DEBUG]2020-06-18 14:44:18,745:utils:load train.pkl\n",
      "[DEBUG]2020-06-18 14:44:23,058:utils:load val.pkl\n",
      "[DEBUG]2020-06-18 14:44:23,411:utils:state KernelRunningState.PREPARE_DATA_DONE\n",
      "[DEBUG]2020-06-18 14:44:41,782:utils:state KernelRunningState.TRAINING_DONE\n",
      "[DEBUG]2020-06-18 14:44:41,784:utils:state KernelRunningState.EVL_DEV_DONE\n",
      "[DEBUG]2020-06-18 14:44:41,785:utils:load test.pkl\n",
      "[DEBUG]2020-06-18 14:44:42,414:utils:state KernelRunningState.SAVE_SUBMISSION_DONE\n"
     ]
    }
   ],
   "source": [
    "k = Shonenkov(metrics=None, loss_func=LabelSmoothing(), opt_func=None)\n",
    "k.run(dump_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0ienNqm3bId"
   },
   "outputs": [],
   "source": [
    "def _check_grad(raw_opt):\n",
    "    pg = raw_opt.param_groups\n",
    "    pg0pl = pg[0]['params'] # pg0pl[0] is a Parameter\n",
    "    pg1pl = pg[1]['params'] # pg0pl[0] is a Parameter\n",
    "\n",
    "    #logger.debug(\"grad info: %s\", raw_opt)\n",
    "\n",
    "    norms = torch.tensor([torch.norm(p) for p in pg0pl])\n",
    "    normsg = torch.tensor([torch.norm(p.grad) for p in pg0pl if p.grad is not None])\n",
    "    logger.debug(\"params info pg0: norm std(%f) mean(%f)\", *torch.std_mean(norms))\n",
    "    logger.debug(\"grad info pg0: norm std(%f) mean(%f)\", *torch.std_mean(normsg))\n",
    "\n",
    "    norms1 = torch.tensor([torch.norm(p) for p in pg1pl])\n",
    "    norms1g = torch.tensor([torch.norm(p.grad) for p in pg1pl if p.grad is not None])\n",
    "    logger.debug(\"params info pg1: norm std(%f) mean(%f)\", *torch.std_mean(norms1))\n",
    "    logger.debug(\"grad info pg1: norm std(%f) mean(%f)\", *torch.std_mean(norms1g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sul01z663bIf",
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from kaggle_runner import logger\n",
    "\n",
    "def test_model_fn(device=torch.device(\"cpu\")):\n",
    "    #device = xm.xla_device(devkind='TPU')\n",
    "    device=torch.device(\"xla\")\n",
    "    logger.debug(\"Device used: %s\", device)\n",
    "\n",
    "    #k.run(dump_flag=True) # it seems it cannot save right\n",
    "    #k.run(dump_flag=False)\n",
    "    #k.peek_data()\n",
    "\n",
    "    self = k\n",
    "    assert self.validation_dataset is not None\n",
    "    #assert self.learner is not None\n",
    "\n",
    "    net = k.model\n",
    "    assert net is not None\n",
    "    net.to(device)\n",
    "\n",
    "    param_optimizer = list(self.model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    #optimizer = AdamW(optimizer_grouped_parameters, lr=TrainGlobalConfig.lr*xm.xrt_world_size())\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=TrainGlobalConfig.lr*8)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        self.train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        shuffle=False, # sampler is set, so shuffle here should be False\n",
    "        sampler=BalanceClassSampler(labels=k.train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    may_debug()\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        self.validation_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "    #    sampler=validation_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        self.test_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "    #    sampler=test_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    validation_tune_loader = torch.utils.data.DataLoader(\n",
    "        self.validation_tune_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        #sampler=validation_tune_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "\n",
    "    def validation(model, device, config, val_loader, criterion):\n",
    "        model.eval()\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(val_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            if config.verbose:\n",
    "                if step % config.verbose_step == 0:\n",
    "                    logger.info(\n",
    "                        f'Valid Step {step}, loss: ' + \\\n",
    "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device, dtype=torch.long)\n",
    "                attention_masks = attention_masks.to(device, dtype=torch.long)\n",
    "                targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "                outputs = model(inputs, attention_masks)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                batch_size = inputs.size(0)\n",
    "\n",
    "                final_scores.update(targets, outputs)\n",
    "                losses.update(loss.detach().item(), batch_size)\n",
    "\n",
    "    def run_inference(model, device, config, test_loader):\n",
    "        model.eval()\n",
    "        result = {'id': [], 'toxic': []}\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(test_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            if config.verbose:\n",
    "                if step % config.verbose_step == 0:\n",
    "                    logger.info(f'Prediction Step {step}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device, dtype=torch.long)\n",
    "                attention_masks = attention_masks.to(device, dtype=torch.long)\n",
    "                outputs = model(inputs, attention_masks)\n",
    "                toxics = nn.functional.softmax(outputs, dim=1).data.cpu().numpy()[:,1]\n",
    "\n",
    "            result['id'].extend(ids.cpu().numpy())\n",
    "            result['toxic'].extend(toxics)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def train_one_epoch(model, device, config, train_loader, criterion, optimizer):\n",
    "        model.train()\n",
    "\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "        t = time.time()\n",
    "\n",
    "        for step, (inputs_masks, targets) in enumerate(train_loader):\n",
    "            inputs=inputs_masks[0]\n",
    "            attention_masks=inputs_masks[1]\n",
    "\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            if config.verbose:\n",
    "                if step % config.verbose_step == 0:\n",
    "                    logger.debug(\n",
    "                        f'Train Step {step}, bs: {batch_size}, loss: ' + \\\n",
    "                        f\"{losses.avg:.5f}, lr: {optimizer.param_groups[0]['lr']} final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, \" + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.long)\n",
    "            attention_masks = attention_masks.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs, attention_masks)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "\n",
    "            final_scores.update(targets, outputs)\n",
    "\n",
    "            losses.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            loss.backward()\n",
    "            _check_grad(optimizer)\n",
    "            #optimizer.step()\n",
    "            xm.optimizer_step(optimizer, barrier=True)\n",
    "\n",
    "        model.eval()\n",
    "        #self.save('last-checkpoint.bin')\n",
    "\n",
    "        return losses, final_scores\n",
    "\n",
    "    def run_tuning_and_inference(net, device, TrainGlobalConfig, validation_loader, train_loader):\n",
    "        for e in range(1):\n",
    "            self.optimizer.param_groups[0]['lr'] = self.config.lr*8\n",
    "\n",
    "            losses, final_scores = train_one_epoch(net, device, TrainGlobalConfig, train_loader, TrainGlobalConfig.criterion, )\n",
    "            self.log(f'[RESULT]: Tune_Train. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            t = time.time()\n",
    "            para_loader = pl.ParallelLoader(validation_loader, [self.device])\n",
    "            losses, final_scores = self.validation(para_loader.per_device_loader(self.device))\n",
    "            self.log(f'[RESULT]: Tune_Validation. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, mc_score: {final_scores.mc_avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            run_inference(net, device, TrainGlobalConfig, validation_loader)\n",
    "\n",
    "    train_one_epoch(net, device, TrainGlobalConfig, train_loader, TrainGlobalConfig.criterion, optimizer)\n",
    "    losses, final_scores = validation(net, device, TrainGlobalConfig, validation_loader, TrainGlobalConfig.criterion)\n",
    "    logger.info(f\"Val results: losses={losses}, final_scores={final_scores}\")\n",
    "\n",
    "    results = run_inference(net, device, TrainGlobalConfig, validation_loader)\n",
    "    logger.info(f\"Test done, result len %d\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDtvtHma3bIh"
   },
   "outputs": [],
   "source": [
    "from kaggle_runner import defaults\n",
    "_DEBUG = defaults.DEBUG\n",
    "defaults.DEBUG = True\n",
    "#test_model_fn()\n",
    "defaults.DEBUG = _DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kl5LAGTl3bIi"
   },
   "outputs": [],
   "source": [
    "#k.learner\n",
    "#k.learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-54VVqb3bIn"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.distributed.data_parallel as dp\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch\n",
    "\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.core import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.vision import *\n",
    "from fastai.basic_train import *\n",
    "from kaggle_runner import logger\n",
    "\n",
    "def len_parallelloader(self):\n",
    "    return len(self._loader._loader)\n",
    "pl.PerDeviceLoader.__len__ = len_parallelloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnvcfuzd3bIp"
   },
   "outputs": [],
   "source": [
    "class CheckGrad(LearnerCallback):\n",
    "    def __init__(self, learn:Learner, skip_loss_step=False):\n",
    "        super().__init__(learn)\n",
    "        self.skip_loss_step = skip_loss_step\n",
    "        logger.debug(\"Callback CheckGrad skip_loss_step: \" +str(self.skip_loss_step))\n",
    "\n",
    "    def on_backward_end(self, **kwargs:Any)->None:\n",
    "        raw_opt = self.learn.opt.opt\n",
    "        _check_grad(raw_opt)\n",
    "\n",
    "        return {'skip_step': self.skip_loss_step}\n",
    "\n",
    "class TPUDistributed(LearnerCallback):\n",
    "    def __init__(self, learn:Learner, debug=True):\n",
    "        super().__init__(learn)\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        if debug:\n",
    "            self.device = xm.xla_device(devkind='TPU')\n",
    "            logger.debug(\"TPUDistributed in DEBUG mode\")\n",
    "            #self.device = xm.xla_device(devkind='CPU')\n",
    "        else:\n",
    "            self.device = xm.xla_device(devkind='TPU')\n",
    "        logger.debug(\"%s used for xla_device for TPUDistributed\" % self.device)\n",
    "\n",
    "    def _change_dl(self,dl, shuffle):\n",
    "        old_dl = dl\n",
    "        train_sampler = DistributedSamplerWrapper(\n",
    "            sampler=BalanceClassSampler(labels=k.train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "            num_replicas=xm.xrt_world_size(),\n",
    "            rank=xm.get_ordinal(),\n",
    "            shuffle=True\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            k.train_dataset,\n",
    "            batch_size=TrainGlobalConfig.batch_size,\n",
    "            sampler=train_sampler,\n",
    "            pin_memory=False,\n",
    "            drop_last=True,\n",
    "            num_workers=TrainGlobalConfig.num_workers,\n",
    "        )\n",
    "        new_dl = train_loader\n",
    "\n",
    "        return old_dl,new_dl,train_sampler\n",
    "\n",
    "    def _change_dl_val(self,dl, shuffle):\n",
    "        old_dl = dl\n",
    "        validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "            k.validation_dataset,\n",
    "            num_replicas=xm.xrt_world_size(),\n",
    "            rank=xm.get_ordinal(),\n",
    "            shuffle=False\n",
    "        )\n",
    "        validation_loader = torch.utils.data.DataLoader(\n",
    "            k.validation_dataset,\n",
    "            batch_size=TrainGlobalConfig.batch_size,\n",
    "            sampler=validation_sampler,\n",
    "            pin_memory=False,\n",
    "            drop_last=False,\n",
    "            num_workers=TrainGlobalConfig.num_workers\n",
    "        )\n",
    "\n",
    "        return old_dl,validation_loader,validation_sampler\n",
    "\n",
    "    def on_train_begin(self, **kwargs:Any)->None:\n",
    "        self.learn.model = self.learn.model.to(self.device)\n",
    "\n",
    "        if self.debug:\n",
    "            self.learn.opt.lr = self.learn.opt.lr\n",
    "            logger.debug(\"opt info: %s, type %s\", self.learn.opt, type(self.learn.opt))\n",
    "        else:\n",
    "            self.learn.opt.lr = self.learn.opt.lr*xm.xrt_world_size()\n",
    "        logger.debug(\"%s used for xla_device, to device done\" % self.device)\n",
    "        shuffle = self.data.train_dl.init_kwargs['shuffle'] if hasattr(self.data.train_dl, 'init_kwargs') else True\n",
    "        self.old_sampler_train_dl,self.data.train_dl,self.train_sampler = self._change_dl(self.data.train_dl, shuffle)\n",
    "\n",
    "        if hasattr(self.data, 'valid_dl') and self.data.valid_dl is not None:\n",
    "            self.old_sampler_valid_dl,self.data.valid_dl,self.valid_sampler = self._change_dl_val(self.data.valid_dl, shuffle)\n",
    "\n",
    "    def on_epoch_begin(self,**kwargs:Any)->None:\n",
    "        logger.debug(\"Epoch begins on device %s\" % self.device)\n",
    "\n",
    "        self.old_train_dl = self.data.train_dl\n",
    "        self.learn.data.train_dl = pl.ParallelLoader(self.old_train_dl, [self.device]).per_device_loader(self.device)\n",
    "        self.learn.data.train_dl.dataset = None #self.old_train_dl.dataset\n",
    "\n",
    "        if hasattr(self.data, 'valid_dl') and self.data.valid_dl is not None:\n",
    "            self.old_valid_dl = self.learn.data.valid_dl\n",
    "            self.learn.data.valid_dl = pl.ParallelLoader(self.old_valid_dl, [self.device]).per_device_loader(self.device)\n",
    "\n",
    "            self.learn.data.valid_dl.dataset = self.old_valid_dl.dataset\n",
    "            self.learn.data.valid_dl.dl = self.learn.data.valid_dl._loader._loader\n",
    "\n",
    "    def on_backward_end(self, **kwargs:Any)->None:\n",
    "        xm.optimizer_step(self.learn.opt, barrier=self.debug) # copied from https://github.com/tmabraham/fastai_tpu/blob/8b73018cf705da1a73d9be1f105a8e886051a90c/fastai_v1/tpu_distributed_fastai.py, and needed a fix\n",
    "        #may_debug(True)\n",
    "        #return {'skip_step': True}\n",
    "\n",
    "    def on_epoch_end(self,**kwargs:Any)->None:\n",
    "        self.learn.data.train_dl = self.old_train_dl\n",
    "        self.learn.data.valid_dl = self.old_valid_dl\n",
    "\n",
    "    def on_train_end(self,**kwargs:Any)->None:\n",
    "        self.learn.data.train_dl = self.old_sampler_train_dl\n",
    "        self.learn.data.valid_dl = self.old_sampler_valid_dl\n",
    "\n",
    "\n",
    "def _to_tpu_distributed(learn:Learner) -> Learner:\n",
    "  #Learner.fit = _fit_tpu\n",
    "    learn.callback_fns.append(TPUDistributed)\n",
    "\n",
    "    return learn\n",
    "\n",
    "\n",
    "Learner.to_tpu_distributed = _to_tpu_distributed\n",
    "\n",
    "def setup_food():\n",
    "    path = untar_data(URLs.FOOD)\n",
    "\n",
    "def filelist2df(path):\n",
    "    df = pd.read_csv(path, delimiter='/', header=None, names=['label', 'name'])\n",
    "    df['name'] =  df['label'].astype(str) + \"/\" + df['name'].astype(str) + \".jpg\"\n",
    "\n",
    "    return df\n",
    "\n",
    "#train_path = path/'train.txt'\n",
    "#test_path = path/'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7z7QKwF3bIr",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from fastai.callbacks.misc import StopAfterNBatches\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import pysnooper\n",
    "\n",
    "@pysnooper.snoop()\n",
    "def debug_train(use_tpu=False):\n",
    "    logger.debug(f'debug train with{\" \" if use_tpu else \"OUT\"} to_tpu_distributed')\n",
    "    from kaggle_runner import defaults\n",
    "    _DEBUG = defaults.DEBUG\n",
    "    defaults.DEBUG = True\n",
    "\n",
    "    param_optimizer = list(k.model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'lr': 0., 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'lr': 0., 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    def AdamW_with_given_p(p_to_ignore, *args, **kargs):\n",
    "        kargs['lr']=TrainGlobalConfig.lr*xm.xrt_world_size()\n",
    "\n",
    "        return AdamW(optimizer_grouped_parameters, *args, **kargs)\n",
    "\n",
    "    learn = k.create_learner(k, opt_func=AdamW_with_given_p,\n",
    "                             loss_func=LabelSmoothing(),\n",
    "                             wd=0.01,\n",
    "                             callback_fns=[partial(GradientClipping, clip=0.5),\n",
    "                                           ShowGraph,\n",
    "                                           partial(CSVLogger, append=True),\n",
    "                                           partial(CheckGrad, skip_loss_step=False)]\n",
    "                             )\n",
    "\n",
    "    if use_tpu:\n",
    "        learn = learn.to_tpu_distributed()\n",
    "\n",
    "    learn.callbacks.append(StopAfterNBatches(n_batches=200))\n",
    "    #learn.callback_fns.append(CheckGrad)\n",
    "    #print('hello')\n",
    "    #learn.lr_find(start_lr=1e-7, end_lr=1e-4, num_it=200)\n",
    "    #learn.recorder.plot()\n",
    "    learn.fit_one_cycle(1, max_lr=2e-5)\n",
    "    #learn.fit(1, lr=5e-5) # original 0.5*e-5*8=4*e-5\n",
    "    defaults.DEBUG = _DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VrJUbCYd3bIu",
    "lines_to_next_cell": 2,
    "outputId": "3dda0676-7309-467a-b5fd-6d0919ddb525"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG]2020-06-18 14:44:43,260:utils:Callback CheckGrad skip_loss_step: False\n",
      "[DEBUG]2020-06-18 14:44:59,530:utils:TPUDistributed in DEBUG mode\n",
      "[DEBUG]2020-06-18 14:45:12,535:utils:opt info: OptimWrapper over Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 1e-07\n",
      "    weight_decay: 0.01\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 1e-07\n",
      "    weight_decay: 0.0\n",
      ").\n",
      "True weight decay: True, type <class 'fastai.callback.OptimWrapper'>\n",
      "[DEBUG]2020-06-18 14:45:12,536:utils:xla:1 used for xla_device, to device done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='199' class='' max='18548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.07% [199/18548 05:20<8:12:02 1.1524]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG]2020-06-18 14:46:05,115:utils:Epoch begins on device xla:1\n",
      "[DEBUG]2020-06-18 14:46:33,269:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:46:33,289:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:46:33,295:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:46:33,297:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:47:26,378:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:47:26,381:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:47:26,386:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:47:26,387:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:29,245:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:29,247:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:29,254:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:29,255:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:30,231:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:30,233:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:30,238:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:30,240:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:31,120:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:31,122:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:31,127:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:31,129:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:32,015:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:32,017:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:32,023:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:32,024:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:32,886:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:32,888:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:32,893:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:32,895:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:33,850:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:33,852:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:33,858:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:33,859:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:34,739:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:34,741:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:34,746:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:34,747:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:35,608:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:35,611:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:35,616:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:35,617:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:36,496:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:36,498:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:36,504:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:36,505:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:37,438:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:37,440:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:37,447:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:37,449:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:38,341:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:38,343:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:38,349:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:38,350:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:39,239:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:39,241:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:39,247:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:39,248:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:40,113:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:40,115:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:40,121:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:40,123:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:41,066:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:41,068:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:41,073:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:41,075:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:41,933:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:41,935:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:41,940:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:41,942:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:42,816:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:42,818:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:42,825:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:42,826:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:43,699:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:43,701:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:43,707:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:43,708:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:44,647:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:44,649:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:44,654:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:44,656:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:45,515:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:45,517:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:45,523:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:45,524:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:46,390:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:46,392:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:46,397:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:46,399:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:47,260:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:47,262:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:47,267:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:47,268:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:48,213:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:48,216:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:48,221:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:48,222:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:49,099:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:49,101:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:49,106:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:49,107:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:49,967:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:49,969:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:49,974:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:49,976:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:50,836:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:50,838:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:50,843:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:50,844:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:51,757:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:51,759:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:51,765:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:51,767:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:52,624:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:52,626:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:52,631:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:52,633:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:53,491:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:53,493:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:53,499:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:53,500:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:54,361:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:54,363:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:54,370:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:54,371:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:55,300:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:55,302:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:55,307:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:55,308:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:56,173:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:56,175:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:56,182:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:56,184:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:57,062:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:57,064:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:57,071:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:57,072:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:57,942:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:57,944:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:57,950:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:57,951:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:58,883:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:58,885:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:58,890:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:58,891:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:59,755:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:48:59,757:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:48:59,763:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:48:59,764:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:00,628:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:00,630:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:00,635:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:00,636:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:01,499:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:01,501:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:01,507:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:01,508:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:02,440:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:02,442:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:02,448:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:02,449:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:03,311:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:03,313:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:03,318:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:03,320:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:04,181:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:04,183:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:04,188:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:04,189:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:05,054:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:05,056:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:05,062:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:05,063:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:05,996:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:05,998:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:06,004:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:06,005:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:06,867:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:06,869:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:06,876:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:06,877:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:07,750:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:07,752:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:07,757:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:07,759:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:08,625:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:08,628:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:08,633:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:08,634:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:09,571:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:09,573:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:09,578:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:09,579:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:10,452:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:10,454:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:10,460:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:10,461:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:11,330:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:11,332:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:11,339:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:11,341:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:12,217:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:12,219:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:12,226:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:12,227:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:13,205:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:13,207:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:13,212:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:13,213:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:14,081:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:14,083:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:14,088:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:14,089:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:14,948:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:14,950:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:14,955:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:14,956:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:15,815:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:15,817:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:15,823:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:15,825:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:16,779:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:16,781:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:16,787:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:16,788:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:17,657:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:17,659:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:17,665:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:17,666:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:18,529:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:18,531:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:18,537:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:18,538:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:19,400:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:19,402:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:19,408:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:19,410:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:20,341:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:20,343:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:20,349:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:20,350:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:21,213:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:21,215:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:21,221:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:21,222:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:22,083:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:22,086:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:22,091:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:22,092:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:22,955:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:22,957:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:22,963:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:22,964:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:23,909:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:23,911:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:23,916:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:23,917:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:24,781:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:24,784:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:24,789:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:24,790:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:25,650:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:25,652:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:25,657:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:25,659:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:26,525:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:26,527:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:26,532:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:26,534:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:27,465:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:27,467:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:27,474:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:27,475:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:28,334:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:28,336:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:28,341:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:28,343:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:29,206:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:29,208:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:29,214:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:29,215:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:30,078:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:30,080:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:30,087:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:30,088:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:31,024:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:31,026:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:31,033:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:31,035:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:31,904:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:31,906:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:31,911:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:31,912:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:32,775:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:32,777:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:32,782:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:32,784:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:33,646:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:33,648:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:33,653:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:33,655:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:34,587:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:34,589:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:34,595:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:34,596:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:35,457:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:35,460:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:35,465:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:35,466:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:36,326:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:36,328:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:36,333:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:36,335:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:37,198:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:37,200:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:37,205:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:37,207:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:38,135:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:38,137:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:38,142:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:38,144:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:39,005:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:39,007:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:39,013:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:39,015:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:39,884:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:39,886:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:39,892:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:39,893:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:40,763:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:40,765:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:40,771:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:40,772:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:41,723:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:41,725:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:41,730:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:41,732:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:42,597:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:42,599:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:42,605:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:42,606:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:43,474:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:43,476:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:43,482:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:43,483:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:44,342:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:44,344:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:44,349:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:44,350:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:45,295:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:45,297:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:45,302:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:45,303:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:46,165:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:46,167:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:46,172:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:46,174:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:47,051:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:47,053:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:47,059:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:47,060:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:47,927:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:47,929:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:47,935:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:47,936:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:48,863:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:48,865:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:48,870:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:48,871:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:49,735:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:49,737:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:49,742:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:49,744:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:50,610:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:50,612:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:50,617:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:50,618:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:51,480:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:51,482:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:51,488:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:51,489:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:52,405:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:52,407:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:52,413:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:52,414:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:53,281:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:53,283:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:53,289:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:53,290:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:54,150:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:54,152:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:54,158:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:54,159:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:55,017:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:55,019:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:55,025:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:55,026:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:56,008:utils:params info pg0: norm std(212.603439) mean(76.284592)\n",
      "[DEBUG]2020-06-18 14:49:56,010:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:56,015:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:56,017:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:56,875:utils:params info pg0: norm std(212.531738) mean(76.278465)\n",
      "[DEBUG]2020-06-18 14:49:56,877:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:56,882:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:56,884:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:57,745:utils:params info pg0: norm std(212.531723) mean(76.278412)\n",
      "[DEBUG]2020-06-18 14:49:57,747:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:57,752:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:57,754:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:58,628:utils:params info pg0: norm std(212.531708) mean(76.278381)\n",
      "[DEBUG]2020-06-18 14:49:58,630:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:58,636:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:58,637:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:59,595:utils:params info pg0: norm std(212.531693) mean(76.278381)\n",
      "[DEBUG]2020-06-18 14:49:59,597:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:49:59,603:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:49:59,604:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:00,465:utils:params info pg0: norm std(212.531662) mean(76.278366)\n",
      "[DEBUG]2020-06-18 14:50:00,467:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:00,473:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:00,474:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:01,345:utils:params info pg0: norm std(212.531662) mean(76.278336)\n",
      "[DEBUG]2020-06-18 14:50:01,347:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:01,355:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:01,357:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:02,222:utils:params info pg0: norm std(212.531662) mean(76.278313)\n",
      "[DEBUG]2020-06-18 14:50:02,223:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:02,229:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:02,230:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:03,174:utils:params info pg0: norm std(212.531570) mean(76.278252)\n",
      "[DEBUG]2020-06-18 14:50:03,177:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:03,183:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:03,185:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:04,059:utils:params info pg0: norm std(212.531494) mean(76.278214)\n",
      "[DEBUG]2020-06-18 14:50:04,061:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:04,066:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:04,067:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:04,928:utils:params info pg0: norm std(212.531494) mean(76.278206)\n",
      "[DEBUG]2020-06-18 14:50:04,930:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:04,935:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:04,936:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:05,797:utils:params info pg0: norm std(212.531494) mean(76.278206)\n",
      "[DEBUG]2020-06-18 14:50:05,799:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:05,804:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:05,805:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:06,743:utils:params info pg0: norm std(212.531494) mean(76.278198)\n",
      "[DEBUG]2020-06-18 14:50:06,745:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:06,750:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:06,752:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:07,623:utils:params info pg0: norm std(212.531494) mean(76.278198)\n",
      "[DEBUG]2020-06-18 14:50:07,625:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:07,630:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:07,632:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:08,502:utils:params info pg0: norm std(212.531494) mean(76.278191)\n",
      "[DEBUG]2020-06-18 14:50:08,504:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:08,509:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:08,511:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:09,383:utils:params info pg0: norm std(212.531494) mean(76.278191)\n",
      "[DEBUG]2020-06-18 14:50:09,385:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:09,392:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:09,394:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:10,326:utils:params info pg0: norm std(212.531448) mean(76.278175)\n",
      "[DEBUG]2020-06-18 14:50:10,328:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:10,335:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:10,336:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:11,209:utils:params info pg0: norm std(212.531433) mean(76.278160)\n",
      "[DEBUG]2020-06-18 14:50:11,211:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:11,217:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:11,218:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:12,094:utils:params info pg0: norm std(212.531418) mean(76.278137)\n",
      "[DEBUG]2020-06-18 14:50:12,096:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:12,101:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:12,103:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:12,992:utils:params info pg0: norm std(212.531387) mean(76.278099)\n",
      "[DEBUG]2020-06-18 14:50:12,994:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:13,000:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:13,002:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:13,971:utils:params info pg0: norm std(212.531372) mean(76.278069)\n",
      "[DEBUG]2020-06-18 14:50:13,973:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:13,978:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:13,980:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:14,847:utils:params info pg0: norm std(212.531372) mean(76.278069)\n",
      "[DEBUG]2020-06-18 14:50:14,849:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:14,854:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:14,856:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:15,719:utils:params info pg0: norm std(212.531372) mean(76.278030)\n",
      "[DEBUG]2020-06-18 14:50:15,721:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:15,727:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:15,728:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:16,591:utils:params info pg0: norm std(212.531372) mean(76.278023)\n",
      "[DEBUG]2020-06-18 14:50:16,593:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:16,599:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:16,600:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:17,536:utils:params info pg0: norm std(212.531372) mean(76.278008)\n",
      "[DEBUG]2020-06-18 14:50:17,538:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:17,544:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:17,545:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:18,406:utils:params info pg0: norm std(212.531372) mean(76.278000)\n",
      "[DEBUG]2020-06-18 14:50:18,408:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:18,414:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:18,415:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:19,279:utils:params info pg0: norm std(212.531357) mean(76.277969)\n",
      "[DEBUG]2020-06-18 14:50:19,281:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:19,287:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:19,288:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:20,155:utils:params info pg0: norm std(212.531357) mean(76.277946)\n",
      "[DEBUG]2020-06-18 14:50:20,158:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:20,163:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:20,165:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:21,104:utils:params info pg0: norm std(212.531357) mean(76.277931)\n",
      "[DEBUG]2020-06-18 14:50:21,106:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:21,112:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:21,114:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:21,974:utils:params info pg0: norm std(212.531357) mean(76.277901)\n",
      "[DEBUG]2020-06-18 14:50:21,976:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:21,981:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:21,983:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:22,850:utils:params info pg0: norm std(212.531357) mean(76.277893)\n",
      "[DEBUG]2020-06-18 14:50:22,852:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:22,857:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:22,858:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:23,720:utils:params info pg0: norm std(212.531357) mean(76.277878)\n",
      "[DEBUG]2020-06-18 14:50:23,722:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:23,727:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:23,728:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:24,648:utils:params info pg0: norm std(212.531128) mean(76.277824)\n",
      "[DEBUG]2020-06-18 14:50:24,650:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:24,656:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:24,657:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:25,521:utils:params info pg0: norm std(212.530884) mean(76.277771)\n",
      "[DEBUG]2020-06-18 14:50:25,523:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:25,528:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:25,529:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:26,393:utils:params info pg0: norm std(212.530884) mean(76.277740)\n",
      "[DEBUG]2020-06-18 14:50:26,395:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:26,400:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:26,401:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:27,263:utils:params info pg0: norm std(212.530884) mean(76.277733)\n",
      "[DEBUG]2020-06-18 14:50:27,266:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:27,271:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:27,272:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:28,225:utils:params info pg0: norm std(212.530884) mean(76.277733)\n",
      "[DEBUG]2020-06-18 14:50:28,227:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:28,232:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:28,233:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:29,098:utils:params info pg0: norm std(212.530884) mean(76.277718)\n",
      "[DEBUG]2020-06-18 14:50:29,100:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:29,106:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:29,107:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:29,970:utils:params info pg0: norm std(212.530884) mean(76.277718)\n",
      "[DEBUG]2020-06-18 14:50:29,972:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:29,978:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:29,979:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:30,849:utils:params info pg0: norm std(212.530884) mean(76.277710)\n",
      "[DEBUG]2020-06-18 14:50:30,851:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:30,856:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:30,858:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:31,793:utils:params info pg0: norm std(212.530884) mean(76.277702)\n",
      "[DEBUG]2020-06-18 14:50:31,795:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:31,800:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:31,802:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:32,667:utils:params info pg0: norm std(212.530838) mean(76.277664)\n",
      "[DEBUG]2020-06-18 14:50:32,669:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:32,675:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:32,676:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:33,548:utils:params info pg0: norm std(212.530838) mean(76.277664)\n",
      "[DEBUG]2020-06-18 14:50:33,550:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:33,556:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:33,557:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:34,429:utils:params info pg0: norm std(212.530838) mean(76.277664)\n",
      "[DEBUG]2020-06-18 14:50:34,431:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:34,436:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:34,438:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:35,360:utils:params info pg0: norm std(212.530838) mean(76.277664)\n",
      "[DEBUG]2020-06-18 14:50:35,362:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:35,369:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:35,370:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:36,248:utils:params info pg0: norm std(212.530838) mean(76.277657)\n",
      "[DEBUG]2020-06-18 14:50:36,250:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:36,255:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:36,257:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:37,117:utils:params info pg0: norm std(212.530838) mean(76.277657)\n",
      "[DEBUG]2020-06-18 14:50:37,119:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:37,125:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:37,126:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:37,987:utils:params info pg0: norm std(212.530853) mean(76.277641)\n",
      "[DEBUG]2020-06-18 14:50:37,989:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:37,995:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:37,997:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:38,922:utils:params info pg0: norm std(212.530624) mean(76.277565)\n",
      "[DEBUG]2020-06-18 14:50:38,924:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:38,930:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:38,931:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:39,802:utils:params info pg0: norm std(212.530624) mean(76.277550)\n",
      "[DEBUG]2020-06-18 14:50:39,804:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:39,810:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:39,811:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:40,674:utils:params info pg0: norm std(212.530624) mean(76.277527)\n",
      "[DEBUG]2020-06-18 14:50:40,676:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:40,681:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:40,683:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:41,551:utils:params info pg0: norm std(212.530624) mean(76.277504)\n",
      "[DEBUG]2020-06-18 14:50:41,553:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:41,559:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:41,560:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:42,478:utils:params info pg0: norm std(212.530640) mean(76.277466)\n",
      "[DEBUG]2020-06-18 14:50:42,480:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:42,485:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:42,487:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:43,349:utils:params info pg0: norm std(212.530640) mean(76.277435)\n",
      "[DEBUG]2020-06-18 14:50:43,351:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:43,357:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:43,358:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:44,230:utils:params info pg0: norm std(212.530609) mean(76.277420)\n",
      "[DEBUG]2020-06-18 14:50:44,232:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:44,237:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:44,239:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:45,115:utils:params info pg0: norm std(212.530609) mean(76.277397)\n",
      "[DEBUG]2020-06-18 14:50:45,117:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:45,123:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:45,124:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:46,075:utils:params info pg0: norm std(212.530609) mean(76.277367)\n",
      "[DEBUG]2020-06-18 14:50:46,077:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:46,082:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:46,084:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:46,948:utils:params info pg0: norm std(212.530624) mean(76.277344)\n",
      "[DEBUG]2020-06-18 14:50:46,950:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:46,956:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:46,957:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:47,816:utils:params info pg0: norm std(212.530624) mean(76.277290)\n",
      "[DEBUG]2020-06-18 14:50:47,818:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:47,823:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:47,825:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:48,689:utils:params info pg0: norm std(212.530518) mean(76.277191)\n",
      "[DEBUG]2020-06-18 14:50:48,691:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:48,697:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:48,699:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:49,633:utils:params info pg0: norm std(212.530518) mean(76.277184)\n",
      "[DEBUG]2020-06-18 14:50:49,635:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:49,642:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:49,644:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:50,522:utils:params info pg0: norm std(212.530502) mean(76.277161)\n",
      "[DEBUG]2020-06-18 14:50:50,525:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:50,531:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:50,533:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:51,412:utils:params info pg0: norm std(212.530502) mean(76.277153)\n",
      "[DEBUG]2020-06-18 14:50:51,414:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:51,419:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:51,421:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:52,284:utils:params info pg0: norm std(212.530502) mean(76.277122)\n",
      "[DEBUG]2020-06-18 14:50:52,286:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:52,292:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:52,294:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:53,225:utils:params info pg0: norm std(212.530502) mean(76.277084)\n",
      "[DEBUG]2020-06-18 14:50:53,227:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:53,233:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:53,234:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:54,097:utils:params info pg0: norm std(212.530502) mean(76.277046)\n",
      "[DEBUG]2020-06-18 14:50:54,100:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:54,105:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:54,106:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:54,974:utils:params info pg0: norm std(212.530502) mean(76.277008)\n",
      "[DEBUG]2020-06-18 14:50:54,976:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:54,981:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:54,983:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:55,847:utils:params info pg0: norm std(212.528931) mean(76.276848)\n",
      "[DEBUG]2020-06-18 14:50:55,849:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:55,855:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:55,857:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:56,827:utils:params info pg0: norm std(212.528931) mean(76.276802)\n",
      "[DEBUG]2020-06-18 14:50:56,830:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:56,836:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:56,838:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:57,712:utils:params info pg0: norm std(212.528885) mean(76.276726)\n",
      "[DEBUG]2020-06-18 14:50:57,714:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:57,719:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:57,721:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:58,589:utils:params info pg0: norm std(212.528885) mean(76.276703)\n",
      "[DEBUG]2020-06-18 14:50:58,591:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:58,597:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:58,598:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:59,471:utils:params info pg0: norm std(212.528885) mean(76.276642)\n",
      "[DEBUG]2020-06-18 14:50:59,473:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:50:59,479:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:50:59,480:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:00,412:utils:params info pg0: norm std(212.528885) mean(76.276596)\n",
      "[DEBUG]2020-06-18 14:51:00,414:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:00,420:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:00,422:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:01,293:utils:params info pg0: norm std(212.528870) mean(76.276558)\n",
      "[DEBUG]2020-06-18 14:51:01,295:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:01,301:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:01,302:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:02,172:utils:params info pg0: norm std(212.528870) mean(76.276512)\n",
      "[DEBUG]2020-06-18 14:51:02,175:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:02,180:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:02,181:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:03,049:utils:params info pg0: norm std(212.528854) mean(76.276451)\n",
      "[DEBUG]2020-06-18 14:51:03,051:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:03,056:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:03,058:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:03,984:utils:params info pg0: norm std(212.528854) mean(76.276405)\n",
      "[DEBUG]2020-06-18 14:51:03,986:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:03,992:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:03,993:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:04,852:utils:params info pg0: norm std(212.528854) mean(76.276352)\n",
      "[DEBUG]2020-06-18 14:51:04,854:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:04,860:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:04,861:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:05,727:utils:params info pg0: norm std(212.527588) mean(76.276131)\n",
      "[DEBUG]2020-06-18 14:51:05,729:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:05,734:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:05,735:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:06,596:utils:params info pg0: norm std(212.527588) mean(76.276070)\n",
      "[DEBUG]2020-06-18 14:51:06,598:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:06,604:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:06,605:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:07,561:utils:params info pg0: norm std(212.527588) mean(76.276024)\n",
      "[DEBUG]2020-06-18 14:51:07,563:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:07,568:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:07,570:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:08,443:utils:params info pg0: norm std(212.527588) mean(76.276009)\n",
      "[DEBUG]2020-06-18 14:51:08,445:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:08,450:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:08,451:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:09,316:utils:params info pg0: norm std(212.527588) mean(76.275970)\n",
      "[DEBUG]2020-06-18 14:51:09,318:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:09,323:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:09,325:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:10,184:utils:params info pg0: norm std(212.527588) mean(76.275925)\n",
      "[DEBUG]2020-06-18 14:51:10,186:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:10,191:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:10,192:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:11,192:utils:params info pg0: norm std(212.527588) mean(76.275902)\n",
      "[DEBUG]2020-06-18 14:51:11,194:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:11,201:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:11,203:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:12,079:utils:params info pg0: norm std(212.527176) mean(76.275795)\n",
      "[DEBUG]2020-06-18 14:51:12,081:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:12,087:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:12,089:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:12,949:utils:params info pg0: norm std(212.527176) mean(76.275703)\n",
      "[DEBUG]2020-06-18 14:51:12,951:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:12,956:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:12,958:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:13,816:utils:params info pg0: norm std(212.527176) mean(76.275627)\n",
      "[DEBUG]2020-06-18 14:51:13,818:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:13,824:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:13,825:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:14,874:utils:params info pg0: norm std(212.527161) mean(76.275558)\n",
      "[DEBUG]2020-06-18 14:51:14,876:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:14,882:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:14,884:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:15,759:utils:params info pg0: norm std(212.527145) mean(76.275452)\n",
      "[DEBUG]2020-06-18 14:51:15,761:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:15,766:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:15,768:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:16,629:utils:params info pg0: norm std(212.527145) mean(76.275383)\n",
      "[DEBUG]2020-06-18 14:51:16,631:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:16,637:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:16,638:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:17,511:utils:params info pg0: norm std(212.527100) mean(76.275284)\n",
      "[DEBUG]2020-06-18 14:51:17,513:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:17,519:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:17,520:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:18,484:utils:params info pg0: norm std(212.527008) mean(76.275131)\n",
      "[DEBUG]2020-06-18 14:51:18,486:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:18,492:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:18,493:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:19,367:utils:params info pg0: norm std(212.526993) mean(76.275024)\n",
      "[DEBUG]2020-06-18 14:51:19,370:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:19,375:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:19,377:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:20,253:utils:params info pg0: norm std(212.526993) mean(76.274963)\n",
      "[DEBUG]2020-06-18 14:51:20,255:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:20,261:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:20,262:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:21,130:utils:params info pg0: norm std(212.526993) mean(76.274879)\n",
      "[DEBUG]2020-06-18 14:51:21,132:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:21,138:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:21,140:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:22,092:utils:params info pg0: norm std(212.526978) mean(76.274788)\n",
      "[DEBUG]2020-06-18 14:51:22,094:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:22,100:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:22,101:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:22,972:utils:params info pg0: norm std(212.526978) mean(76.274689)\n",
      "[DEBUG]2020-06-18 14:51:22,974:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:22,979:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:22,981:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:23,852:utils:params info pg0: norm std(212.526917) mean(76.274506)\n",
      "[DEBUG]2020-06-18 14:51:23,854:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:23,860:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:23,861:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:24,731:utils:params info pg0: norm std(212.526901) mean(76.274406)\n",
      "[DEBUG]2020-06-18 14:51:24,733:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:24,739:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:24,740:utils:grad info pg1: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:25,691:utils:params info pg0: norm std(212.526871) mean(76.274307)\n",
      "[DEBUG]2020-06-18 14:51:25,693:utils:grad info pg0: norm std(nan) mean(nan)\n",
      "[DEBUG]2020-06-18 14:51:25,700:utils:params info pg1: norm std(10.843114) mean(8.226699)\n",
      "[DEBUG]2020-06-18 14:51:25,701:utils:grad info pg1: norm std(nan) mean(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "CPU times: user 20min 33s, sys: 10min 28s, total: 31min 1s\n",
      "Wall time: 7min 8s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOy9eXxcd3nv/35m0azad0uW5d1x7MRJHIcshARCEpYS4BZK2NpC4VJKucAN5ba3LaXtr+3lR+l6IQSapoUSdih7gFASlmx2Em+xY8erJFv7PqPRjGa+9485ZzRaRhrJM5oZ6Xm/XnpZmu+Zma98Rudznl2MMSiKoijKcnAUegOKoihK6aIioiiKoiwbFRFFURRl2aiIKIqiKMtGRURRFEVZNq5CbyCX1NXVmfb29kJvQ1EUpWQ4cOBAvzGmfrnPX1Ui0t7ezv79+wu9DUVRlJJBRM5dyvPVnaUoiqIsGxURRVEUZdmoiCiKoijLRkVEURRFWTYqIoqiKMqyURFRFEVRlo2KiKIoirJsVESAf3z4JI+c6Cv0NhRFUUoOFRHgM4+c4ucqIoqiKEtGRQTwlTmZiMULvQ1FUZSSQ0UE8LpVRBRFUZaDigjgczuJqIgoiqIsGRURLHdWVEVEURRlqaiIoO4sRVGU5aIiQtKdNRFLFHobiqIoJYeKCFZMRN1ZiqIoS0ZFhGRMJDKlIqIoirJUVESwYiJqiSiKoiwZFRHsmIiKiKIoylJREQF8ZQ6tE1EURVkGKiIkLZFY3BCLa4aWoijKUsibiIjI/SLSKyJHMqy/RUQOichhEfmViFyZtnaniDwvIi+IyP/K1x5tvG4ngFojiqIoSySflsgDwJ0LrJ8BXmKM2Q38BXAfgIg4gf8LvALYCdwtIjvzuM+UiGhcRFEUZWnkTUSMMY8Cgwus/8oYM2T9+DjQan2/D3jBGHPaGBMFvgTcla99QtKdBRCJqjtLURRlKRRLTOSdwA+s71uAjrS1TuuxeRGRd4vIfhHZ39e3vJkgvjK1RBRFUZZDwUVERG4lKSIfWc7zjTH3GWP2GmP21tfXL2sPPnVnKYqiLAtXId9cRK4APge8whgzYD3cBaxPO6zVeixvpGIiWnCoKIqyJApmiYhIG/AN4G3GmBNpS08BW0Vko4iUAW8Cvp3PvdjuLM3OUhRFWRp5s0RE5EHgFqBORDqBjwJuAGPMvcCfArXAp0QEYMpyS02JyPuAhwAncL8x5mi+9gnqzlIURVkueRMRY8zdi6z/DvA7Gda+D3w/H/uaD5+6sxRFUZZFwQPrxYC3LPnfoJaIoijK0lARIa1OREVEURRlSaiIoNlZiqIoy0VFBHA7Hbidou4sRVGUJaIiYuHVmSKKoihLRkXEwud2akxEURRliaiIWPjKdESuoijKUlERsdARuYqiKEtHRcTC63YSiWkreEVRlKWgImKhloiiKMrSURGx8LodGlhXFEVZIioiFhpYVxRFWToqIhZaJ6IoirJ0VEQstE5EURRl6aiIWPjc6s5SFEVZKioiFr6ypDvLGFPorSiKopQMKiIWXreThIFoXGtFFEVRskVFxCI1UyS6+kQkOpXQeI+iKHkhbyIiIveLSK+IHMmwvkNEHhORSRG5Z9ba/xCRIyJyVEQ+kK89puMrW71z1j/y9UP87hcOFHobiqKsQvJpiTwA3LnA+iDwfuAT6Q+KyC7gXcA+4Erg1SKyJU97TJGas74KReRU3zjHu8cKvQ1FUVYheRMRY8yjJIUi03qvMeYpIDZr6TLgCWNM2BgzBTwCvD5f+7SxpxuGo1P5fqsVZygcpXdskimN9yiKkmOKMSZyBHixiNSKiB94JbA+32/aUOEBoHskku+3WnGGQzHiCUP/eLTQW1EUZZVRdCJijDkG/B/gR8APgWeBjD4mEXm3iOwXkf19fX3Lft/22gAAZwfCy36NYiQ6lWBsMmlddY+uPoFUFKWwFJ2IABhj/sUYc40x5mZgCDixwLH3GWP2GmP21tfXL/s9q/1uyr0uzg2Elv0axcjwxLT10T0yUcCdKIqyGilKERGRBuvfNpLxkC+uwHuyodbPuVVmiQyFpkNOF5fgqjvbH+Kr+zvysSVFUVYRrny9sIg8CNwC1IlIJ/BRwA1gjLlXRJqA/UAFkLBSeXcaY0aBr4tILcmg++8ZY4bztc90NtQGONo1shJvtWIMhdMtkexEpHcswls+9wRdwxO86opm/GV5+5goilLi5O3qYIy5e5H1bqA1w9qL87KpRWiv9fPQkW5i8QRuZ1EaaUtmKDQtIhdHIkxE4xw4N8RNW+vmPT4WT/Cuf9tP13DS9TUUjqmIKIqSkdVxpcwRG2oDTCUMF4ZXT+xgKJx0Z7XV+OkeifDAr87y1n95gtN94/Me/8TpQQ52jvCKXU3J54c0o0tRlMyoiKRhZ2id7Bnnrn/+Bbv/7CFu/JufMhKeXcpSOtjurMuay+kejfCrU/0APHFm/hKen7/Qh9sp3L2vDYBBFRFFURZARSSN9lo/AJ9+5BQHO0fY0VRO1/AEHUOlG2wfCkXxuZ201wboHonw1NmkeDyZSURO9HN1WzUt1T4gs4gMh6O85XOPp9xeiqKsTVRE0qgv9+BzOzlwbohN9QHe/7KtAIRLeM7IUDhGtd9NU6WXaDxBJJagyu+eV0T6xyd57uIoN2+rp8ZfBmQWkecujPLLFwb41Qv9ed2/oijFjYpIGnaaL8Bv39BOwJMMKIdKuBXKUDhKdaCM5kovACLwjhs30jU8QecsC+uXliDctKWOCp8bh8zM7kpneCLp4usYLF0rTVGUS0dFZBab64OUe128/upWAlZWUniylC2RKNX+MhorkiJy+boKXr6zEZjr0nr0RD9Vfje7WipxOoQqf1lGS2TEEpFzKiKKsqZREZnFH73qMr707hcR8LjwW+3hS9oSCUWp8rtprkzGOG7YXMf2xnIqvC6eOD1TRI5eGOGq9VU4HQIkq/gzWSK2iJxXEVGUNY0WAMyipcpHS1Xygmu7s0p59vpQOEZNoIymSi9/ftfl3L6zCYdD2LexhifPDs46NsoVrZWpn2sCmS2RYStj7fwqq/BXFGVpqCWyAKVuiUzFE4xMxKiyguRvv76dJis2ct3GWs70h+i1mjIaY5JB+EBZ6vnV/rIZbVPSsS2RgVCU8cnS/P9RFOXSURFZAI/LgdMhJRsTsS/0NX73nLV9G2sAUtZIOBonOpWg2j8tIrXBMgYzuLNGJ6bFRa0RRVm7qIgsgIjgdztL1hKx4xnp1oXN5esq8Jc5U3ER221V459tiUQxxsx5/vBENDUNUuMiirJ2URFZBL/HWbKWiN3yJN26sHE5HVyzoTqVoTWf4NQEyphKmNQ8knRGJmLsXFcBaJqvoqxlVEQWIVDmKl1LxLIu5hMRgOs21vB8zxhDoWia4Ey7vuznzdc/a2QixvpqH5U+N+cGV9cMFkVRskdFZBH8HmfJZmdNWxdzYyIA122qBeCps4PTgjPLEoH5q9aHw8mAfVuNn/OD2vpEUdYqKiKL4C9lS2QBdxbAzuakO+qFvvH5YyKWiMyuFYknDGORKSp8btpq/ZxfZdMgFUXJHhWRRQiUOUu2d9ZQKEqZy5FKVZ5NwOOiyu+ma2iC4XAUEajwTVst0/2zZqb5jkWSP1f53LRW+bgwHJk3+K4oyupHiw0Xwe9xlWz2UbLliRsRyXhMS5WPruEJRJKiYFerw7QbbHZMxC40rPS5SRhDNJ5gdGKKynlSiRVFWd2oiCyC3126lshgKJbRlWXTUuXj7ECIQJlrTipw0OPC7ZQ5tSJ2/Umlz43LmRSdvvGIioiirEHUnbUIAY+LUIlWZA9bzRcXoqXaR9fQBIOhuceKSKpWJB1bRKr8burLPQD0jk3mcOeKopQKeRMREblfRHpF5EiG9R0i8piITIrIPbPWPigiR0XkiIg8KCLefO1zMfwlHBMZDEczZmbZtFT5CEXjnB0IzSs4dUEPPVZrFJvhNEukwRKRPhURRVmT5NMSeQC4c4H1QeD9wCfSHxSRFuvxvcaYXYATeFOe9rgoAY+LqYQhOpUo1BaWzXA4O3cWwMWRCDXzCM6GWv+cdu/p7qz6YFLfVUQUZW2SNxExxjxKUigyrfcaY54C5uvw5wJ8IuIC/MCF/OxycezMpnCJpfkmEiZrd5bNfMduqA3QMRgmnpjOvrL7ZlX43FT4XJQ5HfSNq4goylqk6GIixpguktbJeeAiMGKM+VGm40Xk3SKyX0T29/X15Xw/9mCqUIm5tEYjMRJm/r5Z6ayrShOReY5tr/UTixsupM1SHw5H8bodeN1ORIT6co9aIoqyRik6ERGRauAuYCOwDgiIyFszHW+Muc8Ys9cYs7e+vj7n+/HZlkiJBdfna2MyH7WBMrzu5MegZh5LpL0uAMDZtILCkYkYlWn1JHUqIoqyZik6EQFuA84YY/qMMTHgG8ANhdpMwGPPFCktS2RwnjYm8yEiKWukah7Baa+1RKR/pohU+aZftz6oIqIoa5ViFJHzwItExC/JKrmXAccKtRl/as56aVkiw+GFmy+mYwfXa+YRnIZyD163g7NpM0OGwzMtkfpyD/0aE1GUNUneig1F5EHgFqBORDqBjwJuAGPMvSLSBOwHKoCEiHwA2GmMeUJEvgY8DUwBzwD35Wufi2HHREotzXe+XliZsEVkPqvF4RDaawNzLJH1Nf7Uz/XlHgZCUabiCVzOYrwvUVaCkYkYHlcyVqasHfImIsaYuxdZ7wZaM6x9lKToFBy/pzRH5NqtSaoWqRMBUoJQm8H1taHWzwu940Ay6+vC8ARXb6hOrdeXezAmKVwNFQUr6VEKzBvvfYzrNtXw53ftKvRWlBVEbxsXoWQtkXAUl0Mo9yx+n3D3vjY+9ZarU7PYZ9NeF6BjcIJ4wnCqb5zRyBR71lel1uuD2VWtG2O47ZOP8IXHzy3hN1FKgVg8wcneMX75Qn+ht6KsMCoii2BnZ5Va65PhcJQqf9mCzRdtagJlvHJ3c8b19toA0XiCC8MTHDg3BMDeWZYIsGitSM/oJC/0jvOj53qy+RWUEqJ7JELCwKm+UKoYVVkbqIgswnSxYYlZIqHooum92bKhNunuOt0f4sC5Iar9bjZaqb9A1q1P7DThZ84PkUho6/jVRFdaHdGhzuEC7kRZaVREFsHtdFDmcpRcTGQoHFs0vTdbdrdUEihz8vUDnRw4N8Q1G6pnWDj12YqIFZwfi0zxQt94TvamFAddQ9Mi8sx5FZG1hIpIFgTKSm9E7nA4d5ZIudfNm69r47uHLnC6P8Q1G2pmrHvdTsq9LnpnNWqczZm0gsWnLbeYsjqwLZG2Gj/PdqiIrCVURLLAX+YiNFlaIjIYis1b97Fc3nHTxtTAqmvS4iE2m+uDHLs4tuBrnOsPs6k+QLXfzdPnVURWE11DE9QFPVy3sYZnO4Z10uUaQkUkCwIeZ0k1YDTGpALruaK50sfrrmrB53ZyRWvlnPWr2qo41DXMVDxzt+OzAyE21ga4uq06FaBXVgddwxO0VPvY01bFYCiamgY6GonNaN6prD5URLLAX+YqqbYnE7E4UwlDhTe3kwY/9ppdfPf9N81bTLZnfRWRWILj3fNbI4mE4exAiPa6AFdvqOZUXyhVVb8cpuIJvvJUB6/4h5/zuk/9kr/6/jG9+y0gXcMTtFb5uGFzHQ6BT//sFOcHwtz88f/ivf9xQM/NKkZFJAv8Zc6SansSiSWtAbuxYq7wlTnZXB+cd+3qtqSL65kM/vDesUkisQTttf5UjcmRrtFl7+Werx7kD75+CKcDxiNT3PfoaUYnSuccrSYSCZOyRDbWBfjvL9nMl57q4O7PPs5YZIqHjvbwrWe7MMaomKxCVESyIOBxMV5SIpK0mnwr2H6itdpHXbCMZzNk5pyxMrPa6wJc1lwBwHMXR5b1XsYYHj7ey2v3rOM777uJ37t1CwD9Ie3flStCk1NZX/D7Q5NEpxKp9jn/42Vb2doQpGt4gs+89Rr2bqjmj75xhD1//mPecO9j+dy2UgBURLKgNlDGQGj5rpeVxhaRlexhJCLsWV/FMx3zxzrsGpH22gA1gTKaK708d2HaEukanuCPv3WYyanF3YadQxOMRabYt7EWEaHOqpjv107COWFgfJK9f/kTfpxlUaid3muLiNft5IF37OML77yO23Y28ok3XMne9mpaqnwcOD+U1TlWSgcVkSyoC3oYDEVLJkA4kRKRlT29V7VVc7ovxEh4bsXy2YEQZU5Hqu38zuYKnrs4LSIPH+vhC4+f53Dn4tbJUUt8dq5LWjS1wWQCQf946Qh9MfPcxVEmYnGOdGVnKdrpvelTMluqfNy0tQ5IWp+ff+d1/PeXbMIYOD8Qnvd1lNJERSQL6ss9xBOGoUsIBK8k0zGRle2melVbMtbx1Nm5U5E7B5M+cztN+LLmCk71hVJWU49VY3KiZ/EixOcujOAQ2NFUDpCyRAbUnZUT7GabnWkFhAuRskTSRGQ+7C4Hp/pCCx6nlBYqIlmQcpeUyMyMyQK4syBZPxIoc/Lw8d45a71jkVR7FEhaEfGE4aQlGj2jyf/bEz0L15pA8k55c30w9fvVBMoQUXdWrrBFpGMoO4vhUNcI9eWeRbMBbRE50x/idN84r//UL0vmb0rJTFYiIiIBEXFY328TkdeISG7zR4uYOttdMja/JTIcjvKNpztXcksLMlEgEfG4nNy8rZ6fHu+ZE5TtGZ2c0SZ+56zg+rQlsriIHL0wmnJlATgdQo2/jP4SilsVMyeXYIlEpxI88nwfL9vRsOix5V439eUezvSP8/3DF3n6/LB2/V0FZGuJPAp4RaQF+BHwNuCBfG2q2KgrX9gS+fJTHXzoKwe5OJKd+Z9vbHfWSmZn2bzsskZ6RidTcQtIZlP1jkVoTLNE2mr8BMqcqeB6tiIyGIpycSTC5WkiAklrUS2R3HDKEpHu0QjRqczFowCPnx5gfHKKl+9szOq1N9YFONMf4smzyQQMbZFS+mQrImKMCQOvBz5ljHkDcHn+tlVcLNZg0M486h5ZuHfUShEpUGAd4Nbt9YjAT45NZ/aMTU4RiSVoqJgWEYdDuKy5IiU2PaOTuBxC/3iUgQVcHMesYPzO5plV83XlZeoayQFDoSgDoSg7msoxBi4ML3xj9OPnevC5ndy4pS6r199cH+CF3vFU7zQVkdInaxERkeuBtwDfsx5bMzMwyz0uylyOjBeps/1J3/FiQ5lWishUYdxZALVBD1etr5ohIr1WvKOhfObUw21N5ZzoGSMSizMyEUtNS0wPrveNTfKvvzzDj452A8mLlghzLJHagKek0rCLDWMMocnp7sov2V4PLOzSMsbwk2M9vHhrXdaftY11AYbCMcYnp2ip8nH0wugca+eJ0wP84PDFZf4mykqTrYh8APhD4JvGmKMisgn4r4WeICL3i0iviBzJsL5DRB4TkUkRuSft8e0i8mza16g1f71giAj1QU/GoUvnLEukWETE7jjsdRVG51+5u5kjXaMc705aDb1jSQstPbAOsKU+yGhkiqMXknGRm62U0JO9SZfWr17o5/q/fpiPfec53vsfT/Plp87z+cfP8aZr2+a0uVd31qXx7YMXuOYvf8w3n+kC4NbtyRjHQsH1oxdGuTgSydqVBbCxbrrjwTtu2kh0KpH6nNj87Y9P8KGvHGQ0osOtSoGsRMQY84gx5jXGmP9jBdj7jTHvX+RpDwB3LrA+CLwf+MSs93reGLPHGLMHuAYIA9/MZp/5pC5YNm8dQiQW54LlxupbpBX6SjFp3dl5ywqTfPf6q1spczr40pMdwLQbMN2dBbC1MXlB+eULAwDsbq2iwutKxUW+eqCTcq+Lb7z3BpqrvHzk64fxlzm55/Ztc96zrryMUDReci37i4WkRZjgi0+cx+d2cs2GapwOoXMBEfnRcz04BF6aRVDdZlN9MkNrfY2PO3c1AXAwzaVljOFEzxgTsTjfOFA8ySpKZrLNzvqiiFSISAA4AjwnIh9e6DnGmEdJCkWm9V5jzFPAQrcbLwNOGWMKPpS7vtxD31iyvcOTZ6Z/rY7B6T+yYrFEIrE4IlDmLIyI1ATKeMXuJr7+dCcT0XgqaJ6enQWwpcEWkWSGTlOFl+1N5RzuGiWRMDxyoo+XbKvn6rZqPv2Wa6j0ufnDV1xGbXCmGAHUBUorDbvY6BmdxOt24JDkhd7tdNBc6U25s/rHJ/mr7x9LWZWQdC1es6F63vORifXVflwO4dr2GtZVeqkLemb0W+sbm2TYKlb9whPntddWCZDtVWanMWYUeC3wA2AjyQytfPMm4MEVeJ9FqQt66B+f5ItPnOONn3ksJR7nrOpbl0OKSkS8LmdW89Xzxd372hiLTPHdQxfotS5Q5R7XjGOaKrwEPa7UbJHGCg+3XdbIwY5hvrK/g8FQlFsst8qulkoO/PFtvPm6tnnfr67crlovjnNQavSMRtjeVMEn37iHD9yWtPTWV/vpGAzTMRjmDfc+xn2PnuYrTyWty47BMMcuji7JlQVQ5nLw6bdewwdv22a1yqmc0aXA7gL9365u5YXecR4/nfE+VCkSshURt1UX8lrg28aYGJDXWwQRKQNeA3x1kePeLSL7RWR/X19f3vZjtz559GTyrvmUFYC0M7N2t1am7rgLzUQsjq+ssHkP122soaXKx0+P99I7NklDuXeOqIkIm+sDxOKGMpeDSp+bN13bhs/t5GPfeQ4RuHlbfep41wKWVapqXVufLIve0Ukayz289qqWlDC0Vvs43j3Gr/3zLxgYn6S50ptyPT5sJU68fGfTkt/r5TsbWV/jB2B9jX9GBpjtyvyft2/D7RQeOZG/v2klN2QrIp8BzgIB4FER2QAsv493drwCeNoYs2AXOGPMfcaYvcaYvfX19QsdeknUBcuIJwy/sETEtkDODYSp9LnZ1lBeRJZIAq+rsM0IRITrNtbw1NnBOdXq6Wy2XFqNFR5EhEq/m9df3cJELM6VrVVZT2esLbGuAsVGz1iExlnuxva6AOFonE11Ab75ezfyqt3NHDg/RCQW56GjPWyuD6Sq0JdLU4WXUDTOmBVEf757jLqgh3VVPjbUBlI3a0rxkm1g/R+NMS3GmFeaJOeAW/O8t7spElcWQL2Vnhq1JvfZFsjZgRDttX4aKjwMjE8WRZPGSCxekPTe2Vy7sYb+8SiHOkfmBNVttjYk+181pV3AfvvGdkTIqgrapjag7qzlEonFGQ7HaJx1jt52/Qb+9beu5avvuYHN9UFu3FJHdCrB5x87x2OnB3jtnpZLfu+myuR5Ty823d6UvLHYUh9UESkBsg2sV4rIJ223kYj8LUmrZKHnPAg8BmwXkU4ReaeIvEdE3mOtN4lIJ/Ah4I+tYyqstQDwcuAbl/C75RS79QlAc6V3hiWyoTZAQ7mHhGHBQrmVIhJL4CkGEWmvASAcjc+pEbGxg+vpQfctDeV87/dfzLtu3pT1e3ndTso9Lu3kuwDGGP7p4ZOp3lg2qTqeWZZIhdfNrTsaUk0z922sweUQPv7QcYIeF2+/vv2S92RbPz2jkyQShhM942xrTN5YbG4IcH4gTGyBkctK4cnW53E/MAa80foaBf51oScYY+42xjQbY9zGmFZjzL8YY+41xtxrrXdbj1cYY6qs70ettZAxptYYs7ypRXnAbn2yo6mcPeurODsQIjqVoGt4gvZaf8pSKQaXViQWx1eAavXZbK4PpCyETJaILSKNs0Rm57qKJVtTdVYGnTI/IxMx/vbHJ/i3X52d8XiPlXE12501m4DHxZ71VcTihrddv4FK/6W3z7Mt0O6RCJ1DE0zE4qnuzFsagkwlTKoOC1BRKUKyvdJsNsZ81Bhz2vr6GJD9beIqwG59cv3mWjbUBugYDPNsxzDxhGFHc0XqIpmeAlkoisWdJSLsbU9WoWeyRNpq/OzdUM2LNtVc8vttrg/wfBYNHNcqIxPJuEN6ijpMu5KaFhERSPZGC3pcvOPGjTnZk+3O6h6NpM5dyhKxRjG/0JsUkc6hMC/925/x1f1aP1JMuBY/BIAJEbnJGPMLABG5ESiOboMrRIXXzT+/+Sr2bazhp8d6icUNX93fgQhcv6mWUDQ5Ptd2DRSSyFScCl9xNFm+tr2Gh472ZAysOx3C1373hpy8166WSh4+3ktocoqAJ9uP9trBrr94vmeMwVA0lbRgt+GfHROZj3e9eCN371tPlT+7hIfF8LqdVPrcMzIbt1oisskSETsu8t1DF5lKmKw6PSsrR7Z/ae8B/l1E7K53Q8Bv5mdLxcurr1gHwIbaZDjoO4cusLulkupAGX5P8s6/pxhEJJYoSAff+Xjl7mYePz3Ila1VeX+v3S2VGJOcN2LHY5Rphiem63qfOjvIHZcn03N7RyOpFOvFcDkdORMQm6YKL90jEYbCMVqrfQStG4Cgx0VzpTfVVfi7hy4A2Q/LUlaGbLOzDhpjrgSuAK4wxlwFvDSvOyti2uuSOe6RWCLVvdTjclLtdxeFO2siGsdTBDERgHVVPj73m3tz4j9fjN0tyXucbEbsrkVG0kQk3aXVPRpJpVgXgoYKDz2jEU50j7HdskJsNtcHeaFvnNN94xzpGkWEBVuxKCvPkq40xphRO/hNMqtqTdJY7sVj1WG8OK0FdkO5tygC65NTxRETWWkaKrw0Vniyng2+1hixxjtvaQjOEJGe0cicxIaVpKki2V7ldP8425pmisiWhiCnesf57M/PAHDHziY6hya0HUoRcSm3q4XrqVFgHA5hQ60fr9uRal8OySBhMQymShYbrj0RgaQ1ckhFZF5sS+TlOxs5emEkVeDXOzq5aGZWPmmq9DIQihKLmzmWyNbGIKFonAefPM/tOxvZ217N+ORUKr6jFJ5LiT6u6VuBl+9sZHRiasYdf2u1j4OdhR+yk2x7UhzurJVGg+uZGQ7H8Jc5edGmWj79s1Mc7hzhhi119IxGUvNDCkG6gG2bJSKvu6qFcq+bTXUBdjSV85NjvUAyLjJ7HIBSGBb8KxORMeYXCwF8edlRifDhO3bMeWx9jZ/hcIyxSIxyb2Gyo2LxBPGEWdOWSDbBdWMMPz3ey63bG3A41oZRPTIRo9Ln5gordhiXD3IAACAASURBVHSwc4TLWyoJReOFtUSs93Y6hM0NM2uY/WUuXnPlutTP62uSl52OoTC7W2dOt1QKw4K3q8aYcqsYcPZXuTFGb/Nm0Vqd/IAXMntkejTu2hSRPeurEElOx1uIn53o453/tp/HFzluNTFsiUh1oIz1NT4OdQ5z4FwyNmInJRQCu1ZkY10AzyI3P63VyaQWDa4XD2vT55En1lsf8PQZIytNJGYPpFqbIlIb9LBrXeWi3V+fOZ90O3YtMkN8NWFbIgBXtFZxqHOEn5/sx+NycE1abG+lsa2g2fGQ+aj0uanwuugYXDvnrdhREckhRWWJFLiLbyF5ybZ6nj4/PCOldTb2NL1iyKZbKUbCMaqsVOsrWyvpGp7g+4cvsm9jTUEt19pAGY0VHvZtzK62p7Xar5ZIEbF2rzR5oCZQhr/MueBc6nyz1t1ZkJxBEk8YfmVNTJyNMYZDVgLEWuq1NTwRpcqXDEZfYRV/9oxO8uKtdQs9Le84HMIvPvJS3n79hqyOX1/joyOHN2oD45Opz4OydFREcoiIsL7aX2BLxHJnrWERuaqtinKPi0dPzu/S6hicYMhKES2G4tCVYmQilir63NVSiV1beNOWwmVm2bidjqyLHddblkiuakX+9NtHeevnntDak2WiIpJjWqt9hY2JTCUtkWJpe1II3E4HN26p41vPXODln3yELz15fsa6nYZd5XcXRa+zlSASixOJJVIxkaDHxeb6IHVBT6prbqmwvsZPJJbIiRU5MhHjx8/1MBqZYmxyKge7W3uoiOSY9TV+ugpYUTsRtd1Za/vUvuOmjVy/uZbu0QgPH++dsXawY5gyl4MbN9flLCbyQu84f/+TEySKYCjZfIxa8aH0/lj33L6NP3n1ZSWX4rzVGh9woufSB1b98MhFolNJ6723SMZblxpr+0qTB1qrfYxNTjE6UZi7Go2JJNm3sYb7f+tadjZXMDKruvlQ5wiXr6tgXZWXntHIJQv+891j/MZnHuPvf3KS8wW0QhfCbr5YldbD7M5dzdyVg+mEK43dGiUXbf+/+UwXLktEu0cy31AU681BMaAikmPsPPZCBdcjUxoTSafaX8bwxPS0w2MXR9l/bpDrN9XSWOFlcirBaGT5gh+LJ3jbvzzBqNVCZCBUXO6xcHSKbz7TmWoTkk2n3mKnLuihNlDGie5LE5GOwTCPnx7kNXuSxYw9GSyRw50jXPanP+RMf2je9bWOikiOsdN8CxUXmbZE9NRC8s7bDqIbY/jot49S6XPz7ps3pQaN9V1CcL1/fJLesUl+/Zr11s/FNZ73oaPdfPDLB3noaDdAKjur1NnWWH7JlshnHj2F2yn83q1bgGQ34/l4pmOIyakEj51aO4WpS0GvNDmmvS7ZtmH2HOuVQt1ZM6n0uxkJxzDG8IMj3Tx5ZpAP37GDKn9ZatripQTXB0NJ0djemPTTDxSZiPSPJfdjz+KoWoGW/CvB9qZyTvaMLdvNdGF4gi8/1cEb965nc32Qcq8rY0zkbH/yhtCuLVqMrx/onDOCeDWTNxERkftFpFdEjmRY3yEij4nIpIjcM2utSkS+JiLHReSYiFyfr33mmqDHxca6AEcvjC5+cB5QEZlJtb+MaDzBRCzOz0/2U+lz8xvXJq2G6ZHGyxeRoVDSytnSkPTTD4wXlztrwBI5e1hasUy8vFS2NZYTisaX3XHgUz97AYD3WlZIU4U3oyVyfjDpxsq2ueqX93fw+cfPLWtfpUg+LZEHgDsXWB8E3g98Yp61fwB+aIzZAVwJHMv57vLI5esqOHKhMO3IU3Uia7hiPZ0q66I5FI7RPz5Jc6UXpxVItUf2XkqtyKA1o6Op0kO515W6aBcLQ2n7cQiUr5LOxtub7Ayt5bm0fvxcD3fuaqalKul+bqzwZpxKenYgnHqvUBZpwKMTyc/aWiFvVxpjzKMkhSLTeq8x5ilgRuqMNYL3ZuBfrOOixpiSKie9fF0lnUMTc7KCVoKJWBy3U3A5VURg2n0zHI7SNzaZioNA0mr0uZ2X5M6yL9LV/jLqgp6iu3gMhqOpAWoVPnfJpfNmwp7Dvpy4SCJhGBiP0lYz3Yg8KSJzbyYSCcP5wTBbGoIkDFkNPBuZiDEcjhGLJ5a8t1KkGK80G4E+4F9F5BkR+ZyIBDIdLCLvFpH9IrK/r2/hpnsrxeXrKgA4WgBrJBKLr9k28PNhzwMfCcfoG5ukLjgtIiJCQ4XnktxZg6EoIsmsp9pAWdHFRAZDUa5qq6I2UJayylYDFV43LVU+nl9GhtbIRIyphKE2MP1ZaLQ+B7NjLN2jEaJTiVQ7+kNZjF62M+GK7bOQL4pRRFzA1cCnrVnuIeB/ZTrYGHOfMWavMWZvfX3h2zdAuoisfFwkEkus2Q6+82FbIrY7K90SgaRL61LcWUPhKJU+Ny6ng7qgp+hSfIdCUWqDHu7e18b1mwvbIyvXXNZczuFlTLG0z1Fd2mehqdJLPGHon3X+zg4k4yHXbKimtdrHs4vERaJTyfgbUHRWab4oRhHpBDqNMU9YP3+NpKiUDLVBD82V3oJYIpOxuKb3pmGntHYMhZmcSlAfnC0i3kvOzqqxrJ3aYBFaIuEotYEy7rljO3/9+t2F3k5OuaqtmtN9oRlxn2zoszLW6tImI2bK1DtnxUPaavxc0Vq5qDsrvXO0ikiBMMZ0Ax0ist166GXAcwXc0rK4fF0lRwpgiUyoO2sGtiVy0mqRUVc+s06iqdLLxZHlV60PhaOpMa21QQ+D4SjxIqlunoonGA7HqPavjtqQ2dgzUJ7pGFrS82xLpDY40xKBuQWH5wbCuJ3CuiofbTUBLgxPLJhWPJJW2FpsNUP5Ip8pvg8CjwHbRaRTRN4pIu8RkfdY600i0gl8CPhj65gK6+m/D/yHiBwC9gB/la995otdLRWc7htf8buRcZ0tPgOv24nX7eCF3qTvvD44cwxsW42fiVicvmWep8FQjBpLROqCZRiTFJZiwG51UrNKZ5Ff0VqJ0yE8fW5peTf9VgysLjj9/9JopXs/fnqAv/7BsVQHgnMDIdZX+3E6hJZqH7G4WTCGthYtkbxdbYwxdy+y3g20Zlh7Ftibj32tFL925Tr+4eGTPPDLs9xzx/bFn5AjxienKPeqiKRT7S9LFX/Ojom01U5Po7RdGkthMDSZmlluB2oHxqMzAviFwnbzrFYR8Ze52NlcwYFzS7VEojhkOukCoD7oQQQ++/MzQNK99c6bNnJuIMwG6zPSaqUDdw2HU5bLbNJFpNhqhvJF0bmzVgub64PcsbOJf3/sLOMr2GJ6LKIiMptKn5uQ1d04/e4TkpYIJN0W45NTfOKh5/mv53uZyiI90xjDUCiW5s5K/rvUi8f45BRPnhlMdZPNFQOrXEQArm6r4mDncFbny6Z/PEpNwJOqFwJwOR3sbqnk2vZqtjUG+cbTnQyGopzqG2djXbImpSWLyaW2iDhE3VlKDnjPLZsZjUzx4BPnFz84R4xHpgiqO2sGdlzE6ZA58YHWah8icH4wzENHuvnn/3qB3/7Xp3jL556Y76VmEIrGicYT1ASSr28LVP8SA733/uwUb/zMY+z9yx/zzWc6Z6wd7x5ddvbYardEAK7eUE04Guf4ElJ9+8cn59xMAHzrvTfy1ffcwJuubePohVH+51eeJRZP8Obrkh0OWlKWSGYRsdN719f414w7S0Ukj+xZX8VlzRUZJ+zlg6Q7a/XUA+QCWzjqgmVziu08LifNFV7OD4Q53DWCz+3kVVc0Z3VRSi80hGl3Vv8S606e6RhiQ62fdVU+/vZHJ1JB/njCcPd9j/OJh55f0uvZrA1LJBlcz7YlCSQtxfncjfZn4zV71uF0CP/1fB+/fk1rqqVNwOOiyu+mKwtLZGNdYM2MXlYRyTNNFZ4ZftJ8Ek8YxifVEpmNbYlkilO01fo5PxjmSNcIO9dVsLk+yGgktmiW1eCsi3Slz43TIUuqFTHGcKRrlBs21/HOmzbSOTTBQaug7fnuMYbCsVSa6VKxRW61NF2cj9ZqH4EyZyr7Lhv6x6Mp1+N81AU9vGRbPWUuBx+4bduMtZYq34KWyMhEjKDHRVOFt+ha4OQLFZE8U+UvS5m4+SYUTcZeNCYyk0qrVmR2UN2mrcbP2YEQz10cZXdLJVU+N8ZMTwPMhN03y46JOBxCTVrVesdgmB8e6V7wNToGJxiZiLG7pZLbdzbhdgrfPZjsuPvkmWTr8Ysjy3NnDYajlHtceFZxyreIsKUhuKSu2QPjkzOq1efj/3vdLr787hexrso34/GWKt/Clkg4RqXPTV3Qw2AouiaGWamI5JlKn3vFUj7HIioi81Ft3YnPLjS02VAboH88SjgaZ1dL5XS/rUVEJBVzSIuz1AbKONg5wt/84Di3ffIR3vOFAwu2ELcbde5qqaDS7+bmrfV87/BFEgnDk2eTree6RyLLuhgNhqZrWFYzWxrKOdmbXUxkIhonFI3PqReaTXOlj6ssV1k6LdVJSyRTXdHIhC0iZcQTpmjSvfOJikieqfK7GYtMLSl7ZLmMWyIS9Kxe98VySLmzMlgi660MLSBpiaQ1bVwI252VfqHe2ljOsYuj3PvIKV6yrR6Py8HXn+7M9BIc7hrB7RS2WyNfX31lMxdHIjx6so8nzwzicgjReGJOO45sGAxFV3U8xGZrY5Ce0cms3MZ2sLtuEUskEy1VPsLReEbvQkpErM/aWsjQUhHJM3bTu0sZwZotY1aBlFoiM0m5szJZIpaIeN0ONtcHUvUDi7khh8JRXA6hIu3/++/eeCVP/u+XcfjPbue+t+/ljsub+M9nLzA5FZ/3NY50jbCtsTzlcrrz8mbaa/188MvP0j8e5ZbtyX5wF4eX7tIaCq8NEdlSn0zBzcallRKRRSyRTNiTSzPFRUYmYlT53Wk1Q6s/uK4ikmfsu9TF7mpzwZhVjxJUEZlByp21QEwEYGdzBS6nIyX86bPZ52PQqhERmVlv0FDuTWXI/fo1rYxMxPjJc71znm+M4XDXCLvWVaYe85U5+eRv7EnddLz2qhYALo4sffjS4Hh01bY8SWdroy0ii7u07HjVYjGRTLRUJT8rmURk2LJE6i2RWm4nhFJCRSTPVKYNRco3dkykQkVkBle0VnH3vjZu3DJ/F9sqv5vmSi/Xbqyxfs7OEhkYn0wJVCZu3FJHU4V3Tv0HwMHOEYbDMXa1Vs54/Oq2av7wFTu4bmMNN1idd7uWYYkMhhfOQlottFb78bgcS7RElikitiWSIbhuu7Ps9jrdy0yKKCX0apNnUvMsFrmrzQUaE5kfX5lzwQ62IsJ3fv+mVGq0LcILiYgxhkOdI+xtnxt8TcfpEO64vJEv7+9IznqxxhYPh6P8/oNP01Th5VW7m+c873devInfefEmjDF4XA4uLnEM7GgkRiSWmLeobrXhdAib64OczEJELlj/j7XLdPNV+934y5x0DM1Nu47E4kSnElT63VT6k/NOllK/UqqoJZJnUq6RFbFENCayXOqCntQF3uV0UOF1LRio7RicoHs0wnWbahd97Vt2NBCJJXjizPSgzz/5z6N0j0T41FuvXjBuISK0VPm4sER3ln2xbK70LXLk6mBrYzBjrcjhzhF+cPgiDz55nk8/coqr26pS53qpiAhtNX46BueeD/tv3PY+XL2hesnNIUsRFZE8M53pM/8F6UjXCPc9eion7zU+OYUI+HUo1SVT5S9bMD3zCauG4zrLBbYQ12+qxeNy8LPnk3ERYwyPnujjdVe1pCquF6K5ysuFJbqz7ED87DqH1crWhiBdwxPz9ql7zxcO8Lv/8TR/+I3DXNVWzb/+9r5Leq/Waj8dg3MtEfumwxaRa9qq6B6NpAR9taIikmcqvG5EMtccfHV/B3/1/eM5adI4ZvXNSg/0Ksujyu9e0Hp84swgNYEytjYEF30tr9vJ9Ztr+dnzyfY3/eNRRiZi7GiqWOSZSdZV+pYcWLctl3VVS+9MXIrstKaJPjdrhs/A+CRdwxP81g3t/Mtv7uXf37EvdZFfLm01yQ4Hs2tFbBGxB6Fdbc07efr80roMlxoqInnG4RAqfe6M2Vnd1hCcM32hS36vscgUFdo3KydU+csWLDZ88swg17ZXZy3Yt25v4Ex/iLP9oVRhnJ1VtBjNVT56xybn7fKbSJh5H784HMHpkGW1ty9F7Ay32eNy7cFwt1/eyMsua1y2GyudthofE7H4nBoQ+2/cFqnLmivwuh1LblW/VM4PhDnevfID8GxURFaAKl/mu9oeaxznqb7s2zZkYiwS075ZOaLK52Ykg/BfHJng/GCY6zYuHg+xses9Hj3ZxykrALzVauy3GOsqvRgzd+oewMcfep7X/PMv5twVXxiZoLF8Zrvz1UxDhZeGcs+c8bX2z5evq5zvacvCnkFzfpZL66fHk+5KO5Xc7XRwRWsVT5/Pb1zk3kdP8dYsuk7nCxWRFaBygbvaXuvCcDoHIqIDqXJHld+d8ZztP5u8s9yXRTzEpq3GT0uVj8dPD3Cyd5xyjys1TW8x7LjGfJk+Ry+McLx7jNP9My3Zi8MRmtdIPMRmd8vcGehHukbYUOu/ZBdWOnZdUXpc5AuPn+NLT3Xw31+yacbAqqvbqnnuwgiR2PzFprlgcLywRaUqIivA7Lvagx3DnO0PkUhMj9o8lQN31vjklBYa5ogqn5uRiRgv9I7xxs88luqTBXD0wihlTkeqVUk2iAgv2lTL46cHOdEzxuaGYNausH0ba9jeWM6ffOsInbNSS+3mjI883zfr8QmaM0zfW63saqnkVN844eh0fPFw1wi7WnJnhUAysA7Tlkj/+CR//p3neMm2ev7gjh0zjt3dUkksbpbUIHKpDIQmV6eIiMj9ItIrIkcyrO8QkcdEZFJE7pm1dlZEDovIsyKyP197XCmq/e4ZxYYf/Mqz/OX3jjEYjjJlNdbLjTtL28Dniip/cl76g0928OSZwVQzRIBjF0fZ0hDE7Vzan8+LNtUwGIqy/+xQVgF5G6/byb1vu4apuOGDX352xppdzPbIiWkRMcZwcSSyZjKzbHa1VJIw08H14XCUzqGJGR0BcoHX7aSxwpMSkW8900U0nuCPX3XZHPfhFus85+LvOxMDoeiyK/BzQT4tkQeAOxdYHwTeD3wiw/qtxpg9xpiSnrUOdjv46TvZnpEIp/rGUz7u9TU+zliWyaWQHI2rgfVcYKdm/+RYDzAz6+fYxVF2NGdvhdi8yKopmUqYrIPqNhvrArzr5k08dXYolQU0GokxPjmF1+3giTMDKZfJYCjK5FRizVkiu1tmBtePdI3OeDyXpGdofWV/B3vWV7G1ce5nor3Oj0NIxcHywWCosJ0J8iYixphHSQpFpvVeY8xTwMoM2ygglT43o5Ep4gmTakV9fjCcmtV8w6Y6JqcSnOwd559/enLZ6b5jkZjGRHKELSL2QKijloj0j0/SOzbJzubs0nPTWW/FRSD7oHo6e9ZXJfdiXSRtK+RVu9cRiSV40ipmtGtK1kqhoU1jhYe6oIfPPnqat9//JB+wrLZdLUs/V4uxviZZK3Koc4QTPeO8ce/6eY/zuJxsqA3wQp4skVg8wXA4tjrdWZeIAX4kIgdE5N2F3sylYl+QRidiqd498YRJpf5dvzl5h/qBLz/LJ350gh8cvrjk94hOJZicSlCu7qycYHf+hWTx5rGLSRGx/71sGSIC09bIliW4s2zsO+pDlojYRWyvu6qFMqeDX57qTz6+xmpEbESE9926mfU1foZCUW7YXMvf/caVqdZDuaStxk/3aIQ//+5zeN0OXn3l3NY1NpvrlzY0aynYBbHLbeOSC4r1inOTMaZLRBqAH4vIccuymYMlMu8GaGtrW8k9Zo0tIkPh6IyMn8dOJaue7QuLfYF6+vwQb8hwZ5OJce3gm1PSGyv+t6tb+fzj5xgORy9ZRN52/QY8bkfKIlnSngJltFb7Uu4a2xLZWB9gc0OQ56258HafrbUWEwH4rRs38ls3bsz7+2ysC2AMnOgZ46O/dvmC9VlbGoI8cqKXqXgC1xLjaIthz7SpzTDmYCUoyiuOMabL+rdXRL4J7APmFRFjzH3AfQB79+4tylmUqa6wEzH6x6ZbQx+9MEJdsIzGCg9Vfjdel5P1Nb5lFSeNp6YaakwkF9jnrLnSy8t3NvL5x8/x3MVRjl0co7HCs2z3wZ71VSm31HJIT2O9MBJBBBrKPWxrDKZSjy+ORChzOQp6d7rauXNXE//wpj3csr1h0fThLQ1BYnHD+cEwm+qXboEuxKBV8KjurDREJCAi5fb3wO3AvBlepYLdhHEkHEtVubocQsJAQ7kXEeHj/+0KPvv2vdy8tZ4TPeNZTWlLZ9RqvqjZWbnB7uS7t71mRkuNYxdHl22F5IJdLZWcGwgzEo5xcXiChnIPbqeDbY3ldA1PMBaJcX4wzLpKr7a/ySMel5O79rRkVX9iuy7z4dLqD61id5aIPAjcAtSJSCfwUcANYIy5V0SagP1ABZAQkQ8AO4E64JvWH4AL+KIx5of52udKYN8l9I1PpmIil6+r4GDnSKrg7PbLmwAYm0yKwdPnh7i2vQaf25lV1bHtztLAem5wOR186OXbuGlrHXVBD40VHj7/+Dk6BsPcdlljwfZ1hTV75MiFEbpHI6ng+TYrM+hk7zj7zw1xw+bsq+mV/LK5PgDAC33j3J7j1x60rieFtETydsUxxty9yHo30DrP0ihwZV42VSDWVflwOoRzAyHGIlNU+txsbyq3RGRm8PPK1iqcDuFr+zv50Jef5c3XtfHhWQVM8zEWURHJNe9/2dbU97tbKvnJsV5etbuZ33lx/n3umbBrHg51jnBheCIlHtuslOGHjnbTNza5pJYsSn4p97ppqvDmxRIZDEVxCHlJHsgWveKsAG6ng7YaP2f7wxgMdcEyNtYl/+gbZolIwOPisuZyvmdlaGXbAvx5qwHbWgymrgQfu2sX7701klXr9nxSHShjZ3MFXzvQwcWRCC/Z1gDA+mo/XreDrzzVAcB1m7JvyaLkny0NwbzUivSHkiOQC9kjrehiIquV9lo/p/tD9I9FqQt62GSZuPP1T7pxSx3lHhd1QU/KwliMh4/3cmVrJXUFzNJYzbRU+QouIDbve+kWTvWFCEfjqTReh0PY2lDOUDiW/HzVBQq8SyWdLQ1BTvWF5jTKzIZzA6GMXcAL3TcLVERWjI11Qc72h+gbn6Su3MOVrVVU+txc0TI3U+ee27fzi4+8lE11AcYnFw+w949P8mzHMC/dUThfvbJy3Hl5E9stN1Z6sz+7Cv66TTUaVC8yNjcEGZ+cSo1+yJavHejktk8+wj1fPTTv+mBIRWTNsLHOz0QszrmBEPVBD02VXg5+9HZ2t85tyeB2Oqj0uwl6XYQmF+/++bPn+zAGXnZZQz62rhQZDofwodu3ATMr321hedESugsrK8OW+qVnaH3n4AXu+epBvC4nP3u+d0YTUJv+0GTBvQ8qIiuEHQNJGKjLss9N0OPKqgXKT4/30Fjh4fJ1hUs9VVaWOy5v4sAf3zajk/B1m2oJelypOIlSPCwnzffx0wNU+tx8/neuYyph+MGR7tTaYChKdCpRFJaIBtZXiPY6f+r7bO8cgl7XojERYww/P9HPK3c3qwtjjTG7SnnP+iqOfOyOAu1GWYi6YBmVPveSRKRvbJKmCi9XtlayqT7Atw928ebr2uganuAVf/8o17bXFLxvFqglsmKsq/RR5kr+d2crIuUe16IxkcmpBGOTU6lpa4qiFB8iwpaGpfXQ6h2bpL7cg4jwmivX8cSZQR47NcA9XznIaGSKh61JioXs4AsqIiuGwyFsrE1mzNSVZ2mJeFxEYgli8bkztG3C0WTMJFB26bOjFUXJH1vqg0uaK9I3NkmDda349WtaqfK5ufuzj/PY6QH+4rW7aK1OpvMXcpYIqIisKLZLK9uYSMBqYRJaIC5irwW03YmiFDVbGoL0j0czpuumY4yhb2ySeqsEoLXazy8+8lL+4q7L+fAd23nrdW3871deBsCGAnsh9MqzgmyuD+J09C4pJgLJavRMFamp7r0qIopS1KQH1/e2L5xBNzIRIxpPUJ92rQh4XLzt+vbUz6/Y3cwTf/SyOV0vVhq98qwg77xpI9dvrsXrzs71ZM8GWShDSy0RRSkNbBE53DWyqIj0Wt2+Z3e0mE2hBQTUnbWi1AY9vHhrfdbH25bIgiJix0Q8GhNRlGKmtdrHzuYKvrq/c9HK9T5bRLKMnxYSFZEixnZRjS+Q5quWiKKUBiLC3fvW89zF0dRgsUz0jiUr21VElEvC7sg7toAlYlspgTIVEUUpdu66qgWv28GDT3YseFzvaNISqVcRUS6FoCc58Cab7CwNrCtK8VPhdfNrV6zj2892MRHN3NKob2wSn9tZEn/XKiJFTComkoU7y68xEUUpCe7a00IoGufnJ/syHtM7NklDhackulCoiBQxfiuLa7Y7aywS45M/PkF0KkEoGsftFDwuFRFFKQWu21RDudfFT471ZDymdywyI723mFERKWIcDkk2YZxliXzv0EX+8eGTHOwcJjQ5pUF1RSkh3E4Ht2xv4OFjvcQThiNdI8QTM7O1+ixLpBRQESlygvP0z7IzO4ZCUcYnpzSoriglxst3NjIQivL+B5/h1f/0C/7ppydnrPeOTdJQXvgakGzIm4iIyP0i0isiRzKs7xCRx0RkUkTumWfdKSLPiMh387XHUiDondsOPiUi4ahliagrS1FKiZdsq8flEL53+CLlXhefffQ0A+PJjKxILM5YZKokMrMgv5bIA8CdC6wPAu8HPpFh/X8Ax3K8p5Ij6JnZDj46leD4xTEAhsIxwtG4urMUpcSo9Ll5y3VtvHFvK197zw1MxOL83/86BZRWei/kUUSMMY+SFIpM673GmKeAOb3ORaQVeBXwuXztr1Qon2WJnOgZI2p19bXdWaWQBqgoykw+KRJLzQAACQRJREFUdtcuPv7rV7K9qZw3XLOeLzx+ju6RCD96Ljl86op5pp4WI8UaE/l74A+AzD3QLUTk3SKyX0T29/VlTpkrVWYH1g91Jl1ZLodMu7M0JqIoJc3v3bqFuDF87uen+eIT57m6rYodTaUxqbToREREXg30GmMOZHO8MeY+Y8xeY8ze+vrs+1KVCrNH5B7uGqHC62JLQ5DBUIzQZFxrRBSlxGmr9fNrVzRz/y/PcLo/xFtftKHQW8qaohMR4EbgNSJyFvgS8FIR+UJht1Q4AmmWiDGGZzuGuaK1imp/GcPhKKGourMUZTXwu7dsIWGgyu/mlbubC72drCk6ETHG/KExptUY0w68CfipMeatBd5WwSj3uhiPTtE5FOYtn3uCYxdHuXFLHTWBsrTsLBURRSl1tjeV875bt/CRO3dkPS6iGMjb1UdEHgRuAepEpBP4KOAGMMbcKyJNwH6gAkiIyAeAncaY0XztqRQJelwYA+/74jOc7BnjL1+7izfva+NP/vMIPaOTxOJGLRFFWSXcc8f2Qm9hyeTt6mOMuXuR9W6gdZFjfgb8LHe7Kj3s/lnPdgzzkTt3pHylNYGyVKzEr/PVFUUpEEXnzlJmYlsZ/jInb97Xlno8fVyuurMURSkUKiJFjj1T5I1711Ppd6cerwlMf6/uLEVRCoWKSJGzq6WSl2yr5903b5rxeLolou4sRVEKhd7CFjkN5V7+7R375jxekyYiaokoilIo1BIpUao1JqIoShGgIlKiVGtMRFGUIkBFpEQJely4HMnRmRoTURSlUKiIlCgiQnUg6dJSd5aiKIVCRaSEqfa7cTkEj0tPo6IohUGvPiVMtb+MgMeFiBR6K4qirFFUREqYan8ZAY2HKIpSQNSZXsL85g3tdA6FC70NRVHWMCoiJcz1m2uB2kJvQ1GUNYy6sxRFUZRloyKiKIqiLBsVEUVRFGXZqIgoiqIoy0ZFRFEURVk2KiKKoijKslERURRFUZaNioiiKIqybMQYU+g95AwR6QPOFejtK4GRIni9bJ+XzXELHbPUtUzH1wH9i+wj3+Ty3OX7vGVz7HLXl/K4nrelPy9ff3OXet42GGPqF9lXZowx+pWDL+C+Yni9bJ+XzXELHbPUtUzHA/tX07nL93nL5tjlri/lcT1vuT9vix1TrOdN3Vm54ztF8nrZPi+b4xY6Zqlruf7/ySW53Fu+z1s2xy53famPF5rVdt4WO6Yoz9uqcmcppYeI7DfG7C30PpSloeetNMnHeVNLRCk09xV6A8qy0PNWmuT8vKkloiiKoiwbtUQURVGUZaMioiiKoiwbFRElJ4jI/SLSKyJHlvHca0TksIi8ICL/KGlD40Xk90XkuIgcFZGP53bXCuTn3InIn4lIl4g8a329Mvc7X9vk62/OWv+fImJEpG6x11IRUXLFA8Cdy3zup4F3AVutrzsBRORW4C7gSmPM5cAnLn2byjw8QI7PncXfGWP2WF/fv7QtKvPwAHk4byKyHrgdOJ/NC6mIKDnBGPMoMJj+mIhsFpEfisgBEfm5iOyY/TwRaQYqjDGPm2SWx78Dr7WWfxf4G2PMpPUevfn9LdYmeTp3Sp7J43n7O+APgKyyrlRElHxyH/D7xphrgHuAT81zTAvQmfZzp/UYwDbgxSLyhIg8IiLX5nW3SjqXeu4A3icihyy3S3X+tqqkcUnnTUTuArqMMQezfUPX8veqKJkRkSBwA/DVNHerZ4kv4wJqgBcB1wJfEZFNRvPS80qOzt2ngb8geTf7F8DfAu/I1R6VuVzqeRMRP/BHJF1ZWaMiouQLBzBsjNmT/qCIOIED1o/fJnmxaU07pBXosr7vBL5hicaTIpIg2UCuL58bVy793BljetKe91ngu/ncsAJc+nnbDGwEDloi1Ao8LSL7jDHdC72pouQcY8wocEZE3gAgSa40xsTTgq1/aoy5CIyKyIusDJG3A/9pvcy3gFut528Dyih859hVTy7OneV3t3kdsOQMImVpXOp5M8YcNsY0GGPajTHtJG/irl5IQEBFRMkRIvIg8BiwXUQ6ReSdwFuAd4rIQeAoyUyr+Xgv8DngBeAU8APr8fuBTVYK45eA31RXVu7J07n7uJVCeojkjcAH8/k7rEXydN6Wvg/9m1QURVGWi1oiiqIoyrJREVEURVGWjYqIoiiKsmxURBRFUZRloyKiKIqiLBsVEWVVIyLjK/x+v8rR69wiIiNWB9zjIrJo80kRea2I7MzF+ytKtqiIKMoSEJEFuzwYY27I4dv93Ko+vgp4tYjcuMjxrwVURJQVRUVEWXNk6nQqIr9mNXt8RkR+IiKN1uN/JiKfF5FfAp+3fr5fRH4mIqdF5P1prz1u/XuLtf41y5L4D3tmg4i80nrsgCRnOSzYEsQYMwE8y3STvHeJyFMiclBEvi4ifhG5AXgN8P9b1svmbDq6KsqloiKirEUydTr9BfAiY8xVJCvk/yDtOTuB24wxd1s/7wDuAPYBHxUR9zzvcxXwAeu5m4AbRcQLfAZ4hfX+9Ytt1uqAuxV41HroG8aYa40xVwLHgHcaY35Fsi/Sh632FqcW+D0VJWdoA0ZlTbFIp9NW4MtW36cy4EzaU79tWQQ237PmnEyKSC/QyMz22gBPGmM6rfd9FmgHxoHTxhj7tR8E3p1huy+22ldsBf4+rYfRLhH5S6AKCAIPLfH3VJScoSKirDXm7XRq8U/AJ40x3xaRW4A/S1sLzTp2Mu37OPP/LWVzzEL83BjzahHZCDwuIl8xxjxLcqLda40xB0Xkt4Bb5nnuQr+nouQMdWcpa4pMnU6t5Uqm29D/Zp628DzJppLt1s+/sdgTLKvlb4CPWA+VAxctF9pb0g4ds9YW+z0VJWeoiCirHb/V4dT++hCZO53+GUn3zwHy1HLecom9F/ih9T5jwEgWT70XuNkSnz8BngB+CRxPO+ZLwIetxIDNZN/RVVGWjXbxVZQVRkSCxphxK1vr/wInjTF/V+h9KcpyUEtEUVaed1mB9v/Xjh0TAQDDQAwrfwYBVj4dysBLFglBNt/nnv9Cm+V7ILNEAMgsEQAyEQEgExEAMhEBIBMRALIHOH5W/ZsVeIcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "debug_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4MbjVEVm3bIw"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pysnooper\n",
    "\n",
    "@pysnooper.snoop()\n",
    "def train_loop(index, *args):\n",
    "  #data = (ImageList.from_df(df=train_df, path=path/'images', cols=1)\n",
    "  #        .random_split_by_pct(0.2)\n",
    "  #        .label_from_df(cols=0)\n",
    "  #        .transform(get_transforms(), size=224)\n",
    "  #        .databunch(bs=32, num_workers=0)\n",
    "  #        .normalize(imagenet_stat))\n",
    "  #learn = cnn_learner(data, models.resnet152, metrics=accuracy).to_tpu_distributed()\n",
    "    logger.debug(\"rank: %d entered train_loop\", index)\n",
    "\n",
    "    param_optimizer = list(k.model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'lr': 4e-5, 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'lr': 4e-5, 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    def AdamW_with_given_p(p_to_ignore, *args, **kargs):\n",
    "        kargs['lr']=TrainGlobalConfig.lr*xm.xrt_world_size()\n",
    "\n",
    "        return AdamW(optimizer_grouped_parameters, *args, **kargs)\n",
    "\n",
    "    if index == 0:\n",
    "        time.sleep(1)\n",
    "    learn = k.create_learner(k, opt_func=AdamW_with_given_p,\n",
    "                             loss_func=LabelSmoothing(),\n",
    "                             wd=0.01,\n",
    "                             callback_fns=[partial(GradientClipping, clip=0.5),\n",
    "                                           ShowGraph,\n",
    "                                           partial(CSVLogger, append=True),\n",
    "                                           partial(CheckGrad, skip_loss_step=False)]\n",
    "                             ).to_tpu_distributed()\n",
    "    learn.lr_find(start_lr=1e-7, end_lr=1e-4, num_it=200)\n",
    "    learn.recorder.plot()\n",
    "    #learn.fit_one_cycle(3, max_lr=9e-6, wd=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "EQDJ4gsP3bIx",
    "lines_to_next_cell": 2,
    "outputId": "69212456-cd22-45b1-a507-d638a39ae9bc"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-a1356ce81a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\n-- Process %d terminated with the following error:\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moriginal_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 225, in _start_fn\n    _setup_replication()\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 218, in _setup_replication\n    xm.set_replication(str(device), [str(device)])\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 217, in set_replication\n    replication_devices = xla_replication_devices(devices)\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 204, in xla_replication_devices\n    format(len(local_devices), len(kind_devices)))\nRuntimeError: Cannot replicate if number of devices (1) is different from 8\n"
     ]
    }
   ],
   "source": [
    "FLAGS={}\n",
    "#xmp.spawn(train_loop, args=(FLAGS,),  nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-zDM9QL3bIz"
   },
   "outputs": [],
   "source": [
    "import pysnooper\n",
    "\n",
    "@pysnooper.snoop()\n",
    "def _mp_fn(rank, flags, k=k):\n",
    "    device = xm.xla_device(devkind='TPU')\n",
    "    logger.debug(\"%s used for xla_device\" % device)\n",
    "    net = k.model\n",
    "    net.to(device)\n",
    "    logger.debug(\"%s used for xla_device, to device done\" % device)\n",
    "\n",
    "    train_sampler = DistributedSamplerWrapper(\n",
    "        sampler=BalanceClassSampler(labels=k.train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        k.train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        k.validation_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        k.validation_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=validation_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        k.validation_tune_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True\n",
    "    )\n",
    "    validation_tune_loader = torch.utils.data.DataLoader(\n",
    "        k.validation_tune_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=validation_tune_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        k.test_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        k.test_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=test_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "\n",
    "    logger.debug(\"rank: %d\", rank)\n",
    "\n",
    "    if rank == 0:\n",
    "        time.sleep(1)\n",
    "\n",
    "    fitter = TPUFitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    fitter.fit(train_loader, validation_loader)\n",
    "    fitter.run_tuning_and_inference(test_loader, validation_tune_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhQxQcSA3bI3",
    "outputId": "b3b2239f-1b6b-4dd4-d9cc-d698016403a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpLwWDel3bI7",
    "outputId": "b7ff8ab4-7852-46d5-b553-d7c712043eb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG]2020-06-18 13:58:51,269:utils:xla:1 used for xla_device\n",
      "[DEBUG]2020-06-18 13:58:52,444:utils:xla:0 used for xla_device\n",
      "[DEBUG]2020-06-18 13:58:52,728:utils:xla:0 used for xla_device\n",
      "[DEBUG]2020-06-18 13:58:52,735:utils:xla:0 used for xla_device\n",
      "[DEBUG]2020-06-18 13:58:52,853:utils:xla:0 used for xla_device\n",
      "[DEBUG]2020-06-18 13:58:53,119:utils:xla:0 used for xla_device\n",
      "[DEBUG]2020-06-18 13:58:53,616:utils:xla:0 used for xla_device\n",
      "[DEBUG]2020-06-18 13:58:54,177:utils:xla:0 used for xla_device\n",
      "[DEBUG]2020-06-18 13:59:59,523:utils:xla:1 used for xla_device, to device done\n",
      "[DEBUG]2020-06-18 14:00:01,509:utils:xla:0 used for xla_device, to device done\n",
      "[DEBUG]2020-06-18 14:00:06,897:utils:xla:0 used for xla_device, to device done\n",
      "[DEBUG]2020-06-18 14:00:07,729:utils:xla:0 used for xla_device, to device done\n",
      "[DEBUG]2020-06-18 14:00:08,287:utils:rank: 0\n",
      "[DEBUG]2020-06-18 14:00:09,252:utils:xla:0 used for xla_device, to device done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is xla:1\n",
      "\n",
      "2020-06-18T14:00:09.326978\n",
      "LR: 4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG]2020-06-18 14:00:09,514:utils:xla:0 used for xla_device, to device done\n",
      "[DEBUG]2020-06-18 14:00:09,514:utils:xla:0 used for xla_device, to device done\n",
      "[DEBUG]2020-06-18 14:00:09,782:utils:xla:0 used for xla_device, to device done\n",
      "[INFO]2020-06-18 14:00:10,024:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.69253\n",
      "[DEBUG]2020-06-18 14:00:10,570:utils:rank: 3\n",
      "[INFO]2020-06-18 14:00:11,350:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.74237\n",
      "[INFO]2020-06-18 14:00:11,066:utils:step: 0, loss: 1.109375\n",
      "[INFO]2020-06-18 14:00:12,402:utils:step: 0, loss: 1.132812\n",
      "[DEBUG]2020-06-18 14:00:15,828:utils:rank: 1\n",
      "[INFO]2020-06-18 14:00:16,519:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.65324\n",
      "[DEBUG]2020-06-18 14:00:16,559:utils:rank: 2\n",
      "[INFO]2020-06-18 14:00:17,268:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.67101\n",
      "[DEBUG]2020-06-18 14:00:18,178:utils:rank: 6\n",
      "[DEBUG]2020-06-18 14:00:18,363:utils:rank: 4\n",
      "[DEBUG]2020-06-18 14:00:18,386:utils:rank: 5\n",
      "[INFO]2020-06-18 14:00:17,565:utils:step: 0, loss: 1.078125\n",
      "[DEBUG]2020-06-18 14:00:18,725:utils:rank: 7\n",
      "[INFO]2020-06-18 14:00:19,033:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.81558\n",
      "[INFO]2020-06-18 14:00:19,161:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.75211\n",
      "[INFO]2020-06-18 14:00:19,197:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.76921\n",
      "[INFO]2020-06-18 14:00:18,325:utils:step: 0, loss: 1.429688\n",
      "[INFO]2020-06-18 14:00:19,512:utils:Train Step 0, loss: 0.00000, final_score: 0.00000, mc_score: 0.00000, time: 0.74831\n",
      "[INFO]2020-06-18 14:00:20,008:utils:step: 0, loss: 1.234375\n",
      "[INFO]2020-06-18 14:00:20,195:utils:step: 0, loss: 1.156250\n",
      "[INFO]2020-06-18 14:00:20,239:utils:step: 0, loss: 1.078125\n",
      "[INFO]2020-06-18 14:00:20,504:utils:step: 0, loss: 0.906250\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FLAGS={}\n",
    "    xmp.spawn(_mp_fn, args=(FLAGS,),  nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTEdrF6n3bJA"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "output_model_file='XLMRobertaModel_tpu_trained.bin'\n",
    "torch.save(k.model.state_dict(), f\"{today}_{output_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu0VhhZAFuYs"
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.read_csv(path) for path in glob('node_submissions/*.csv')]).groupby('id').mean()\n",
    "submission['toxic'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRr-yzJ_yVTW"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f'{ROOT_PATH}/submission.csv')\n",
    "\n",
    "#!cp log.txt '/content/drive/My Drive/jigsaw2020-kaggle-public-baseline/'\n",
    "!make -C kaggle_runner push_dataset"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "name": "shonenkov_training_pipeline.ipynb",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "id,colab_type,colab,language,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
